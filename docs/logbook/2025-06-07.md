# Logbook
### Date: 7th June 2025
### Project: Fraud Detection System
### Issues Resolved: [ML-01](https://github.com/EsosaOrumwese/fraud-detection-system/issues/8) `in-progress`
### Reference commits: Check commits on this date (if any)

* 1:00am
  * Working on feature engineering for my datetime column
  * Designed to expect on `datetime` column i.e. "event_time". If more should be added, then we'll need to update the code

* 10:33am
  * Resumed working on adding a helper function for extracting features from datetime into `train_baseline.py`
  * Added `DateTimeFeaturizer` class to `src/fraud_detection/utils/datetime_featurizer` incase the project grows and I have other `datetime` columns, or I need to improve feature engineering on `datetime` columns.
  * Will commit changes without running the pre-commit hooks just so I don't mess things up when trying to address the other errors that MyPy and Pytest picked up
  * Removed the invalid '✗' markers in ge_validate.py

* 12:00pm
  * Pipeline throwing warning that the Pipeline isn't fit. Ignored it.

* 1:30pm
  * Test `train_baseline.py` and it works well. 
    * However, it lacks a logging or a progress bar within the training as I don't know what's going on
    * Also Test and Train AUC-PR was 0.0029 and this is expected as the synthetic data, for now, has no underlying distribution that connects y and X. Everything is just randomized. This will have to be fixed later to create a better synthetic dataset.
  
* 2:00pm
  * Trying to understand why my expectations don't expect null values for longitude and latitude
  * Made longitude and latitude nullable and bumped up schema (patch). Also update the expectation schema suite. This removes the nullable test for longitude and latitude as they're expected to have null values.

* 3:00pm
  * Forced the schema dtypes on the generated data in `generate.py` to account for the `None` and prevent it from saving as an `object`
  * Noticed that there is a discrepancy between my schema and what great expectation validates. While I have `enum` dtype, it has `object` dtype
  
* 4:36pm
  * Changed the dtype map for `enum` to `CategoricalDtypetype` which is apparently what is wants instead of just `category` or `CategoryDtype`
    * I think it does `df[column].dtype.__class__.__name__` and not just `df[column].dtype`
  * Now I need to change mcc_codes from `int` to `enum` as it really is more of a category than a number. Plus it never reads as `int64` in pandas due to the `Nan`.
    * So schema was bumped up again but I'll leave it as 0.1.1 seeing as it's a similar patch as before.
    * Instead of adding the values of MCC codes to great-expectation, I just called the list of integers in and made it a number
    * Commit changes, now back to ml problems

* 5:02pm
  * Resumed working on the issues with train_baseline
  * 1) Polars’ CategoricalRemappingWarning
    * Cause: When you read & sample your Parquet, Polars treats each file/partition as having its own “local” categorical dictionary. Sampling or combining forces an expensive merge.
    * Fix: Use a global `StringCache` (or declare your `enums` as a Polars Enum up‐front), so all reads share one dictionary
      * `src/fraud_detection/modelling/train_baseline.py:132`
  * 2) scikit-learn’s “unknown categories” warning
    * Cause: Your one-hot encoder saw new levels in test that it never saw at fit, so it encodes them as all-zero rows and warns you.
    * Fix: I'll have to pass in the known list of categories before hand but I need to know what to do with the strings as that's what is messing up the predictive power. transaction_id is a unique string so perhaps it'll have to be dropped.

* 8:00pm
  * Focus needs to be given to proper feature engineering of the model as it is currently not good. I will just set this up, make sure it's free of errors, close the issue but revisit the fine-tuning of this model locally before shipping to Sagemaker