# Logbook
### Date: 29th October 2025
### Project: Fraud Detection System
### Reference commits: Check commits on this date (if any)

* 2:58am:
   - Threaded the S4 allocator so it honours a configurable worker pool: AggregationContext now carries workers, the aggregator fans countries across a ThreadPoolExecutor, preserves deterministic shard order, and logs per-country timing snapshots (packages/engine/src/engine/layers/l1/seg_1B/s4_alloc_plan/l2/aggregate.py:31,54,147). Run reports include the timing table and explicit worker counts via the extended allocation result and materialiser (packages/engine/src/engine/layers/l1/seg_1B/s4_alloc_plan/l1/allocation.py:34, packages/engine/src/engine/layers/l1/seg_1B/s4_alloc_plan/l2/materialise.py:102, packages/engine/src/engine/layers/l1/seg_1B/s4_alloc_plan/l3/observability.py:49).
   - Surfaced the new knob through the orchestration layer: Segment1BConfig carries s4_workers, the CLI exposes --s4-workers, and the scenario runner forwards the value into the S4 runner (packages/engine/src/engine/cli/segment1b.py:60 & 314, packages/engine/src/engine/scenario_runner/l1_seg_1B.py:59 & 203).
   - Restored the S5 anomaly counters by reinstating the missing NumPy import so the streaming tile-index checks no longer crash (packages/engine/src/engine/layers/l1/seg_1B/s5_site_tile_assignment/l2/materialise.py:13).

* 4:45am:
   - Patched the S5 assignment kernel to build the dataframe with an explicit UInt64 schema so large tile identifiers no longer trigger Polars inference overflow (packages/engine/src/engine/layers/l1/seg_1B/s5_site_tile_assignment/l1/assignment.py:180).
   - Dry-run S5 on `local_layer1_regen7` succeeds and publishes the dataset; S6 currently fails immediately because its loader still expects the legacy `TileIndexPartition(frame=...)` signature. That parity gap sits in `s6_site_jitter/l0/datasets.py` and will need the same streaming-aware constructor the other states now rely on.

* 7:15am:
   - Reworked the S6 jitter stage to stream per-country: loaders now expose `collect_country`, the aggregator employs lazy caches, and the kernel drops per-ISO buffers once processed while logging progress so we can spot long tails (packages/engine/src/engine/layers/l1/seg_1B/s6_site_jitter/l0/datasets.py, l2/aggregate.py, l1/jitter.py). Waiting on the next full Segmentâ€¯1B run to confirm the reduced memory profile.
