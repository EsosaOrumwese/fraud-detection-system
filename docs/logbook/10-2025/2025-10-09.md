# Logbook
### Date: 9th October 2025
### Project: Fraud Detection System
### Reference commits: Check commits on this date (if any)


* 5:21am
   - Updated the governance artefacts so S0’s loaders now accept them. Added the mandatory numeric-policy switches (`binary_format`, `rounding_mode`, `fma_allowed`, etc.) and kept the existing merchant/GDP/channel thresholds (`reference/governance/numeric_policy/2025-10-07/numeric_policy.json`). 
   - Added a proper artifacts array with SHA256 digests to the math profile while preserving the recorded functions and metadata (`reference/governance/math_profile/2025-10-08/math_profile_manifest.json`). 
   - Verified both files by exercising `load_numeric_policy`, `load_math_profile_manifest`, and `build_numeric_policy_attestation`, which now complete without raising.
   
* 6:09am:
   - Introduced hurdle_simulation.priors.yaml as the versioned seed for synthetic training priors, capturing RNG, hurdle, NB-mean, and dispersion offsets (`config/models/hurdle/hurdle_simulation.priors.yaml`).
   - Built a typed loader for that file so downstream code can reason about priors without hand-parsing YAML.
   - Added a reusable universe loader that reopens the merchant ingress parquet, joins GDP/bucket metadata, converts channels to CP/CNP, and (optionally) drops rows without macro coverage to keep simulations stable.
   - Wired everything under a new `engine.training.hurdle` namespace for clean imports.
   - Exercised the new pieces with targeted tests to catch schema regressions and confirm the enriched universe carries the expected log-GDP signal.

* 6:12am:
   - Introduced `engine.training.hurdle.simulator` with `simulate_hurdle_corpus`, which:
      - Seeds a NumPy RNG from the governed priors, deterministically builds synthetic brand IDs, and aggregates channel evidence.
      - Computes hurdle logits (base + MCC/channel/bucket offsets + noise) and samples `is_multi`.
      - Generates zero-truncated negative-binomial outlet counts with priors over mean and dispersion (including GDP slope), yielding the NB training table for multi-site brands only.
      - Returns a `SimulatedHurdleCorpus` dataclass bundling logistic rows, NB rows, brand aliases, channel roster, plus a convenience summary.
   - Updated the package namespace so everything is importable via `engine.training.hurdle`.
   - Added reproducibility/structure tests in `tests/engine/training/test_hurdle_simulation_phase2.py`. These assert deterministic outputs, channel vocabulary, multi counts ≥ 2, and sensible summary metrics.
   - Created persistence utilities (`packages/engine/src/engine/training/hurdle/persist.py`) that wrap the simulator, write the logistic/NB/alias/channel parquet datasets under a hierarchical partition (`simulation_version=…/seed=…/<timestamp>`), and record a manifest capturing source paths, RNG seed, and summary stats.
   - Exported the new helpers via the hurdle training package and added a dataclass describing the artefact bundle for easy downstream consumption.
   - Added an integration test (`tests/engine/training/test_hurdle_simulation_phase3.py`) that materialises a run into a temporary directory, re-opens the parquet outputs, and verifies the manifest metadata matches the actual row counts and seed. All phase tests pass together 
   - Added a validator (`packages/engine/src/engine/training/hurdle/validate.py`) that re-opens persisted runs, checks schema coverage, basic corridors, and manifest consistency. `materialise_simulated_corpus` now invokes it after writing. Tests cover the end-to-end flow.
   - Documented the synthetic training provenance and pipeline in `docs/model_spec/data-engine/specs/data-intake/1A/synthetic-hurdle-training.md`.

* 6:55am:
   - Added design-matrix tooling (`packages/engine/src/engine/training/hurdle/design.py`) and persistence loaders so we can reopen a manifest, build S0-aligned hurdle/NB design matrices, and feed them into the fitting stage. Integration tests cover the matrix shapes and dictionary alignment.
