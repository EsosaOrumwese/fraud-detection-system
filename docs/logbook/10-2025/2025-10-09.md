# Logbook
### Date: 9th October 2025
### Project: Fraud Detection System
### Reference commits: Check commits on this date (if any)


* 5:21am
   - Updated the governance artefacts so S0’s loaders now accept them. Added the mandatory numeric-policy switches (`binary_format`, `rounding_mode`, `fma_allowed`, etc.) and kept the existing merchant/GDP/channel thresholds (`reference/governance/numeric_policy/2025-10-07/numeric_policy.json`). 
   - Added a proper artifacts array with SHA256 digests to the math profile while preserving the recorded functions and metadata (`reference/governance/math_profile/2025-10-08/math_profile_manifest.json`). 
   - Verified both files by exercising `load_numeric_policy`, `load_math_profile_manifest`, and `build_numeric_policy_attestation`, which now complete without raising.
   
* 6:09am:
   - Introduced hurdle_simulation.priors.yaml as the versioned seed for synthetic training priors, capturing RNG, hurdle, NB-mean, and dispersion offsets (`config/models/hurdle/hurdle_simulation.priors.yaml`).
   - Built a typed loader for that file so downstream code can reason about priors without hand-parsing YAML.
   - Added a reusable universe loader that reopens the merchant ingress parquet, joins GDP/bucket metadata, converts channels to CP/CNP, and (optionally) drops rows without macro coverage to keep simulations stable.
   - Wired everything under a new `engine.training.hurdle` namespace for clean imports.
   - Exercised the new pieces with targeted tests to catch schema regressions and confirm the enriched universe carries the expected log-GDP signal.

* 6:12am:
   - Introduced `engine.training.hurdle.simulator` with `simulate_hurdle_corpus`, which:
      - Seeds a NumPy RNG from the governed priors, deterministically builds synthetic brand IDs, and aggregates channel evidence.
      - Computes hurdle logits (base + MCC/channel/bucket offsets + noise) and samples `is_multi`.
      - Generates zero-truncated negative-binomial outlet counts with priors over mean and dispersion (including GDP slope), yielding the NB training table for multi-site brands only.
      - Returns a `SimulatedHurdleCorpus` dataclass bundling logistic rows, NB rows, brand aliases, channel roster, plus a convenience summary.
   - Updated the package namespace so everything is importable via `engine.training.hurdle`.
   - Added reproducibility/structure tests in `tests/engine/training/test_hurdle_simulation_phase2.py`. These assert deterministic outputs, channel vocabulary, multi counts ≥ 2, and sensible summary metrics.
   - Created persistence utilities (`packages/engine/src/engine/training/hurdle/persist.py`) that wrap the simulator, write the logistic/NB/alias/channel parquet datasets under a hierarchical partition (`simulation_version=…/seed=…/<timestamp>`), and record a manifest capturing source paths, RNG seed, and summary stats.
   - Exported the new helpers via the hurdle training package and added a dataclass describing the artefact bundle for easy downstream consumption.
   - Added an integration test (`tests/engine/training/test_hurdle_simulation_phase3.py`) that materialises a run into a temporary directory, re-opens the parquet outputs, and verifies the manifest metadata matches the actual row counts and seed. All phase tests pass together 
   - Added a validator (`packages/engine/src/engine/training/hurdle/validate.py`) that re-opens persisted runs, checks schema coverage, basic corridors, and manifest consistency. `materialise_simulated_corpus` now invokes it after writing. Tests cover the end-to-end flow.
   - Documented the synthetic training provenance and pipeline in `docs/model_spec/data-engine/specs/data-intake/1A/synthetic-hurdle-training.md`.

* 6:55am:
   - Added design-matrix tooling (`packages/engine/src/engine/training/hurdle/design.py`) and persistence loaders so we can reopen a manifest, build S0-aligned hurdle/NB design matrices, and feed them into the fitting stage. Integration tests cover the matrix shapes and dictionary alignment.

* 7:00am:
   - Implemented fit_hurdle_coefficients in the new packages/engine/src/engine/training/hurdle/fit.py, providing IRLS-based logistic fitting for the hurdle coefficients, log-linear regression for NB mean, and a clipped method-of-moments regression for dispersion. The helper returns a HurdleFit dataclass with coefficients and diagnostic metadata (iterations, convergence, final step).
   - Exported the fitting utilities through engine.training.hurdle.__init__, alongside the existing simulators, design builders, and persistence helpers.
   - Extended the simulator to persist ln_gdp_pc_usd_2015 within both logistic and NB tables and normalized IDs to strings, supporting deterministic design matrix construction and fitting accuracy (simulator.py and universe.py).
   - Added load_persisted_corpus for reopening a saved simulation run by manifest, enabling Phase 2 to operate on previously persisted data (persist.py).
   - Created tests that materialise a synthetic run, build design matrices, fit the models, and assert coefficient lengths, finiteness, and convergence (tests/engine/training/test_hurdle_fit_phase2.py), alongside the existing simulation/validation suites.

* 7:48am:
   - Added export plumbing (`engine.training.hurdle.exports.generate_export_bundle`) that reuses the simulation/persistence pipeline, fits the logistic/NB coefficients, and writes governed YAML bundles with diagnostic metadata.
   - Materialised a real run under `artefacts/training/1A/hurdle_sim/simulation_version=2025-10-09/seed=9248923/20251009T120000Z/` and published the coefficients at `configs/models/hurdle/exports/version=2025-10-09/20251009T120000Z/` (`hurdle_coefficients.yaml`, `nb_dispersion_coefficients.yaml`).
   - Extended the training helper namespace plus new integration tests (`tests/engine/training/test_hurdle_export_phase3.py`) to round-trip the YAMLs through the S0 loaders. Updated documentation (`synthetic-hurdle-training.md`, logbook) with export provenance.

* 8:36am:
   - added `configs/policy/crossborder_hyperparams.yaml` with a simple synthetic ladder:
      - Default `allow`.
      - Deny high-risk MCCs (`6011`, `6051`) for CNP traffic globally.
      - Deny CNP travel MCCs (`3000–3999`, `4722`).
      - Explicit allow for CP merchants in the EEA ISO set.
      - Final catch-all allow.
   The loader accepts it once you extend the ISO table with the synthetic pseudo-codes we generated (we saw 22 extras like `XC`, `XJ`, etc.).
   - Authored configs/policy/crossborder_hyperparams.yaml with a synthetic, deterministic ladder that denies high-risk CNP MCCs, special-cases travel MCCs, whitelists CP traffic across the synthetic EEA subset, and defaults to allow.
   - Added a new ISO canonical snapshot at reference/layer1/iso_canonical/v2025-10-09/ that appends the pseudo-country codes emitted by the synthetic merchant universe, keeping the policy loader happy.
   - Confirmed the policy parses cleanly against the merchant ISO universe (loader reports 4 rules). A full evaluate_eligibility run will go through once we finalize how S0 ingests the large merchant IDs; for now, we have coverage at the policy level.

* 9:00am:
   - Tightened the merchant builder (`scripts/build_transaction_schema_merchant_ids.py`) to restrict GDP weights to ISO codes present in the canonical list (new `--iso-version` flag), eliminating pseudo ISO emissions and aligning S0 inputs with the policy set.

* 9:32am:
   - All outstanding S0 prerequisites are now in place.
      - Merchant builder tightened (`scripts/build_transaction_schema_merchant_ids.py` now takes `--iso-version` and filters GDP/bucket weights to the canonical ISO set). New run published under `reference/layer1/transaction_schema_merchant_ids/v2025-10-09/`.
      - Synthetic ISO canonical extension (reference/layer1/iso_canonical/v2025-10-09/) already holds the pseudo codes emitted earlier.
      - Tests still green (`python -m pytest tests/engine/training`).
   - Authored configs/policy.s3.rule_ladder.yaml with a deterministic synthetic ladder:
      - Metadata: semver: 0.1.0, version: 2025-10-09, rule_set_id: "CB-2025.10".
      - Closed vocabularies:
         - reason_codes: ALLOW_HOME, ALLOW_EEA_CNP_GROCERY, CLASS_BASELINE, DENY_NON_REGION, DENY_SANCTIONED_CP, DEFAULT_FALLBACK.
         - filter_tags: HOME, EEA, GROCERY, REGION_SCOPE, SANCTIONED.
      - Ordered rules (precedence DENY ≻ ALLOW ≻ CLASS ≻ DEFAULT):
         - DENY_NON_REGION – denies foreign candidates outside the synthetic EEA scope.
         - DENY_SANCTIONED_CP – denies CP traffic to sanctioned destinations (IR, KP, RU).
         - ALLOW_HOME – always ranks the home country first.
         - ALLOW_EEA_CNP_GROCERY – promotes CNP grocery traffic (MCC 5411) within the EEA.
         - CLASS_BASELINE – non-decision-bearing marker for remaining foreign candidates.
         - DEFAULT – catch-all decision, reason code DEFAULT_FALLBACK.

* 10:04am
   - Created an automated path-to-config workflow so S0 can be wired without manual edits:
      - Added `scripts/generate_s0_config.py`. It inspects the latest versioned artefacts (merchant ingress, ISO canonical, GDP, bucket map, numeric/math governance, synthetic model YAMLs, cross‑border policy) and writes `configs/runs/s0_synthetic_config.json`. Optional flags let you pin specific versions.
      - Regenerated `configs/runs/s0_synthetic_config.json`; it now references `transaction_schema_merchant_ids/v2025-10-09/`, `iso_canonical/v2025-10-09/`, the 2025-10-07/08 GDP artefacts, synthetic hurdle exports (`version=2025-10-09/20251009T120000Z`), and the S0 policy.
      - Documented the workflow in the logbook and in `synthetic-hurdle-training.md` (“Run configuration” section).

* 10:36am:
   - `packages/engine/src/engine/layers/l1/seg_1A/s0_foundations/l1/context.py` now accepts JSON-schema files stored as YAML, so the CLI can validate `layer1/schemas.layer1.yaml` without tripping the authority guard.
   - `scripts/generate_s0_config.py` taps `git rev-parse HEAD` when no commit is supplied; reran it so `configs/runs/s0_synthetic_config.json` is pinned to `1dc31c0e76779718d322e4f4f6fb854d9b10fc3e`.
   - `tests/engine/l1/seg_1A/test_s0_foundations.py` adds a config-driven smoke that loads a JSON config, executes `S0FoundationsRunner.run_from_paths`, and verifies the persisted artefacts.

* 11:05am:
   - Added `scripts/run_s0_from_config.py` plus `make run-s0` so the full S0 orchestrator can be replayed from `configs/runs/s0_synthetic_config.json` without retyping the long CLI invocation.
   - Hardened the S0 loaders to treat merchant identifiers as `uint64`, tolerate canonical ISO codes that never appear in the merchant universe, and relaxed the JSON contracts/tests to match the wider ID range.
   - Executed `python scripts/run_s0_from_config.py --config configs/runs/s0_synthetic_config.json --context-json artefacts/s0_runs/2025-10-09_synthetic/run_context.json` (validate on, ≈7 min). Run metadata: `parameter_hash=26b7e7a8fc309440d7e5ad6fc490956da6d18e7a47f76b69f40893f69ff53a9e`, `manifest_fingerprint=991c57a380d81d7ab9ba4901efb0d0db3eb7a82af59249d7cc71017126622709`, `run_id=94568f3abf10ec0a66d214dbb6a8a6e7`. Outputs landed in `artefacts/s0_runs/2025-10-09_synthetic/` with fresh validation bundles and RNG logs.

* 1:29pm:
   - Added resilience around the merchant ingress artefact so S0 can handle the repo’s 128‑bit parquet encoding without crashing.
      - `packages/engine/src/engine/layers/l1/seg_1A/s0_foundations/l0/datasets.py` wraps the parquet reader, detecting the unsupported `FixedLenByteArray(16)`→`INT128` failure and falling back to the sibling CSV while coercing `merchant_id` to `UInt64` so the downstream hashing logic keeps working.
      - `packages/engine/src/engine/layers/l1/seg_1A/s0_foundations/l0/datasets.py` adds a small helper that gathers single or multi-file CSV fallbacks and concatenates them deterministically.
      - `packages/engine/src/engine/layers/l1/seg_1A/s0_foundations/l0/datasets.py` adds a heuristic matcher for the parquet error signature so we only use the CSV path for that specific legacy format.
      - `packages/engine/src/engine/layers/l1/seg_1A/s0_foundations/exceptions.py` registers the new loader error codes with the S0 failure taxonomy so validation emits the right category if the fallback also fails.

* 9:36pm:
   - Locked down the S1 requirements from `docs/model_spec/data-engine/specs/state-flow/1A/state.1A.s1.expanded.md`: logistic hurdle uses the S0 design matrix and coefficient bundle without reshuffling columns; probabilities come from a fixed-order Neumaier dot plus two-branch logistic; RNG draws flow through the merchant-keyed hurdle_bernoulli substream with counters satisfying the budget identity; the event envelope must emit full lineage (`seed`, `parameter_hash`, `manifest_fingerprint`, `run_id`) and enforce `draws ∈ {"0","1"}`, `blocks ∈ {0,1}`, and the nullable `u` policy tied to the deterministic flag. Downstream gating hinges on `is_multi=true` for every gated stream and validators replay decisions from the keyed counters.
   - Extended the dataset dictionary to mark that file as covering both S0 and S1 and registered the hurdle Bernoulli stream so consumers know where the S1 events will land: `contracts/dataset_dictionary/l1/seg_1A/layer1.1A.yaml` now advertises states: [s0, s1], and `contracts/dataset_dictionary/l1/seg_1A/layer1.1A.yaml` defines the `rng_event_hurdle_bernoulli` entry with its partitions and schema anchor.

* 10:10pm
   - Added the S1 logistic core (`packages/engine/src/engine/layers/l1/seg_1A/s1_hurdle/l1/probability.py`) with a Neumaier-compensated dot product and two-branch logistic that returns a typed `HurdleProbability`.
   - Introduced hurdle RNG helpers (`packages/engine/src/engine/layers/l1/seg_1A/s1_hurdle/l1/rng.py`) exposing the `hurdle_bernoulli` label, substream derivation, and counter unpacking; re-exported through the segment package (`packages/engine/src/engine/layers/l1/seg_1A/s1_hurdle/__init__.py`).
   - Implemented event/trace materialisation for S1 (`packages/engine/src/engine/layers/l1/seg_1A/s1_hurdle/l2/output.py`) and the orchestrator (`packages/engine/src/engine/layers/l1/seg_1A/s1_hurdle/l2/runner.py`) that iterates S0 design vectors, computes probabilities, consumes keyed Philox substreams, writes JSONL records, and returns an in-memory `S1RunResult` with the multi-merchant set.