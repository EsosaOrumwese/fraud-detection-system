# Logbook
### Date: 5th July 2025
### Project: Fraud Detection System
### Issues Resolved: [SD-01](https://github.com/EsosaOrumwese/fraud-detection-system/issues/24) `in-progress`
### Reference commits: Check commits on this date (if any)

* 1:30am
  * Began revamping Airflow `daily_synthetic` DAG. Issues pointed out `docs/references/[AIRFLOW_DAG]_update_fix_notes.md`

* 2:21am
  * Chose to not fully refactor the code as adherence to Airflow's v3 documentation wasn't followed.
  * Now I want to make sure that `generate_dataframe` only collects `cfg` so that any override is made outside of it (especially for test cases).

* 3:00am
  * Successfully refactored Airflow DAG, now to test if it works
  * Failed because of a dag import error. Airflow couldn't load my schema due to its path resolution being false seeing as `src/` was installed as a package and not kept at root.
    * Attempted solution: Replace with hard coded path
  * Another issue I have, which will be reserved for later is why my airflow-build to airflow-up took nearly 10mins.

* 11:24am
  * Dag runs successfully, however it saves as `dataset_{rows}.parquet` in s3 instead of `payments_{rows:_}_{date.today()}.parquet`
    * This has been solved

* 1:39pm
  * Everything runs okay, apart from MLflow training
  * Decided to also hardcode the output paths in thereby resolving any issues withing the docker file.
  * Although my data gen appears fixed with a bit of realism added, I have an issue with the labelling. 
    * Most fields for each row are independent of each other so a positive fraud label doesn't make sense 
    * What I'd expect is for their to be a distribution for fraudulent cases which we draw from and then another for the non-fraudulent cases which we also draw from. 
    * That's just my vague idea of things because frauds are expected to behave in a certain way than non-fraudulent accounts although there is expected to be an overlap

* 1:50pm
  * Model trains successfully. That shows that the revamped data generator slots in just fine with the trainer. However, we can see an improved in AUC-PR (0.0267) 
  * Tests (`test_baseline`) were also improved and work well with the new data that I had to change the relaxed assertion from `>0.000001` back to `>0.005`