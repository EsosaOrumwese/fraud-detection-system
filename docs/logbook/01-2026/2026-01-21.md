# Logbook
### Date: 21st January 2026
### Project: Fraud Detection System
### Reference commits: Check commits on this date (if any)

* 3:15am
  - Planned S4 shared-memory routing maps (memory-mapped NumPy arrays) to avoid
    per-worker dict duplication and `BrokenProcessPool` crashes.
  - Logged detailed plan in
    `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md`
    (Entry: 2026-01-21 03:15).

* 3:42am
  - Appended a detailed plan to incrementally load year-scoped `s4_group_weights`
    into `group_weights_map` so S4 avoids full-memory loads and fixes the
    missing map regression. (Implementation map entry: 2026-01-21 03:41)

* 3:44am
  - Implemented year-scoped `s4_group_weights` loading for 5B.S4 so the map is
    built lazily per scenario and skipped entirely when the time-grid years don’t
    overlap. This prevents sending a large map to workers when unused and fixes
    the missing-map regression.

* 3:46am
  - Ran `make segment5b-s4`; run failed with `5B.S4.IO_WRITE_FAILED` and
    `BrokenProcessPool` (child process terminated abruptly). Run report:
    `runs/local_full_run-5/d61f08e2e45ef1bc28884034de4c1b68/reports/layer2/segment_state_runs/segment=5B/utc_day=2026-01-21/segment_state_runs.jsonl`.
  - Reduced S4 defaults in `makefile` (workers=8, inflight=8, output_buffer_rows=20000)
    to cut per-worker memory pressure before re-running.

* 3:55am
  - Planned a diagnostic wrapper for `_process_s4_batch` to capture worker
    exceptions and surface them in the parent process (to distinguish Python
    errors from native/OOM crashes). Logged plan in implementation map
    (Entry: 2026-01-21 03:54).

* 3:58am
  - Added `_process_s4_batch` wrapper to catch worker exceptions and return a
    structured error payload, plus parent-side handling to abort with context.
  - Imported `traceback` for worker error capture.

* 3:59am
  - Re-ran `make segment5b-s4` with updated defaults (workers=8); still failed
    with `5B.S4.IO_WRITE_FAILED` / BrokenProcessPool.
  - Ran `ENGINE_5B_S4_WORKERS=1` to force serial mode; hit
    `5B.S4.DOMAIN_ALIGN_FAILED` (bucket_missing, bucket_index=0).

* 4:05am
  - Restored `runner.py` to the last committed state after an indentation tool
    corrupted the file (syntax errors). Re-applied the worker error wrapper and
    incremental group-weights loading changes.

* 4:07am
  - Started `make segment5b-s4` with workers=8; after ~52s ETA was ~12–13
    minutes (above target). Terminated the running `s4_arrival_events_5b`
    python processes to avoid a long run.

* 4:10am
  - Tested workers=12/inflight=12; early ETA looked low but later stabilized at
    ~11–13 minutes. Killed the running `s4_arrival_events_5b` processes once ETA
    exceeded target.

* 4:17am
  - Reintroduced shared-memory lookup maps in `s4_arrival_events` (shared_maps
    build/load + worker usage) to cut per-event dict lookups and improve speed.

* 4:19am
  - Ran `make segment5b-s4` with shared maps enabled (workers=8). The run started
    fast but the PowerShell host hit an out-of-memory error; terminated the
    `s4_arrival_events_5b` python processes to recover.

* 4:35am
  - Confirmed no lingering `s4_arrival_events_5b` worker processes after the restart.
  - Logged a new S4-safe-defaults plan in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 04:34) to reduce workers/inflight/output buffer and re-test.

* 4:36am
  - Reduced 5B.S4 defaults in `makefile` (workers=4, inflight=4, output_buffer_rows=5000) to lower peak RAM before re-running S4 with shared maps.

* 4:38am
  - Ran `make segment5b-s4` with shared maps + new defaults (workers=4, inflight=4, output_buffer_rows=5000). Early ETA looked promising but after ~145s throughput collapsed (bucket ETA ~70+ min, arrivals ETA hours). Terminated the running `s4_arrival_events_5b` python processes to avoid a long run.

* 4:40am
  - Planned an S4 override test (workers=6, inflight=6, output_buffer_rows=10000) with shared maps to recover throughput without the 8/8/20000 OOM risk; logged plan in the implementation map (Entry: 2026-01-21 04:40).

* 4:42am
  - Ran S4 with overrides (workers=6, inflight=6, output_buffer_rows=10000). After ~115s the rates collapsed (ETA ~36 min+). Terminated the `s4_arrival_events_5b` processes to avoid a long run.

* 4:45am
  - Planned S4 worker optimizations to cut per-arrival overhead (skip bucket sorting when ordering checks are off, cache RNG prefix hashers, cache tzid index per worker). Logged full plan in the implementation map (Entry: 2026-01-21 04:44).

* 4:49am
  - Implemented S4 optimizations: cached RNG prefix hashers per worker, cached tzid index, and skipped per-bucket sorting when ordering stats are disabled (default). Prepared to re-run S4 to validate ETA and memory.

* 4:53am
  - Ran S4 after worker optimizations (workers=6, inflight=6, output_buffer_rows=10000). Throughput still collapsed after ~2 minutes (ETA ~38 min). Terminated the running `s4_arrival_events_5b` processes.

* 4:57am
  - Corrective note: added tuple-based event buffering in the S4 worker path (plus tuple-aware validation in `_write_events`) to reduce per-event dict overhead. Logged the corrective plan in the implementation map (Entry: 2026-01-21 04:56).

* 4:58am
  - Planned a validation run for the tuple-buffer change (workers=6, inflight=6, output_buffer_rows=10000) and will terminate early if ETA exceeds target.

* 5:00am
  - S4 tuple-buffer run failed schema validation (None values for optional fields). Adjusted tuple validation to omit None-valued keys to match previous dict-row behavior. Preparing to re-run.

* 5:02am
  - Re-ran S4 with tuple buffering (workers=6, inflight=6, output_buffer_rows=10000). Validation fix worked, but sustained ETA was still ~32 min (55k arrivals/sec). Terminated the run. Noted Polars DataOrientationWarning for tuple rows.

* 5:03am
  - Planned to add `orient="row"` for tuple DataFrame construction and test a larger output buffer (50000 rows) to reduce write overhead.

* 5:05am
  - Added `orient="row"` when building Polars DataFrames from tuple buffers to remove row-orientation warnings and reduce inference overhead.

* 5:05am
  - Ran S4 with tuple buffer + orient="row" and output_buffer_rows=50000 (workers=6). Sustained rate improved (~98k arrivals/sec) but ETA stayed ~18 min; terminated run.

* 5:06am
  - Planned a higher-parallelism test for S4 (workers=12, inflight=12, output_buffer_rows=50000) to see if throughput scales to the target window.

* 5:08am
  - Tested workers=12/inflight=12/output_buffer_rows=50000. Throughput improved (~118k arrivals/sec) but ETA still ~14-15 min; terminated run.

* 5:12am
  - Logged a detailed plan for the S4 compiled-kernel refactor (Numba-based SHA256 + Philox + routing fast path with fallback) in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md`.

* 5:13am
  - Added `numba` to `pyproject.toml` dependencies to support the compiled S4 kernel path.

* 5:16am
  - Moved the new `numba_kernel.py` into `packages/engine/src/engine/layers/l2/seg_5B/s4_arrival_events/` (initial path missed the `layers` segment).

* 5:24am
  - Implemented a Numba kernel module for S4 (SHA256+Philox+routing) and integrated a compiled-kernel fast path in `_process_s4_batch_impl` guarded by `ENGINE_5B_S4_COMPILED_KERNEL` and shared-maps availability.
  - Added shared-map edge alias arrays and per-worker tz cache/bytes preparation for the compiled path.

* 5:26am
  - Checked `numba_kernel` import with PYTHONPATH set; numba is not installed (`numba_available=False`), so compiled path will stay off until dependency is installed.

* 5:27am
  - Added `ENGINE_5B_S4_COMPILED_KERNEL` default and wiring in `makefile` so the compiled S4 path can be toggled via make.

* 5:28am
  - Verified `engine.layers.l2.seg_5B.s4_arrival_events.runner` imports cleanly with PYTHONPATH set; compiled-kernel module does not break imports even without numba installed.

* 5:30am
  - Logged the plan to install numba and run the full 5B.S4 benchmark (compiled kernel on) in the 5B implementation map.

* 5:31am
  - Detected Python 3.12.7 in the active environment; logged a decision to bump the numba constraint to a 3.12-compatible range before installation.

* 5:31am
  - Updated `pyproject.toml` to use `numba >=0.60,<0.61` for Python 3.12 compatibility.

* 5:33am
  - Numba install pulled numpy 2.0.2, conflicting with feast (requires numpy<2). Logged plan to pin numpy <2.0 and downgrade in the venv.

* 5:50am
  - Ran `make segment5b-s4` with `ENGINE_5B_S4_COMPILED_KERNEL=1`; compiled kernel came up, but numba failed in `u01_from_u64` due to `2**64` integer overflow in nopython mode.

* 5:51am
  - Patched `u01_from_u64` in `packages/engine/src/engine/layers/l2/seg_5B/s4_arrival_events/numba_kernel.py` to use a float constant (`1.0 / 18446744073709551616.0`) and logged the corrective rationale in the 5B implementation map.

* 5:52am
  - Fixed a syntax error caused by a stray `@nb.njit` decorator on `_INV_TWO_POW_64`; moved the decorator to `u01_from_u64` and logged the corrective entry in the 5B implementation map.

* 5:55am
  - Compiled-kernel run hit a numba TypingError on structured key indexing; converted `site_keys`/`site_tz_keys` to 2-column int64 matrices in `_init_s4_worker` and updated the kernel call to use these compiled keys.

* 5:57am
  - Fixed compiled-path schema validation issues by forcing `%6f` microsecond formatting for timestamps and dropping `None` values from validation sample rows before `_validate_rows`.

* 6:08am
  - The compiled-kernel S4 run did not progress beyond initial batch logs; the command timed out and the worker processes were consuming several GB of memory, so I terminated the `make`/`python` processes.

* 6:10am
  - Switched pyarrow batch iteration to `iter_batches(batch_size=BATCH_SIZE)` and updated `pl.from_arrow` conversion to accept `pa.RecordBatch`, so compiled-kernel batches are capped and memory usage stays bounded.

* 6:20am
  - The rerun still stalled after the first few batch logs (last log at 06:10:54); I terminated the `make`/`python` processes again to avoid runaway memory, and plan to re-run with a longer window to allow numba JIT compilation to finish.

* 6:35am
  - The long S4 benchmark I started was still running in the background after the command was interrupted, so I killed the remaining `make`/`python` processes to stop the runaway workers.

* 6:40am
  - Planned a compiled-kernel warmup in `_init_s4_worker` to force numba JIT before real batches, with narrative logs and run_log attachment in workers; recorded the plan in the 5B implementation map.

* 6:41am
  - Implemented the compiled-kernel warmup function in `numba_kernel.py`, added worker warmup logs, and passed `run_log_path` into the worker context so the warmup is visible in the run log.

* 6:58am
  - Ran `make segment5b-s4` with the compiled kernel and warmup enabled; warmup logs appeared for each worker, but the run stopped emitting progress after warmup and did not complete within the 15-min window, so I terminated the background `make`/`python` processes.

* 7:31am
  - Implemented worker-side batch progress logs (time-based cadence with rows/arrivals/ETA) by adding a progress counter in the compiled kernel and a logging thread in `_process_s4_batch_impl`.

* 7:33am
  - Corrected the worker progress log format to be narrative (bucket_rows/arrival_events_5B) and fixed a formatting typo in the ETA string.

* 7:44am
  - Terminated the user-run S4 processes at their request; checked the run log and confirmed worker batch-start lines are present (progress lines appear on the 30s cadence).

* 7:48am
  - Killed the user-run S4 processes again after they reported no log updates past 07:34:47; updated the numba kernel decorators to `nogil=True` across helper functions so the worker progress thread can run while the kernel executes.

* 7:58am
  - Ran S4 with the updated `nogil` kernel; the run log still stopped at 07:50:52 without any `S4: batch progress` lines, so I terminated the `make`/`python` processes again after confirming the stall.

* 8:02am
  - Planned a parent-process heartbeat while awaiting futures (log every ~30s with batch metadata) to keep the run log alive without affecting kernel speed; recorded the plan in the 5B implementation map.

* 8:06am
  - Implemented the parent heartbeat in the parallel worker loop and verified the run log now emits `S4: awaiting worker batch ...` lines every ~30s; terminated the run after confirming the new log behavior.

* 8:56am
  - Reviewed the stalled S4 run log and confirmed workers start batch 0 but never emit `S4: batch progress` lines; the parent keeps logging `awaiting worker batch`, indicating the compiled-kernel path is stuck.
  - Run log: `runs/local_full_run-5/d61f08e2e45ef1bc28884034de4c1b68/run_log_d61f08e2e45ef1bc28884034de4c1b68.log`.

* 9:01am
  - Logged the quick-stabilization plan to disable the compiled kernel by default and add an S4 batch-size knob in
    `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 09:01:30).

* 9:03am
  - Implemented the quick-stabilization changes:
    - Defaulted `ENGINE_5B_S4_COMPILED_KERNEL` to off in `packages/engine/src/engine/layers/l2/seg_5B/s4_arrival_events/runner.py` and `makefile`.
    - Added `ENGINE_5B_S4_BATCH_SIZE` with a 50k default, wired through `_iter_parquet_batches`, and logged the batch size at S4 start.
  - Files updated: `packages/engine/src/engine/layers/l2/seg_5B/s4_arrival_events/runner.py`, `makefile`.

* 9:38am
  - Read the 5B.S4 state-expanded doc and 5B contracts (`dataset_dictionary.layer2.5B.yaml`, `schemas.5B.yaml`, `artefact_registry_5B.yaml`) as the authoritative sources for the redesign.
  - Logged a minimal-relaxation redesign plan for 5B.S4 (keep contracts, relax ordering enforcement, vectorized/compiled pipeline) in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 09:38).

* 9:42am
  - Logged a detailed reimplementation plan for 5B.S4 (bucket-stream RNG, remove per-arrival SHA256, update compiled kernel signature, relax ordering to warn-only) in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 09:42) before coding.

* 10:06am
  - Read the required context in order: `docs/references/closed-world-fraud-enterprise-conceptual-design.md`, `docs/references/closed-world-synthetic-data-engine-with-realism-conceptual-design.md`, `docs/model_spec/data-engine/layer-1/narrative/narrative_1A-to-3B.md`, `docs/model_spec/data-engine/layer-2/narrative/narrative_5A-and-5B.md`, `docs/model_spec/data-engine/layer-3/narrative/narrative_6A-and-6B.md`, and `packages/engine/AGENTS.md`.
  - Re-read 5B.S4 binding docs + contracts: `docs/model_spec/data-engine/layer-2/specs/state-flow/5B/state.5B.s4.expanded.md`, `docs/model_spec/data-engine/layer-2/specs/contracts/5B/dataset_dictionary.layer2.5B.yaml`, `docs/model_spec/data-engine/layer-2/specs/contracts/5B/schemas.5B.yaml`, `docs/model_spec/data-engine/layer-2/specs/contracts/5B/artefact_registry_5B.yaml`.
  - Reviewed the S4 run log for the stalled run and confirmed ETA inflation at ~116M arrivals: `runs/local_full_run-5/d61f08e2e45ef1bc28884034de4c1b68/run_log_d61f08e2e45ef1bc28884034de4c1b68.log`.

* 10:08am
  - Added an execution-plan entry for the minimal-relaxation reimplementation in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 10:08), including the decision to keep contract sources via `ContractSource(config.contracts_root, config.contracts_layout)` for easy dev/prod switching.

* 10:23am
  - Ran `make segment5b-s4` with the compiled kernel enabled; early ETA logs projected ~19-22 minutes for arrivals, so I terminated the `make`/`python` processes per the 15-minute target requirement. Run log: `runs/local_full_run-5/d61f08e2e45ef1bc28884034de4c1b68/run_log_d61f08e2e45ef1bc28884034de4c1b68.log`.

* 10:32am
  - Reworked 5B.S4 to remove per-arrival SHA256 and use bucket-stream Philox counters in both worker and non-parallel paths; updated RNG accounting to 1 block per arrival and computed last counters from base+offset. (`packages/engine/src/engine/layers/l2/seg_5B/s4_arrival_events/runner.py`)
  - Switched compiled-kernel invocation to `expand_batch_kernel_v2`, removed unused tzid/prefix byte plumbing, and made strict ordering warn-only. (`packages/engine/src/engine/layers/l2/seg_5B/s4_arrival_events/runner.py`)
  - Enabled compiled kernel by default for S4 and updated Makefile default. (`packages/engine/src/engine/layers/l2/seg_5B/s4_arrival_events/runner.py`, `makefile`)

* 10:35am
  - Logged the implementation update in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 10:34).

* 10:41am
  - Confirmed the user removed `packages/engine/src/engine/layers/l2/seg_5B/s4_arrival_events` and re-read S4 binding docs + contracts:
    `docs/model_spec/data-engine/layer-2/specs/state-flow/5B/state.5B.s4.expanded.md`,
    `docs/model_spec/data-engine/layer-2/specs/contracts/5B/dataset_dictionary.layer2.5B.yaml`,
    `docs/model_spec/data-engine/layer-2/specs/contracts/5B/schemas.5B.yaml`,
    `docs/model_spec/data-engine/layer-2/specs/contracts/5B/artefact_registry_5B.yaml`.
  - Logged a full re-implementation plan with approved relaxations in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 10:41).

* 11:01am
  - Appended a new S4 reimplementation plan entry in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 11:01).
  - Reviewed S4 routing/time policies and upstream routing fabric references to align the rebuild plan: `config/layer2/5B/arrival_routing_policy_5B.yaml`, `config/layer2/5B/arrival_time_placement_policy_5B.yaml`, `config/layer2/5B/arrival_rng_policy_5B.yaml`, `config/layer1/2B/policy/alias_layout_policy_v1.json`, `config/layer1/2B/policy/route_rng_policy_v1.json`, and routing implementation in `packages/engine/src/engine/layers/l1/seg_2B/s5_router/runner.py` and `packages/engine/src/engine/layers/l1/seg_3B/s4_virtual_contracts/runner.py`.

* 11:34am
  - Read binding context in order: `docs/references/closed-world-fraud-enterprise-conceptual-design.md`, `docs/references/closed-world-synthetic-data-engine-with-realism-conceptual-design.md`, `docs/model_spec/data-engine/layer-1/narrative/narrative_1A-to-3B.md`, `docs/model_spec/data-engine/layer-2/narrative/narrative_5A-and-5B.md`, `docs/model_spec/data-engine/layer-3/narrative/narrative_6A-and-6B.md`, `packages/engine/AGENTS.md`.
  - Read 5B.S4 authority docs + contracts: `docs/model_spec/data-engine/layer-2/specs/state-flow/5B/state.5B.s4.expanded.md`, `docs/model_spec/data-engine/layer-2/specs/contracts/5B/schemas.5B.yaml`, `docs/model_spec/data-engine/layer-2/specs/contracts/5B/dataset_dictionary.layer2.5B.yaml`, `docs/model_spec/data-engine/layer-2/specs/contracts/5B/artefact_registry_5B.yaml`.
  - Reviewed the stalled run log for ETA inflation context: `runs/local_full_run-5/d61f08e2e45ef1bc28884034de4c1b68/run_log_d61f08e2e45ef1bc28884034de4c1b68.log`.
  - Logged a new S4 stabilization plan in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 11:34) before coding.

* 11:44am
  - User requested a full wipe of 5B.S4 implementation (core + CLI) and a rebuild from zero with no reuse.
  - Logged reset decision and deletion plan in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 11:44).

* 11:45am
  - Deleted `packages/engine/src/engine/layers/l2/seg_5B/s4_arrival_events` and `packages/engine/src/engine/cli/s4_arrival_events_5b.py` to honor the full reset request for 5B.S4.

* 12:09pm
  - Logged a fresh from-scratch S4 rebuild plan (minimal relaxations for 15-min target) in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 12:09) before restarting implementation.

* 12:29pm
  - Logged a design relaxation decision: rebuild physical site alias tables from `s1_site_weights` + `site_timezones` instead of consuming `s2_alias_blob`, while still requiring the alias blob/index in `sealed_inputs_5B` to keep contract boundaries intact (Entry: 2026-01-21 12:29 in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md`).

* 1:05pm
  - Completed chunked assembly of the new S4 core (`run_s4`) after the command-length issue; added RNG trace max-counter logic, nullable site/edge IDs, and scenario-union merchant indexing in `packages/engine/src/engine/layers/l2/seg_5B/s4_arrival_events/runner.py`.
  - Added new CLI entrypoint `packages/engine/src/engine/cli/s4_arrival_events_5b.py` and wired Makefile defaults + `segment5b-s4` target in `makefile`.
  - Logged the implementation progress and decisions in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 13:05).

* 1:08pm
  - Ran `make segment5b-s4`; it failed fast because `tz_timetable_cache` is OPTIONAL in sealed_inputs. Adjusted S4 gate to accept OPTIONAL status for `tz_timetable_cache` while still requiring the cache file at runtime. Logged the decision in the implementation map (Entry: 2026-01-21 13:08).

* 1:18pm
  - Re-read the binding S4 docs + contracts and confirmed id64 range for identifiers: `docs/model_spec/data-engine/layer-2/specs/state-flow/5B/state.5B.s4.expanded.md`, `docs/model_spec/data-engine/layer-2/specs/contracts/5B/schemas.5B.yaml`, `docs/model_spec/data-engine/layer-2/specs/contracts/5B/dataset_dictionary.layer2.5B.yaml`, `docs/model_spec/data-engine/layer-2/specs/contracts/5B/artefact_registry_5B.yaml`, `docs/model_spec/data-engine/layer-1/specs/contracts/1A/schemas.layer1.yaml`.
  - Logged the id64 overflow fix plan (uint64 IDs + 0 sentinel to null) in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 13:18).

* 1:22pm
  - Implemented the id64 overflow fix in S4: switched site/edge/merchant IDs to `uint64`, set `site_id` sentinel to 0 in the kernel, added an edge_id=0 guard, and mapped `*_raw == 0` to nullable UInt64 columns in the output. (`packages/engine/src/engine/layers/l2/seg_5B/s4_arrival_events/runner.py`, `packages/engine/src/engine/layers/l2/seg_5B/s4_arrival_events/numba_kernel.py`)
  - Ran `python -m py_compile` for the modified modules; no errors.
  - Logged the implementation outcome in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 13:22).

* 1:24pm
  - Fixed `_decode_alias_slice` format string construction (endianness prefix + `I` repeats) to prevent `bad char in struct format` errors in edge alias blob decoding, and recompiled the runner.
  - Logged the implementation update in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 13:24).

* 1:25pm
  - Ran `make segment5b-s4`; it failed fast with `bad char in struct format` during `build_alias_tables` while decoding the edge alias blob.
  - Logged the alias-slice format-string fix plan in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 13:25).

* 1:27pm
  - Re-ran `make segment5b-s4`; it failed with `5B.S4.ROUTING_POLICY_INVALID` because group weights are missing for at least one (merchant_id, utc_day) while `use_group_weights=true`.
  - Logged a minimal-relaxation plan to fall back to `zone_representation` when group weights are missing in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 13:27).

* 1:28pm
  - Implemented the missing group-weights fallback (warn once per scenario, fallback to `zone_representation`, record `missing_group_weights` in scenario details) and recompiled `runner.py`.
  - Logged the implementation update in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 13:28).

* 1:31pm
  - Re-ran `make segment5b-s4`; it now fails via kernel `row_errors` (missing site/edge alias tables) with `row_index` reported.
  - Logged a minimal-relaxation plan to fall back to a merchant default site table (and to physical routing when edge tables are missing) in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 13:31).

* 1:33pm
  - Implemented kernel fallbacks for missing site/edge alias tables (default site table, virtual->physical fallback) and recompiled `numba_kernel.py`.
  - Logged the implementation update in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 13:33).

* 1:35pm
  - Re-ran `make segment5b-s4`; it failed on output schema validation with `PointerToNowhere: '/$defs/hex64'` when validating `s4_arrival_events_5B` item schemas.
  - Logged the fix plan to wrap item schemas with `$defs` in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 13:35).

* 1:36pm
  - Implemented `$defs` carry-through in `_schema_items` and recompiled `runner.py`.
  - Logged the implementation update in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 13:36).

* 1:37pm
  - Re-ran `make segment5b-s4`; it failed validation because `tzid_settlement`/`tzid_operational` were null (schema requires strings if present).
  - Logged a plan to set operational/settlement tzids to primary for physical rows, and to fall back to operational tzid when settlement tzid is missing for virtual rows (Entry: 2026-01-21 13:37 in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md`).

* 1:38pm
  - Implemented operational/settlement tzid/time population in the kernel (no nulls) and recompiled `numba_kernel.py`.
  - Logged the implementation update in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 13:38).

* 1:39pm
  - Re-ran `make segment5b-s4`; it failed schema validation because `edge_id` is null while the schema expects an integer.
  - Logged a plan to treat `None` values as omitted fields during row validation in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 13:39).

* 1:40pm
  - Implemented `None`-field stripping in `_validate_array_rows` and recompiled `runner.py`.
  - Logged the implementation update in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 13:40).

* 1:41pm
  - Ran `make segment5b-s4`; the run progressed past validation and is emitting arrivals with ETA ~8-9 minutes (within the 15-minute target). The process remains running in the background; monitoring continues.

* 1:50pm
  - S4 run finished PASS for run_id `d61f08e2e45ef1bc28884034de4c1b68` in ~8.4 minutes (503.9s); totals: arrivals=116,424,410; bucket_rows=31,667,760; virtual=2,137,989.
  - Run-report row recorded in `runs/local_full_run-5/d61f08e2e45ef1bc28884034de4c1b68/reports/layer2/segment_state_runs/segment=5B/utc_day=2026-01-21/segment_state_runs.jsonl`.

* 2:18pm
  - Read conceptual + layer narratives in required order: `docs/references/closed-world-fraud-enterprise-conceptual-design.md`, `docs/references/closed-world-synthetic-data-engine-with-realism-conceptual-design.md`, `docs/model_spec/data-engine/layer-1/narrative/narrative_1A-to-3B.md`, `docs/model_spec/data-engine/layer-2/narrative/narrative_5A-and-5B.md`, `docs/model_spec/data-engine/layer-3/narrative/narrative_6A-and-6B.md`.
  - Read expanded state docs required before edits: `docs/model_spec/data-engine/layer-2/specs/state-flow/5B/state.5B.s4.expanded.md`, `docs/model_spec/data-engine/layer-1/specs/state-flow/2B/state.2B.s3.expanded.md`, `docs/model_spec/data-engine/layer-1/specs/state-flow/2B/state.2B.s4.expanded.md`.
  - Reviewed current contracts/policy inputs: `docs/model_spec/data-engine/layer-2/specs/contracts/5B/schemas.5B.yaml`, `docs/model_spec/data-engine/layer-2/specs/contracts/5B/dataset_dictionary.layer2.5B.yaml`, `docs/model_spec/data-engine/layer-2/specs/contracts/5B/artefact_registry_5B.yaml`, `config/layer1/2B/policy/day_effect_policy_v1.json`.

* 2:19pm
  - Logged new plan entries for the 5B nullable-schema relaxation and the 2B day-range policy alignment in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 14:17) and `docs/model_spec/data-engine/implementation_maps/segment_2B.impl_actual.md` (Entry: 2026-01-21 14:17) before touching code/contracts.

* 2:22pm
  - Updated 5B contracts to allow nullable optional fields for S4 arrivals and bumped contract versions: `docs/model_spec/data-engine/layer-2/specs/contracts/5B/schemas.5B.yaml` (version 1.0.1 + nullable fields), `docs/model_spec/data-engine/layer-2/specs/contracts/5B/dataset_dictionary.layer2.5B.yaml` (version 1.0.1), `docs/model_spec/data-engine/layer-2/specs/contracts/5B/artefact_registry_5B.yaml` (arrival_events_5B semver 1.0.1).
  - Removed the `None`-stripping validation workaround in `_validate_array_rows` so schema validation now uses the emitted rows directly (`packages/engine/src/engine/layers/l2/seg_5B/s4_arrival_events/runner.py`).
  - Updated `config/layer1/2B/policy/day_effect_policy_v1.json` day_range to 2026-01-01..2026-03-31, bumped `policy_version`/`version_tag` to 1.0.2, and recomputed `sha256_hex` to `f98ca0621eea84fb5f7054e81766b27aaa32f1ace136a256ffddae191dd5406a`.

* 2:24pm
  - `make segment2b-s3` failed with `2B-S3-070` (`policy_digest_mismatch`) because `sealed_inputs_2B` still references the prior day_effect_policy digest.
  - Logged the remedial plan to rerun 2B.S0 before S3/S4 in `docs/model_spec/data-engine/implementation_maps/segment_2B.impl_actual.md` (Entry: 2026-01-21 14:23).

* 2:25pm
  - `make segment2b-s0` failed with `2B-S0-080` (immutability) since the existing `s0_gate_receipt_2B`/`sealed_inputs_2B` outputs already exist for this run_id and cannot be overwritten.
  - Logged the decision options (delete current S0 outputs vs start a new run_id) in `docs/model_spec/data-engine/implementation_maps/segment_2B.impl_actual.md` (Entry: 2026-01-21 14:24).

* 2:32pm
  - Read 5B.S5 expanded state spec and S5-related contracts/policies for implementation: `docs/model_spec/data-engine/layer-2/specs/state-flow/5B/state.5B.s5.expanded.md`, `docs/model_spec/data-engine/layer-2/specs/contracts/5B/dataset_dictionary.layer2.5B.yaml`, `docs/model_spec/data-engine/layer-2/specs/contracts/5B/artefact_registry_5B.yaml`, `docs/model_spec/data-engine/layer-2/specs/contracts/5A/schemas.layer2.yaml`, `docs/model_spec/data-engine/layer-2/specs/contracts/5B/schemas.5B.yaml`, `config/layer2/5B/validation_policy_5B.yaml`, `config/layer2/5B/bundle_layout_policy_5B.yaml`.
  - Logged the 5B.S5 implementation plan (streaming + summary-based checks with bounded sampling for heavy validations) in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 14:30) before touching code.
