# Logbook
### Date: 21st January 2026
### Project: Fraud Detection System
### Reference commits: Check commits on this date (if any)

* 3:15am
  - Planned S4 shared-memory routing maps (memory-mapped NumPy arrays) to avoid
    per-worker dict duplication and `BrokenProcessPool` crashes.
  - Logged detailed plan in
    `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md`
    (Entry: 2026-01-21 03:15).

* 3:42am
  - Appended a detailed plan to incrementally load year-scoped `s4_group_weights`
    into `group_weights_map` so S4 avoids full-memory loads and fixes the
    missing map regression. (Implementation map entry: 2026-01-21 03:41)

* 3:44am
  - Implemented year-scoped `s4_group_weights` loading for 5B.S4 so the map is
    built lazily per scenario and skipped entirely when the time-grid years don’t
    overlap. This prevents sending a large map to workers when unused and fixes
    the missing-map regression.

* 3:46am
  - Ran `make segment5b-s4`; run failed with `5B.S4.IO_WRITE_FAILED` and
    `BrokenProcessPool` (child process terminated abruptly). Run report:
    `runs/local_full_run-5/d61f08e2e45ef1bc28884034de4c1b68/reports/layer2/segment_state_runs/segment=5B/utc_day=2026-01-21/segment_state_runs.jsonl`.
  - Reduced S4 defaults in `makefile` (workers=8, inflight=8, output_buffer_rows=20000)
    to cut per-worker memory pressure before re-running.

* 3:55am
  - Planned a diagnostic wrapper for `_process_s4_batch` to capture worker
    exceptions and surface them in the parent process (to distinguish Python
    errors from native/OOM crashes). Logged plan in implementation map
    (Entry: 2026-01-21 03:54).

* 3:58am
  - Added `_process_s4_batch` wrapper to catch worker exceptions and return a
    structured error payload, plus parent-side handling to abort with context.
  - Imported `traceback` for worker error capture.

* 3:59am
  - Re-ran `make segment5b-s4` with updated defaults (workers=8); still failed
    with `5B.S4.IO_WRITE_FAILED` / BrokenProcessPool.
  - Ran `ENGINE_5B_S4_WORKERS=1` to force serial mode; hit
    `5B.S4.DOMAIN_ALIGN_FAILED` (bucket_missing, bucket_index=0).

* 4:05am
  - Restored `runner.py` to the last committed state after an indentation tool
    corrupted the file (syntax errors). Re-applied the worker error wrapper and
    incremental group-weights loading changes.

* 4:07am
  - Started `make segment5b-s4` with workers=8; after ~52s ETA was ~12–13
    minutes (above target). Terminated the running `s4_arrival_events_5b`
    python processes to avoid a long run.

* 4:10am
  - Tested workers=12/inflight=12; early ETA looked low but later stabilized at
    ~11–13 minutes. Killed the running `s4_arrival_events_5b` processes once ETA
    exceeded target.

* 4:17am
  - Reintroduced shared-memory lookup maps in `s4_arrival_events` (shared_maps
    build/load + worker usage) to cut per-event dict lookups and improve speed.

* 4:19am
  - Ran `make segment5b-s4` with shared maps enabled (workers=8). The run started
    fast but the PowerShell host hit an out-of-memory error; terminated the
    `s4_arrival_events_5b` python processes to recover.

* 4:35am
  - Confirmed no lingering `s4_arrival_events_5b` worker processes after the restart.
  - Logged a new S4-safe-defaults plan in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md` (Entry: 2026-01-21 04:34) to reduce workers/inflight/output buffer and re-test.

* 4:36am
  - Reduced 5B.S4 defaults in `makefile` (workers=4, inflight=4, output_buffer_rows=5000) to lower peak RAM before re-running S4 with shared maps.

* 4:38am
  - Ran `make segment5b-s4` with shared maps + new defaults (workers=4, inflight=4, output_buffer_rows=5000). Early ETA looked promising but after ~145s throughput collapsed (bucket ETA ~70+ min, arrivals ETA hours). Terminated the running `s4_arrival_events_5b` python processes to avoid a long run.

* 4:40am
  - Planned an S4 override test (workers=6, inflight=6, output_buffer_rows=10000) with shared maps to recover throughput without the 8/8/20000 OOM risk; logged plan in the implementation map (Entry: 2026-01-21 04:40).

* 4:42am
  - Ran S4 with overrides (workers=6, inflight=6, output_buffer_rows=10000). After ~115s the rates collapsed (ETA ~36 min+). Terminated the `s4_arrival_events_5b` processes to avoid a long run.

* 4:45am
  - Planned S4 worker optimizations to cut per-arrival overhead (skip bucket sorting when ordering checks are off, cache RNG prefix hashers, cache tzid index per worker). Logged full plan in the implementation map (Entry: 2026-01-21 04:44).

* 4:49am
  - Implemented S4 optimizations: cached RNG prefix hashers per worker, cached tzid index, and skipped per-bucket sorting when ordering stats are disabled (default). Prepared to re-run S4 to validate ETA and memory.

* 4:53am
  - Ran S4 after worker optimizations (workers=6, inflight=6, output_buffer_rows=10000). Throughput still collapsed after ~2 minutes (ETA ~38 min). Terminated the running `s4_arrival_events_5b` processes.

* 4:57am
  - Corrective note: added tuple-based event buffering in the S4 worker path (plus tuple-aware validation in `_write_events`) to reduce per-event dict overhead. Logged the corrective plan in the implementation map (Entry: 2026-01-21 04:56).

* 4:58am
  - Planned a validation run for the tuple-buffer change (workers=6, inflight=6, output_buffer_rows=10000) and will terminate early if ETA exceeds target.

* 5:00am
  - S4 tuple-buffer run failed schema validation (None values for optional fields). Adjusted tuple validation to omit None-valued keys to match previous dict-row behavior. Preparing to re-run.

* 5:02am
  - Re-ran S4 with tuple buffering (workers=6, inflight=6, output_buffer_rows=10000). Validation fix worked, but sustained ETA was still ~32 min (55k arrivals/sec). Terminated the run. Noted Polars DataOrientationWarning for tuple rows.

* 5:03am
  - Planned to add `orient="row"` for tuple DataFrame construction and test a larger output buffer (50000 rows) to reduce write overhead.

* 5:05am
  - Added `orient="row"` when building Polars DataFrames from tuple buffers to remove row-orientation warnings and reduce inference overhead.

* 5:05am
  - Ran S4 with tuple buffer + orient="row" and output_buffer_rows=50000 (workers=6). Sustained rate improved (~98k arrivals/sec) but ETA stayed ~18 min; terminated run.

* 5:06am
  - Planned a higher-parallelism test for S4 (workers=12, inflight=12, output_buffer_rows=50000) to see if throughput scales to the target window.

* 5:08am
  - Tested workers=12/inflight=12/output_buffer_rows=50000. Throughput improved (~118k arrivals/sec) but ETA still ~14-15 min; terminated run.

* 5:12am
  - Logged a detailed plan for the S4 compiled-kernel refactor (Numba-based SHA256 + Philox + routing fast path with fallback) in `docs/model_spec/data-engine/implementation_maps/segment_5B.impl_actual.md`.

* 5:13am
  - Added `numba` to `pyproject.toml` dependencies to support the compiled S4 kernel path.

* 5:16am
  - Moved the new `numba_kernel.py` into `packages/engine/src/engine/layers/l2/seg_5B/s4_arrival_events/` (initial path missed the `layers` segment).

* 5:24am
  - Implemented a Numba kernel module for S4 (SHA256+Philox+routing) and integrated a compiled-kernel fast path in `_process_s4_batch_impl` guarded by `ENGINE_5B_S4_COMPILED_KERNEL` and shared-maps availability.
  - Added shared-map edge alias arrays and per-worker tz cache/bytes preparation for the compiled path.

* 5:26am
  - Checked `numba_kernel` import with PYTHONPATH set; numba is not installed (`numba_available=False`), so compiled path will stay off until dependency is installed.

* 5:27am
  - Added `ENGINE_5B_S4_COMPILED_KERNEL` default and wiring in `makefile` so the compiled S4 path can be toggled via make.

* 5:28am
  - Verified `engine.layers.l2.seg_5B.s4_arrival_events.runner` imports cleanly with PYTHONPATH set; compiled-kernel module does not break imports even without numba installed.

* 5:30am
  - Logged the plan to install numba and run the full 5B.S4 benchmark (compiled kernel on) in the 5B implementation map.

* 5:31am
  - Detected Python 3.12.7 in the active environment; logged a decision to bump the numba constraint to a 3.12-compatible range before installation.

* 5:31am
  - Updated `pyproject.toml` to use `numba >=0.60,<0.61` for Python 3.12 compatibility.

* 5:33am
  - Numba install pulled numpy 2.0.2, conflicting with feast (requires numpy<2). Logged plan to pin numpy <2.0 and downgrade in the venv.

* 5:50am
  - Ran `make segment5b-s4` with `ENGINE_5B_S4_COMPILED_KERNEL=1`; compiled kernel came up, but numba failed in `u01_from_u64` due to `2**64` integer overflow in nopython mode.

* 5:51am
  - Patched `u01_from_u64` in `packages/engine/src/engine/layers/l2/seg_5B/s4_arrival_events/numba_kernel.py` to use a float constant (`1.0 / 18446744073709551616.0`) and logged the corrective rationale in the 5B implementation map.

* 5:52am
  - Fixed a syntax error caused by a stray `@nb.njit` decorator on `_INV_TWO_POW_64`; moved the decorator to `u01_from_u64` and logged the corrective entry in the 5B implementation map.

* 5:55am
  - Compiled-kernel run hit a numba TypingError on structured key indexing; converted `site_keys`/`site_tz_keys` to 2-column int64 matrices in `_init_s4_worker` and updated the kernel call to use these compiled keys.

* 5:57am
  - Fixed compiled-path schema validation issues by forcing `%6f` microsecond formatting for timestamps and dropping `None` values from validation sample rows before `_validate_rows`.

* 6:08am
  - The compiled-kernel S4 run did not progress beyond initial batch logs; the command timed out and the worker processes were consuming several GB of memory, so I terminated the `make`/`python` processes.

* 6:10am
  - Switched pyarrow batch iteration to `iter_batches(batch_size=BATCH_SIZE)` and updated `pl.from_arrow` conversion to accept `pa.RecordBatch`, so compiled-kernel batches are capped and memory usage stays bounded.

* 6:20am
  - The rerun still stalled after the first few batch logs (last log at 06:10:54); I terminated the `make`/`python` processes again to avoid runaway memory, and plan to re-run with a longer window to allow numba JIT compilation to finish.

* 6:35am
  - The long S4 benchmark I started was still running in the background after the command was interrupted, so I killed the remaining `make`/`python` processes to stop the runaway workers.

* 6:40am
  - Planned a compiled-kernel warmup in `_init_s4_worker` to force numba JIT before real batches, with narrative logs and run_log attachment in workers; recorded the plan in the 5B implementation map.

* 6:41am
  - Implemented the compiled-kernel warmup function in `numba_kernel.py`, added worker warmup logs, and passed `run_log_path` into the worker context so the warmup is visible in the run log.

* 6:58am
  - Ran `make segment5b-s4` with the compiled kernel and warmup enabled; warmup logs appeared for each worker, but the run stopped emitting progress after warmup and did not complete within the 15-min window, so I terminated the background `make`/`python` processes.

* 7:31am
  - Implemented worker-side batch progress logs (time-based cadence with rows/arrivals/ETA) by adding a progress counter in the compiled kernel and a logging thread in `_process_s4_batch_impl`.

* 7:33am
  - Corrected the worker progress log format to be narrative (bucket_rows/arrival_events_5B) and fixed a formatting typo in the ETA string.

* 7:44am
  - Terminated the user-run S4 processes at their request; checked the run log and confirmed worker batch-start lines are present (progress lines appear on the 30s cadence).

* 7:48am
  - Killed the user-run S4 processes again after they reported no log updates past 07:34:47; updated the numba kernel decorators to `nogil=True` across helper functions so the worker progress thread can run while the kernel executes.

* 7:58am
  - Ran S4 with the updated `nogil` kernel; the run log still stopped at 07:50:52 without any `S4: batch progress` lines, so I terminated the `make`/`python` processes again after confirming the stall.

* 8:02am
  - Planned a parent-process heartbeat while awaiting futures (log every ~30s with batch metadata) to keep the run log alive without affecting kernel speed; recorded the plan in the 5B implementation map.

* 8:06am
  - Implemented the parent heartbeat in the parallel worker loop and verified the run log now emits `S4: awaiting worker batch ...` lines every ~30s; terminated the run after confirming the new log behavior.
