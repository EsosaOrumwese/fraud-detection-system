In the synthetic universe a “cross‑zone” merchant must behave like the household names in the real settlement stream: one legal entity, one settlement currency, yet outlets appear in several civil time‑zones and their local clocks all tick when headquarters launches a promo. To reproduce that behaviour the generator inserts a zone‑allocation layer that sits squarely between the country‑level outlet split finished in the hurdle step and the per‑site coordinate sampler. The layer’s charter is three‑fold. First, it has to transform every merchant’s country‑mass vector into legally plausible time‑zone mass while preserving the exact integer outlet counts already drawn for each country. Second, it must do so by sampling from a parameterised prior whose hyper‑parameters come straight from public network‑settlement statistics, so any regulator can rerun the exercise and watch the geography morph in a fully predictable way. Third, once the zone allocation exists, the temporal engine must be able to make stores in different offsets surge together when corporate marketing acts—otherwise the data fail the forensic “offset‑barcode” test auditors love to run.

The procedure begins the instant the hurdle layer commits a merchant’s outlet counts by ISO‑3166 country. For brevity call that vector **v**, normalised to unit mass. The algorithm scans v and flags every country whose mass exceeds a tunable attention threshold θ, defaulting to 1 percent. For governance, θ is loaded at runtime from `config/allocation/zone_mixture_policy.yml` (keys: `theta_mix`, `semver`, `sha256_digest`), and its SHA‑256 is recorded as `theta_digest` in the dataset manifest; the CI test `test_mix_threshold.py` byte‑compares the YAML‑driven queue to the parquet output to detect any drift. Those flagged countries enter the *escalation queue*; every other country keeps its outlets in one monolithic zone, namely the `TZID` whose polygon covers the largest land area of that nation according to the frozen tz‑world shapefile.

Each queued country now needs an internal split across its legal time‑zones. The engine opens the YAML ledger `country_zone_alphas.yaml`, finds the country key, and reads a concise Dirichlet concentration vector **α** that was itself computed from rolling two‑year averages of anonymised settlement counts. That ledger is stored at `config/allocation/country_zone_alphas.yaml` (mapping ISO code→{TZID: α}), carries fields `semver` and `sha256_digest` (manifest key `zone_alpha_digest`), and is consumed by `make_zone_alphas.py` to rebuild α when needed. Because the settlement counts already sum to unity, the file simply rescales them by a global smoothing constant τ = 200 so that the posterior variance matches what JPM’s analytics team observes in quarterly production. No hidden numbers remain in code; a reviewer can crank τ up or down and regenerate the universe, watching dispersion shrink or swell exactly as the Dirichlet mathematics predicts.

With α in hand and an integer outlet count **Nₙ** already set for the country, the algorithm draws a random zone‑share vector **s** from Dirichlet(α) on its own Philox sub‑stream keyed by `(merchant_id,country_iso)`. Multiplying s by Nₙ yields a real‑valued expected count per `TZID`. The engine applies the largest‑remainder deterministic rounding so that the integers sum exactly to Nₙ and the relative rounding error is sub‑one‑outlet. But rounding alone sometimes zeroes out a zone that should statistically survive—especially micro‑zones like `America/Phoenix` that run on permanent standard time. To prevent that artefact, the engine enforces a *bump rule*: if any zone’s fractional expectation exceeds 0.8 yet the rounding would drop it to zero, the smallest positive share s\_z steals one outlet from the largest rounded zone in the same country. Because all operations use integer arithmetic and a fixed tie‑break ordering (alphabetical `TZID`), the bump rule is completely deterministic once the Dirichlet draw is fixed. The floor definitions reside in `config/allocation/zone_floor.yml` (entries: `TZID`, `floor`, `semver`, `sha256_digest`), with its SHA‑256 recorded as `zone_floor_digest` and verified by `ci/test_zone_floor.py` to ensure micro‑zone protections.

All escalated countries are processed in the same fashion, and their `(country_iso, tzid, outlet_count)` triples are appended to a merchant‑scoped Parquet file sorted first by country, then by zone. The allocator writes this as `artefacts/allocation/<merchant_id>_zone_alloc.parquet` and simultaneously appends `<merchant_id>,<sha256>` to `artefacts/allocation/zone_alloc_index.csv` (manifest key `zone_alloc_index_digest`), so the router can verify drift before use.

Zone allocation alone still yields independent store rhythms. To inter‑lock them the generator instantiates a latent **corporate‑day multiplier** γ\_d for every merchant on every UTC calendar day d. A single log‑normal draw with variance σ\_γ²=0.15 does the trick; the log‑normal variance is pinned in `config/routing/routing_day_effect.yml` (key `sigma_gamma_sq`, plus `semver` and `sha256_digest`), and its digest appears as `gamma_variance_digest` in the manifest. That uniform draw is produced by a Philox sub‑stream seeded per merchant via the SHA‑256 of `global_seed` concatenated with the literal string `"gamma_day"` and `merchant_id`; the seed derivation is governed by `config/routing/rng_policy.yml` and its SHA‑256 is stored as `gamma_day_key_digest`, locking the corporate‑day sequence for repeatable replay. Because the mean of γ is exactly one, century‑scale market shares remain untouched, yet hour‑scale counts across offsets develop a Pearson correlation of roughly 0.35, matching what JPM analysts see when Walmart or Zara pushes a midnight‑local flash sale. The multiplier is injected multiplicatively into the LGCP mean μ before sampling and then algebraically divided out when weights are passed to the alias router, so the alias tables built earlier remain valid and need no rebuild.

Micro‑states introduce a final wrinkle: zones like `Europe/San_Marino` could be robbed of all outlets if their host country’s total is small. A floor vector φ\_z in `config/allocation/zone_floor.yml` lists the minimum integer counts for such zones—usually one or two outlets globally. During the largest‑remainder pass the algorithm checks whether any φ\_z would be violated; if so, it atomically reallocates from the largest zone in the same country. Because φ\_z is tiny relative to world volume (< 0.1 percent) the reallocation barely shifts global shares but ensures that every zone appearing in live settlement files can also appear in the synthetic data.

Everything described up to this point is frozen by cryptographic hashes. When the router opens its per‑merchant alias table it also recomputes a *universe hash* by concatenating the manifest digests in the exact order

```
zone_alpha_digest ∥ theta_digest ∥ zone_floor_digest ∥ gamma_variance_digest ∥ zone_alloc_parquet_digest
```

computes

```
h = SHA256(zone_alpha_digest ∥ theta_digest ∥ zone_floor_digest ∥ gamma_variance_digest ∥ zone_alloc_parquet_digest)
```

and embeds `h` as `universe_hash` in each `<merchant_id>_alias.npz`, ensuring all mixture parameters and the allocation Parquet are covered.

Validation closes the loop. After 30 synthetic days are produced the harness bins events by `local_time_offset` and UTC hour for every merchant that owns outlets in at least three offsets. A fast Hough‑transform scans the heat‑map looking for a diagonal ridge; if the slope lies outside the physically plausible –1 to –0.5 offsets‑per‑hour band, the build fails. A second diagnostic compares empirical zone shares against integer allocations, flagging any deviation beyond two percentage points. Both thresholds live in `cross_zone_validation.yml`, so tightening them is one line in a file, not a code change.

By layering a Dirichlet‑driven zone mixture on top of the country split, enforcing deterministic rounding with a documented bump rule and zone floors, modulating all sites daily with a latent corporate multiplier, binding everything together with manifest digests, and wiring heat‑map plus share tests into CI, the sub‑segment “Capturing cross‑zone merchants” turns each multi‑zone `merchant_id` into exactly the poly‑offset creature acquirer logs reveal—no more, no less—while remaining repeatable down to the byte across hosts, seeds and future parameter updates.