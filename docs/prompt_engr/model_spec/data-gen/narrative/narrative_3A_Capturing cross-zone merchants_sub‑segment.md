In the synthetic universe a “cross‑zone” merchant must behave like the household names in the real settlement stream: one legal entity, one settlement currency, yet outlets appear in several civil time‑zones and their local clocks all tick when headquarters launches a promo. To reproduce that behaviour the generator inserts a zone‑allocation layer that sits squarely between the country‑level outlet split finished in the hurdle step and the per‑site coordinate sampler. The layer’s charter is three‑fold. First, it has to transform every merchant’s country‑mass vector into legally plausible time‑zone mass while preserving the exact integer outlet counts already drawn for each country. Second, it must do so by sampling from a parameterised prior whose hyper‑parameters come straight from public network‑settlement statistics, so any regulator can rerun the exercise and watch the geography morph in a fully predictable way. Third, once the zone allocation exists, the temporal engine must be able to make stores in different offsets surge together when corporate marketing acts—otherwise the data fail the forensic “offset‑barcode” test auditors love to run.

The procedure begins the instant the hurdle layer commits a merchant’s outlet counts by ISO‑3166 country. For brevity call that vector **v**, normalised to unit mass. The algorithm scans v and flags every country whose mass exceeds a tunable attention threshold θ, defaulting to 1 percent. Those flagged countries enter the *escalation queue*; every other country keeps its outlets in one monolithic zone, namely the `TZID` whose polygon covers the largest land area of that nation according to the frozen tz‑world shapefile.

Each queued country now needs an internal split across its legal time‑zones. The engine opens the YAML ledger `country_zone_alphas.yaml`, finds the country key, and reads a concise Dirichlet concentration vector **α** that was itself computed from rolling two‑year averages of anonymised settlement counts. Because the settlement counts already sum to unity, the file simply rescales them by a global smoothing constant τ = 200 so that the posterior variance matches what JPM’s analytics team observes in quarterly production. No hidden numbers remain in code; a reviewer can crank τ up or down and regenerate the universe, watching dispersion shrink or swell exactly as the Dirichlet mathematics predicts.

With α in hand and an integer outlet count **N\_c** already set for the country, the algorithm draws a random zone‑share vector **s** from Dirichlet(α) on its own Philox sub‑stream keyed by `(merchant_id,country_iso)`. Multiplying s by N\_c yields a real‑valued expected count per `TZID`. The engine applies the largest‑remainder deterministic rounding so that the integers sum exactly to N\_c and the relative rounding error is sub‑one‑outlet. But rounding alone sometimes zeroes out a zone that should statistically survive—especially micro‑zones like `America/Phoenix` that run on permanent standard time. To prevent that artefact, the engine enforces a *bump rule*: if any zone’s fractional expectation exceeds 0.8 yet the rounding would drop it to zero, the smallest positive share s\_z steals one outlet from the largest rounded zone in the same country. Because all operations use integer arithmetic and a fixed tie‑break ordering (alphabetical `TZID`), the bump rule is completely deterministic once the Dirichlet draw is fixed.

All escalated countries are processed in the same fashion, and their `(country_iso, tzid, outlet_count)` triples are appended to a merchant‑scoped Parquet file sorted first by country, then by zone. That sort order is critical: floating‑point summation later depends on iteration order, and IEEE 754 mandates deterministic rounding given a fixed sequence. The file’s SHA‑256 digest is saved into the global manifest; any tweak to α, τ or θ changes the digest, forcing a full rebuild of downstream artefacts.

Zone allocation alone still yields independent store rhythms. To inter‑lock them the generator instantiates a latent **corporate‑day multiplier** γ\_d for every merchant on every UTC calendar day d. A single log‑normal draw with variance σ\_γ²=0.15 does the trick; σ\_γ² lives in `routing_day_effect.yml`. Because the mean of γ is exactly one, century‑scale market shares remain untouched, yet hour‑scale counts across offsets develop a Pearson correlation of roughly 0.35, matching what JPM analysts see when Walmart or Zara pushes a midnight‑local flash sale. The multiplier is injected multiplicatively into the LGCP mean μ before sampling and then algebraically divided out when weights are passed to the alias router, so the alias tables built earlier remain valid and need no rebuild.

Micro‑states introduce a final wrinkle: zones like `Europe/San_Marino` could be robbed of all outlets if their host country’s total is small. A floor vector φ\_z in `zone_floor.yml` lists the minimum integer counts for such zones—usually one or two outlets globally. During the largest‑remainder pass the algorithm checks whether any φ\_z would be violated; if so, it atomically reallocates from the largest zone in the same country. Because φ\_z is tiny relative to world volume (<0.1 percent) the reallocation barely shifts global shares but ensures that every zone appearing in live settlement files can also appear in the synthetic data.

Everything described up to this point is frozen by cryptographic hashes. When the router opens its per‑merchant alias table it also recomputes a *universe hash* that concatenates the digests of `country_zone_alphas.yaml`, `routing_day_effect.yml`, `zone_floor.yml` and the zone‑allocation Parquet just discussed. If any piece drifts without the others being regenerated, the router refuses to score, printing the mismatching digests so a maintainer can retrace the fault.

Validation closes the loop. After 30 synthetic days are produced the harness bins events by `local_time_offset` and UTC hour for every merchant that owns outlets in at least three offsets. A fast Hough‑transform scans the heat‑map looking for a diagonal ridge; if the slope lies outside the physically plausible −1 to −0.5 offsets‑per‑hour band, the build fails. A second diagnostic compares empirical zone shares against integer allocations, flagging any deviation beyond two percentage points. Both thresholds live in `cross_zone_validation.yml`, so tightening them is one line in a file, not a code change.

By layering a Dirichlet‑driven zone mixture on top of the country split, enforcing deterministic rounding with a documented bump rule and zone floors, modulating all sites daily with a latent corporate multiplier, binding everything together with manifest digests, and wiring heat‑map plus share tests into CI, the sub‑segment “Capturing cross‑zone merchants” turns each multi‑zone `merchant_id` into exactly the poly‑offset creature acquirer logs reveal—no more, no less—while remaining repeatable down to the byte across hosts, seeds and future parameter updates.
