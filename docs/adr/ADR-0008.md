# ADR-0008  Adopt **Feast** (OSS v0.41) as the Feature Store  
*Status  : Proposed*  
*Date    : 2025-06-08*  
*Author  : Esosa Orumwese*  

---

## 1  Decision Statement
We will use **Feast v0.41** (open-source, Apache 2.0) as the canonical *feature store* for both offline training and online inference in the Fraud-Detection system.  
Feast will operate in **“fully self-hosted on AWS”** mode:

| Plane               | Technology                                | Notes                                          |
|---------------------|-------------------------------------------|------------------------------------------------|
| **Offline store**   | S3 (+ Iceberg partition metadata)         | Cheap / Athena-queryable                       |
| **Online store**    | DynamoDB (on-demand)                      | <150 ms p99, scales to 1 k QPS in £10-£15 / mo |
| **Registry**        | YAML on Git                               | Versioned with code, reviewed in PRs           |
| **Orchestration**   | Apache Airflow 3.x DAG (Sprint-02)        | `FeastMaterializeIncrementalOperator`          |
| **Feature serving** | Python SDK in SageMaker endpoint (future) | µ-latency, no network hop                      |

---

## 2  Context and Problem Statement
*Sprint-02 / Sprint-03* will introduce time-aware features (transaction velocity, MCC histories, device blacklists).  
Without a feature-store we risk:

* **Training/serving skew** – point-in-time joins are error-prone.  
* **Operational drift** – handcrafted SQL in multiple places.  
* **Recruiter perception** – modern MLOps roles expect familiarity with a feature-store (Survey 2025: 67 % of FAANG ads mention Feast or Tecton).

Key non-functional requirements (NFR):

| NFR                         | Target                    | Source                 |
|-----------------------------|---------------------------|------------------------|
| *Pragmatic cost*            | Dev sandbox ≤ £50 / month | Cost guard-rail CST-01 |
| *FOSS licence*              | Apache-compatible         | Portfolio/public repo  |
| *Point-in-time correctness* | Built-in API              | Fraud domain           |
| *Airflow integration*       | Native operators          | Orchestration pivot    |
| *Observable lineage*        | Registry + MLflow tags    | Audit/readiness        |

---

## 3  Decision Drivers
1. **Developer productivity** – minimal boilerplate; YAML-defined FeatureViews.  
2. **Community & hiring signal** – 8.7 k GitHub ★, active Slack (~10 k).  
3. **Cost elasticity** – pay-per-request DynamoDB, S3 tiering.  
4. **Vendor neutrality** – keep repo fully public; no closed SaaS keys.  
5. **AWS glue** – Should integrate with existing Terraform/IaC modules.  

---

## 4  Options Considered
| # | Option                | CapEx / OpEx               | Pros                                                             | Cons                                                                      |
|---|-----------------------|----------------------------|------------------------------------------------------------------|---------------------------------------------------------------------------|
| 1 | **Feast v0.41 OSS**   | S3 + DynamoDB ≈ £5-15 / mo | ✓ Point-in-time API<br>✓ Airflow/Flink providers<br>✓ Active OSS | - Requires IAM plumbing<br>- DIY monitoring & dashboards                  |
| 2 | *Hopsworks Cloud*     | \$99 / mo starter          | ✓ Slick UI, FeatureHub<br>✓ K-NN embeddings                      | - Paywall, EU servers only<br>- JVM stack bumps container size            |
| 3 | *Tecton* (SaaS)       | Contact-sales              | ✓ Enterprise SLA, realtime push                                  | - Closed-source, NDA, pricing opaque                                      |
| 4 | *DIY Parquet + Redis* | £0 infra                   | ✓ Zero licence cost                                              | - Re-implement point-in-time joins<br>- No recruiter signal, risk of bugs |

---

## 5  Decision Outcome
**Option 1 (Feast)** chosen because it best balances community familiarity, cost, and implementation effort while satisfying all NFRs.

Status: *Proposed* – will move to **Accepted** once the initial POC (Sprint-02) materialises features nightly and serves them into the baseline model.

---

## 6  Consequences
### Positive
* One-click offline→online materialisation DAG (Airflow `FeastMaterializeIncrementalOperator`).
* Feature registry YAML lives in repo – promotes PR review culture.
* Built-in point-in-time join eliminates label leakage.

### Negative / Trade-offs
* Requires least-privilege IAM role for Airflow worker pods (S3:Get, DDB:PutItem).  
* Online DynamoDB table may cost spike if we run high-QPS realtime demo – mitigated by AWS Budget Alert (CST-01).  
* Must educate team on Feast entity → feature-view DSL (≈ 0.5 day).

---

## 7  Implementation Sketch (Sprint-02)
1. **Terraform module** — create DynamoDB table (`on_demand`, TTL) + S3 prefix.  
2. **Feature repo** — `features/` folder with `customers.py`, `tx_aggregates.py`.  
3. **Airflow DAG**  
   * `FeastPushTransformerOperator` – raw Parquet → feature batch  
   * `FeastMaterializeIncrementalOperator` — hourly online write  
4. **CI** — `feast apply --registry registry.db` smoke test.  
5. **ML pipeline** — model code pulls features via `feast.get_online_features`.

---

## 8  Security & Compliance
* **Data sensitivity** – synthetic only; no GDPR concerns.  
* **IAM** – follow least-privilege policy `Action: s3:PutObject` to `fraud-feature/offline/*`, `dynamodb:PutItem` on the single table.  
* **Logging** – CloudTrail + DynamoDB Streams enable lineage audit.  

---

## 9  Open Questions
* Should we enable **Feast embedded Redis** cache for sub-5 ms latency?  
* Glue catalog vs. Iceberg manifest for offline store partition pruning?  
* Need to benchmark on-demand vs. provisioned RCU/WCU at 500 QPS.


---
