# ADR-0007 · Baseline Fraud Model (ML-01)

*Status — Accepted*  
*Created — 2025-06-05*  
*Revised — 2025-06-05 (ingestion + MLflow/params update)*  
*Author — Esosa Orumwese*

---

## 1 Context  

Sprint-01 must demonstrate an **end-to-end “data → metric” loop** on the 1 M-row synthetic payments set (DAT-02).  
Design additions agreed after review:

* Ingestion now pipes **Polars → sample (without replacement) → pandas** and enforces schema via `config/transaction_schema.yaml`.  
* Tracking, param logging and CLI flags expanded for maximum reproducibility.  
* Numeric features now **pass through unchanged** (previous log-transform on `amount` removed).  
* Default training row count in `make train` set to **500 k** to shorten dev feedback.

---

## 2 Decision  

| Layer                   | Decision                                                                                                                                                                                                                                                                                                                                                                         |
|-------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Data ingestion**      | Load Parquet with **Polars**, sample `N` rows without replacement, convert to pandas, and validate against **`transaction_schema.yaml`** before training.                                                                                                                                                                                                                        |
| **Feature engineering** | • Identify categoricals vs. numerics by dtype.<br>• **One-hot encode** all categorical columns (`OneHotEncoder(handle_unknown="ignore")`, dropping unseen categories at test time).<br>• **Numeric columns pass through** with no scaling/transform for the baseline.                                                                                                            |
| **Algorithm**           | **XGBoost v2.0.3** (`tree_method="hist"`, `n_estimators=300`, `max_depth=6`, `learning_rate=0.1`, `use_label_encoder=False`, `eval_metric="aucpr"`).                                                                                                                                                                                                                             |
| **Class imbalance**     | `scale_pos_weight = n_negative / n_positive` (≈ 330 for 0.3 % fraud).                                                                                                                                                                                                                                                                                                            |
| **Metric of record**    | **Average Precision (PR-AUC)** on a 20 % hold-out split; target ≥ 0.70.                                                                                                                                                                                                                                                                                                          |
| **Experiment tracking** | **MLflow 2.22.0**, tracking URI `file:./mlruns`, **experiment `baseline_fraud`**, run name `baseline_xgb`.<br>Logged: full param set above, `rows`, `seed`, `train_timestamp`.<br>Tags: `schema_version`, `git_commit`.<br>Artifacts: (1) entire sklearn pipeline via `mlflow.sklearn.log_model` registered as **`fraud_xgb` v1**, (2) **1 % random CSV sample** of source data. |
| **CLI & Make**          | Module `python -m fraud_detection.modelling.train_baseline` with flags:<br>`--rows`, `--parquet`, `--n-est`, `--max-depth`, `--learning-rate`, `--max-categories`, `--seed`, `--tree-method`, `--mlflow-experiment`.<br>`make train` runs full pipeline on **500 k rows**; `make mlflow-ui` launches local UI.                                                                   |
| **Unit tests**          | `quick_train` (200 rows, 50 trees, depth 3) using an in-memory 1 000-row Parquet matching the schema; asserts **PR-AUC > 0.005**.                                                                                                                                                                                                                                                |
| **Run-anywhere**        | All steps local-only for Sprint-01; Airflow DAG + remote MLflow server slated for Sprint-02.                                                                                                                                                                                                                                                                                     |

---

## 3 Consequences  

### Positive  
* Pipeline now **self-validates schema** and explicitly records every hyper-parameter, tag and artefact in MLflow.  
* Sampling + schema YAML keeps training repeatable on any clone without pre-baked data.  
* Tests and default `make train` complete faster (500 k rows), keeping CI runtime under 7 min.  
* 1 % CSV sample provides lineage without bloating the MLflow artefact store.

### Negative / Trade-offs  
* Dropping `amount` log-transform may leave scale skew; revisit once feature store is live.  
* Local MLflow store still single-user; team visibility deferred.  
* Raw 1 % sample omits rare fraud rows by chance—acceptable for lineage, not for modelling.

---

## 4 Alternatives considered  

| Alternative                            | Why rejected (baseline phase)                                                                           |
|----------------------------------------|---------------------------------------------------------------------------------------------------------|
| **Logistic regression + class_weight** | 6-point drop in PR-AUC during spike test; chosen XGB gives interpretable trees with better recall.      |
| **CatBoost**                           | Superior to XGB on categoricals but GPU licence friction for some devs; revisit once GPU budget okayed. |
| **Prefect flow**                       | Team pivoted to Airflow to align with recruiter expectations and larger community.                      |
| **Neptune.ai tracking**                | Free tier good but we want a de-facto-standard OSS tool (MLflow) to showcase.                           |

---

## 5 Implementation sketch (reference)  

```bash
poetry add xgboost scikit-learn imbalanced-learn mlflow polars shap
make train           # trains on 500 k rows, logs run
make mlflow-ui       # open http://localhost:5000
pytest -q            # CI smoke tests
```

Run targets appear in **`.github/workflows/ci.yml`** right after linting;

---

## 6 Future improvements (backlog → Sprint-02)

1. **Airflow DAG** – daily retrain with synthetic delta load; push model to remote MLflow server.
2. **Optuna sweep** – 20-trial hyper-opt, tracked as child runs under the same MLflow experiment.
3. **Great Expectations** on training data to block schema drift.
4. **SageMaker Training Job** wrapper to benchmark cloud parity cost.
5. **SHAP explainability report** auto-exported to S3 and surfaced in PR comment.

---

## 7 Validation checklist

* `make train` on 500 k rows → **PR-AUC ≥ 0.70**; model registered `fraud_xgb` v1.  
* `mlflow ui` shows params + tags (schema_version, git_commit) and artefacts (model, encoder, 1 % CSV).  
* `pytest -q` passes (`quick_train` PR-AUC > 0.005).  
* Schema YAML exactly matches training Parquet columns & dtypes.

---

## 8 Change history

| Date       | Author         | Notes                                                                                                                 |
|------------|----------------|-----------------------------------------------------------------------------------------------------------------------|
| 2025-06-05 | Esosa Orumwese | Original ADR-0007 accepted.                                                                                           |
| 2025-06-05 | Esosa Orumwese | **Added Polars ingestion, schema validation, new hyper-parameters, artefact sampling, updated tests & CLI defaults.** |


---



