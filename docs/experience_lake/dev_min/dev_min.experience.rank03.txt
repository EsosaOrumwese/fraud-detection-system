dev_min.experience.rank03.txt
Title: Established production-shaped CI/CD + immutable artifact identity (provenance, secure CI auth, deterministic packaging boundaries)

Context (what was at stake, in recruiter terms)
In a managed minimal dev environment, “running the platform” is only credible if the artifact that runs on managed compute is:
- produced repeatably (not “built on my laptop”),
- identifiable immutably (so you can answer “what exactly is running?”),
- traceable to source (so you can audit, rollback, and reproduce),
- and built in a secure way (so you don’t leak secrets or create supply-chain risk).

This is the release engineering line that recruiters care about:
If you can’t ship a provable artifact, you don’t really have a platform — you have a demo.

Non-negotiables (release discipline I enforced)
- CI is the authoritative build plane (not ad-hoc local builds).
- Every artifact has an immutable identity (digest) and traceable provenance (who/what/when produced it).
- Mutable tags (“latest”) are convenience only — never proof.
- Packaging must be deterministic: build boundaries are explicit so “what gets shipped” doesn’t drift accidentally.
- Secrets must not be baked into images; the build/evidence must remain non-secret.
- “Build succeeded” is not enough — packaging only counts when provenance + identity are verifiably recorded.

What I built (the release system, described in recruiter-relevant terms)

1) Authoritative CI build lane (“build happens off laptop”)
I moved packaging into a controlled CI lane so that the runtime artifact is produced in a known, auditable environment.
This matters because the moment you run on managed compute, any “local-only” build story becomes a risk:
- it’s hard to reproduce,
- it’s hard to trust,
- and it’s hard to support operationally (especially under incident pressure).

Outcome of this design:
A reviewer can trust that “the artifact that ran” is the artifact that CI produced, not something hand-built.

2) Immutable artifact identity as a first-class requirement (digest over vibes)
I treated immutable identity as the core anchor for everything downstream:
- deployment references can point to something immutable,
- rollback is meaningful because you can return to a known artifact,
- run evidence can refer to an exact build (not a moving tag).

This is a big senior signal because it shows you think in operational terms:
“What is running right now?” is answerable.
“What ran during run X?” is answerable.
“Can we reproduce that environment?” is answerable.

3) Provenance as part of the artifact, not a side note
I captured (and required) provenance information that ties together:
- source revision,
- build actor/context,
- artifact identity,
- and the fact that the build happened under the authoritative lane.

Why recruiters care:
This is how real systems defend trust without requiring someone to read your code.
It also becomes the bridge between “engineering delivery” and “governance”.

4) Deterministic packaging boundaries (avoid accidental bloat/leaks/drift)
In a large repo, “just copy everything into the image” is how you create:
- giant images,
- unstable builds,
- accidental inclusion of things that shouldn’t ship (and sometimes sensitive material).

So I enforced explicit packaging boundaries:
- what is allowed into the runtime artifact is deliberate,
- what is not allowed stays out,
- and the build contract prevents accidental drift.

Recruiter relevance:
This is supply-chain hygiene, operational reliability, and professionalism — not “nice to have”.

5) CI security posture (secure-by-default CI, not “keys on laptop”)
I treated CI identity as a real security boundary:
- CI should authenticate without long-lived static keys,
- and it should have only the permissions needed to produce and publish artifacts.

Why this matters:
It’s how modern platform teams reduce credential risk and keep delivery auditable.
It also proves you understand “least privilege” in a practical way (not just as a concept).

What “real work” looked like (pressure points this release system had to survive)
A production-shaped release lane isn’t proven by a happy-path build.
It’s proven by encountering and closing real failures like:
- CI auth boundaries not working as assumed,
- permissions being too tight (or too broad) and needing correction,
- artifacts building successfully but still being operationally wrong because the packaging contract was incomplete.

The senior behavior here is not “I fixed it once”.
It’s that the system ended up with a tighter contract:
- the lane fails closed until artifact identity + provenance are present,
- and packaging correctness is treated as part of system correctness.

Before → After (explicit outcome)
Before: “The platform builds” could mean “it builds locally” or “it built once” — neither is operationally trustworthy on managed compute.
After: You can point to a provable release:
- built in CI (authoritative),
- identified immutably (digest),
- tied to provenance,
- and bounded by deterministic packaging rules.

That makes the rest of the managed minimal dev environment credible — because managed runtime is now running something you can actually name and reproduce.

Prevention (what this stops from happening again)
- Stops “shadow builds” (different artifacts built in different places).
- Stops “we deployed latest” ambiguity (you can always reference the digest).
- Stops accidental packaging drift (explicit boundaries reduce “it worked yesterday” surprises).
- Stops secret leakage through artifacts (secrets aren’t embedded; evidence stays non-secret).
- Stops unverifiable demos (runs can refer back to an exact artifact identity).

Why this experience is strong for Senior Platform + Senior MLOps screens
This is one of the clearest “senior” signals because it shows you understand that production systems are:
- shipped,
- traced,
- rolled back,
- and audited.

MLOps teams care because models and data pipelines only become “real” when they are delivered and operated with this level of discipline.
Platform teams care because everything else (runtime, observability, incident response) depends on having a trustworthy artifact story.

What it does NOT claim yet
This proves release engineering maturity for the platform (artifact identity, provenance, secure CI posture, deterministic packaging boundaries).
It does not claim full ML lifecycle controls like model registry promotion/rollback, drift monitoring, or CT pipelines — those remain dev_full/prod_target proofs.
But it is a prerequisite foundation: without artifact identity + provenance, those later MLOps controls don’t stand on solid ground.