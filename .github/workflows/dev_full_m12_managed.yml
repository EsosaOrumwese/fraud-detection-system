name: dev-full-m12-managed

on:
  workflow_dispatch:
    inputs:
      aws_region:
        description: AWS region
        required: true
        default: eu-west-2
        type: string
      aws_role_to_assume:
        description: OIDC role ARN
        required: true
        type: string
      evidence_bucket:
        description: S3 evidence bucket
        required: true
        default: fraud-platform-dev-full-evidence
        type: string
      m12_subphase:
        description: "M12 subphase target (single managed lane)"
        required: true
        default: A
        type: choice
        options:
          - A
          - B
          - C
          - D
          - E
          - F
          - G
          - H
          - I
          - J
      execution_mode:
        description: "Execution mode"
        required: true
        default: materialization_check
        type: choice
        options:
          - materialization_check
          - m12a_execute
          - m12b_execute
      upstream_m11j_execution:
        description: Upstream M11.J execution id (entry readiness ref)
        required: true
        default: m11j_closure_sync_20260227T104756Z
        type: string
      upstream_m12a_execution:
        description: Upstream M12.A execution id (M12.B entry readiness ref)
        required: true
        default: m12a_handle_closure_20260227T121911Z
        type: string
      m12_execution_id:
        description: Optional fixed execution id override
        required: false
        default: ""
        type: string

permissions:
  contents: read
  id-token: write

concurrency:
  group: dev-full-m12-managed-${{ github.ref_name }}
  cancel-in-progress: false

jobs:
  run_m12_managed:
    name: Run M12.${{ inputs.m12_subphase }} managed lane
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Validate supported mode and subphase
        shell: bash
        run: |
          set -euo pipefail
          case "${{ inputs.m12_subphase }}" in
            A|B|C|D|E|F|G|H|I|J) ;;
            *)
              echo "Unsupported m12_subphase='${{ inputs.m12_subphase }}'"
              exit 1
              ;;
          esac
          if [[ "${{ inputs.execution_mode }}" != "materialization_check" && "${{ inputs.execution_mode }}" != "m12a_execute" && "${{ inputs.execution_mode }}" != "m12b_execute" ]]; then
            echo "Unsupported execution_mode='${{ inputs.execution_mode }}'"
            exit 1
          fi
          if [[ "${{ inputs.execution_mode }}" == "m12a_execute" && "${{ inputs.m12_subphase }}" != "A" ]]; then
            echo "execution_mode='m12a_execute' currently supports only m12_subphase='A'."
            exit 1
          fi
          if [[ "${{ inputs.execution_mode }}" == "m12b_execute" && "${{ inputs.m12_subphase }}" != "B" ]]; then
            echo "execution_mode='m12b_execute' currently supports only m12_subphase='B'."
            exit 1
          fi

      - name: Reject static AWS credential posture
        shell: bash
        run: |
          set -euo pipefail
          if [[ -n "${AWS_ACCESS_KEY_ID:-}" || -n "${AWS_SECRET_ACCESS_KEY:-}" ]]; then
            echo "Static AWS credentials are forbidden; use OIDC role assumption."
            exit 1
          fi

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ inputs.aws_region }}
          role-to-assume: ${{ inputs.aws_role_to_assume }}

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install runtime dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          python -m pip install boto3 botocore

      - name: Compute execution metadata
        id: run_meta
        shell: bash
        run: |
          set -euo pipefail
          TS="$(date -u +'%Y%m%dT%H%M%SZ')"
          if [[ -n "${{ inputs.m12_execution_id }}" ]]; then
            EXEC_ID="${{ inputs.m12_execution_id }}"
          else
            case "${{ inputs.m12_subphase }}" in
              A) EXEC_ID="m12a_handle_closure_${TS}" ;;
              B) EXEC_ID="m12b_candidate_eligibility_${TS}" ;;
              C) EXEC_ID="m12c_compatibility_precheck_${TS}" ;;
              D) EXEC_ID="m12d_promotion_commit_${TS}" ;;
              E) EXEC_ID="m12e_rollback_drill_${TS}" ;;
              F) EXEC_ID="m12f_active_resolution_${TS}" ;;
              G) EXEC_ID="m12g_governance_append_${TS}" ;;
              H) EXEC_ID="m12h_p15_gate_rollup_${TS}" ;;
              I) EXEC_ID="m12i_phase_cost_outcome_${TS}" ;;
              J) EXEC_ID="m12j_closure_sync_${TS}" ;;
            esac
          fi
          echo "execution_id=${EXEC_ID}" >> "$GITHUB_OUTPUT"
          echo "run_dir=runs/dev_substrate/dev_full/m12/${EXEC_ID}" >> "$GITHUB_OUTPUT"

      - name: Execute M12-B0 managed lane materialization check
        if: ${{ inputs.execution_mode == 'materialization_check' }}
        shell: bash
        env:
          EXEC_ID: ${{ steps.run_meta.outputs.execution_id }}
          RUN_DIR: ${{ steps.run_meta.outputs.run_dir }}
          EVIDENCE_BUCKET: ${{ inputs.evidence_bucket }}
          AWS_REGION: ${{ inputs.aws_region }}
          M12_SUBPHASE: ${{ inputs.m12_subphase }}
          EXECUTION_MODE: ${{ inputs.execution_mode }}
          UPSTREAM_M11J_EXEC: ${{ inputs.upstream_m11j_execution }}
        run: |
          set -euo pipefail
          python - <<'PY'
          from __future__ import annotations
          import json
          import os
          from datetime import datetime, timezone
          from pathlib import Path
          from typing import Any

          import boto3
          from botocore.exceptions import BotoCoreError, ClientError

          def now() -> str:
              return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")

          def s3_get_json(s3: Any, bucket: str, key: str) -> dict[str, Any]:
              raw = s3.get_object(Bucket=bucket, Key=key)["Body"].read().decode("utf-8")
              payload = json.loads(raw)
              if not isinstance(payload, dict):
                  raise ValueError("json_not_object")
              return payload

          def s3_put_json(s3: Any, bucket: str, key: str, payload: dict[str, Any]) -> None:
              body = (json.dumps(payload, indent=2, ensure_ascii=True) + "\n").encode("utf-8")
              s3.put_object(Bucket=bucket, Key=key, Body=body, ContentType="application/json")
              s3.head_object(Bucket=bucket, Key=key)

          def dedupe(blockers: list[dict[str, str]]) -> list[dict[str, str]]:
              out: list[dict[str, str]] = []
              seen: set[tuple[str, str]] = set()
              for b in blockers:
                  code = str(b.get("code", "")).strip()
                  msg = str(b.get("message", "")).strip()
                  sig = (code, msg)
                  if sig in seen:
                      continue
                  seen.add(sig)
                  out.append({"code": code, "message": msg})
              return out

          exec_id = os.environ["EXEC_ID"].strip()
          run_dir = Path(os.environ["RUN_DIR"].strip())
          bucket = os.environ["EVIDENCE_BUCKET"].strip()
          region = os.environ.get("AWS_REGION", "eu-west-2").strip() or "eu-west-2"
          subphase = os.environ["M12_SUBPHASE"].strip()
          mode = os.environ["EXECUTION_MODE"].strip()
          upstream_m11j = os.environ["UPSTREAM_M11J_EXEC"].strip()

          s3 = boto3.client("s3", region_name=region)
          blockers: list[dict[str, str]] = []
          read_errors: list[dict[str, str]] = []
          upload_errors: list[dict[str, str]] = []

          supported_subphases = ["A", "B", "C", "D", "E", "F", "G", "H", "I", "J"]
          if subphase not in supported_subphases:
              blockers.append({"code": "M12-B0", "message": f"Unsupported subphase '{subphase}'."})
          if mode != "materialization_check":
              blockers.append({"code": "M12-B0", "message": f"Unsupported execution mode '{mode}'."})

          routing_map = {
              "A": "m12a_handle_closure_<ts>",
              "B": "m12b_candidate_eligibility_<ts>",
              "C": "m12c_compatibility_precheck_<ts>",
              "D": "m12d_promotion_commit_<ts>",
              "E": "m12e_rollback_drill_<ts>",
              "F": "m12f_active_resolution_<ts>",
              "G": "m12g_governance_append_<ts>",
              "H": "m12h_p15_gate_rollup_<ts>",
              "I": "m12i_phase_cost_outcome_<ts>",
              "J": "m12j_closure_sync_<ts>",
          }

          upstream_summary_key = f"evidence/dev_full/run_control/{upstream_m11j}/m11j_execution_summary.json"
          upstream_summary: dict[str, Any] = {}
          try:
              upstream_summary = s3_get_json(s3, bucket, upstream_summary_key)
          except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
              read_errors.append({"surface": upstream_summary_key, "error": type(exc).__name__})
              blockers.append({"code": "M12-B0", "message": "Unreadable M11.J upstream summary."})

          if upstream_summary:
              if not bool(upstream_summary.get("overall_pass", False)):
                  blockers.append({"code": "M12-B0", "message": "M11.J upstream summary overall_pass is false."})
              if str(upstream_summary.get("next_gate", "")).strip() != "M12_READY":
                  blockers.append({"code": "M12-B0", "message": "M11.J upstream summary next_gate is not M12_READY."})

          snapshot = {
              "captured_at_utc": now(),
              "phase": "M12.B0",
              "execution_id": exec_id,
              "mode": mode,
              "requested_subphase": subphase,
              "supported_subphases": supported_subphases,
              "deterministic_execution_routing": routing_map,
              "upstream_m11j_execution": upstream_m11j,
              "upstream_m11j_summary_key": upstream_summary_key,
              "entry_ready": bool(upstream_summary.get("overall_pass", False)) and str(upstream_summary.get("next_gate", "")).strip() == "M12_READY",
              "managed_lane_materialized": True,
          }

          dispatchability = {
              "captured_at_utc": now(),
              "phase": "M12.B0",
              "execution_id": exec_id,
              "requested_subphase": subphase,
              "dispatchable": True,
              "single_workflow_lane": "dev-full-m12-managed",
              "authoritative_path": "managed_only",
          }

          blocker_register = {
              "captured_at_utc": now(),
              "phase": "M12.B0",
              "execution_id": exec_id,
              "blocker_count": 0,
              "blockers": [],
              "overall_pass": False,
          }

          execution_summary = {
              "captured_at_utc": now(),
              "phase": "M12.B0",
              "execution_id": exec_id,
              "requested_subphase": subphase,
              "overall_pass": False,
              "blocker_count": 0,
              "verdict": "HOLD_REMEDIATE",
              "next_gate": "HOLD_REMEDIATE",
              "artifact_keys": {},
          }

          artifacts = {
              "m12_managed_lane_materialization_snapshot.json": snapshot,
              "m12_subphase_dispatchability_snapshot.json": dispatchability,
              "m12b0_blocker_register.json": blocker_register,
              "m12b0_execution_summary.json": execution_summary,
          }

          run_dir.mkdir(parents=True, exist_ok=True)
          for fname, payload in artifacts.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")

          run_control_prefix = f"evidence/dev_full/run_control/{exec_id}/"
          for fname, payload in artifacts.items():
              try:
                  s3_put_json(s3, bucket, run_control_prefix + fname, payload)
              except (BotoCoreError, ClientError) as exc:
                  upload_errors.append({"surface": run_control_prefix + fname, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B0", "message": f"Failed to publish {fname}."})

          blockers = dedupe(blockers)
          overall_pass = len(blockers) == 0
          verdict = "ADVANCE_TO_M12_A" if overall_pass else "HOLD_REMEDIATE"
          next_gate = "M12.A_READY" if overall_pass else "HOLD_REMEDIATE"
          blocker_register["blocker_count"] = len(blockers)
          blocker_register["blockers"] = blockers
          blocker_register["overall_pass"] = overall_pass
          execution_summary["overall_pass"] = overall_pass
          execution_summary["blocker_count"] = len(blockers)
          execution_summary["verdict"] = verdict
          execution_summary["next_gate"] = next_gate
          execution_summary["artifact_keys"] = {
              "m12_managed_lane_materialization_snapshot": run_control_prefix + "m12_managed_lane_materialization_snapshot.json",
              "m12_subphase_dispatchability_snapshot": run_control_prefix + "m12_subphase_dispatchability_snapshot.json",
              "m12b0_blocker_register": run_control_prefix + "m12b0_blocker_register.json",
              "m12b0_execution_summary": run_control_prefix + "m12b0_execution_summary.json",
          }
          execution_summary["read_errors"] = read_errors
          execution_summary["upload_errors"] = upload_errors

          for fname, payload in {
              "m12b0_blocker_register.json": blocker_register,
              "m12b0_execution_summary.json": execution_summary,
          }.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")
              try:
                  s3_put_json(s3, bucket, run_control_prefix + fname, payload)
              except Exception:
                  pass

          print(
              json.dumps(
                  {
                      "execution_id": exec_id,
                      "requested_subphase": subphase,
                      "overall_pass": overall_pass,
                      "blocker_count": len(blockers),
                      "next_gate": next_gate,
                      "verdict": verdict,
                      "evidence_prefix": f"s3://{bucket}/{run_control_prefix}",
                  },
                  indent=2,
                  ensure_ascii=True,
              )
          )
          if not overall_pass:
              raise SystemExit(1)
          PY

      - name: Execute M12.A handle closure (managed)
        if: ${{ inputs.execution_mode == 'm12a_execute' && inputs.m12_subphase == 'A' }}
        shell: bash
        env:
          EXEC_ID: ${{ steps.run_meta.outputs.execution_id }}
          RUN_DIR: ${{ steps.run_meta.outputs.run_dir }}
          EVIDENCE_BUCKET: ${{ inputs.evidence_bucket }}
          AWS_REGION: ${{ inputs.aws_region }}
          UPSTREAM_M11J_EXEC: ${{ inputs.upstream_m11j_execution }}
        run: |
          set -euo pipefail
          python - <<'PY'
          from __future__ import annotations
          import json
          import os
          import re
          from datetime import datetime, timezone
          from pathlib import Path
          from typing import Any

          import boto3
          from botocore.exceptions import BotoCoreError, ClientError

          def now() -> str:
              return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")

          def s3_get_json(s3: Any, bucket: str, key: str) -> dict[str, Any]:
              raw = s3.get_object(Bucket=bucket, Key=key)["Body"].read().decode("utf-8")
              payload = json.loads(raw)
              if not isinstance(payload, dict):
                  raise ValueError("json_not_object")
              return payload

          def s3_put_json(s3: Any, bucket: str, key: str, payload: dict[str, Any]) -> None:
              body = (json.dumps(payload, indent=2, ensure_ascii=True) + "\n").encode("utf-8")
              s3.put_object(Bucket=bucket, Key=key, Body=body, ContentType="application/json")
              s3.head_object(Bucket=bucket, Key=key)

          def dedupe(blockers: list[dict[str, str]]) -> list[dict[str, str]]:
              out: list[dict[str, str]] = []
              seen: set[tuple[str, str]] = set()
              for b in blockers:
                  code = str(b.get("code", "")).strip()
                  msg = str(b.get("message", "")).strip()
                  sig = (code, msg)
                  if sig in seen:
                      continue
                  seen.add(sig)
                  out.append({"code": code, "message": msg})
              return out

          def parse_handles(path: Path) -> dict[str, str]:
              rx = re.compile(r"^\*\s+`([A-Z0-9_]+)\s*=\s*(.+)`\s*$")
              out: dict[str, str] = {}
              for line in path.read_text(encoding="utf-8").splitlines():
                  m = rx.match(line.strip())
                  if not m:
                      continue
                  key = m.group(1).strip()
                  raw = m.group(2).strip()
                  if (raw.startswith('"') and raw.endswith('"')) or (raw.startswith("'") and raw.endswith("'")):
                      out[key] = raw[1:-1]
                  else:
                      out[key] = raw
              return out

          exec_id = os.environ["EXEC_ID"].strip()
          run_dir = Path(os.environ["RUN_DIR"].strip())
          bucket = os.environ["EVIDENCE_BUCKET"].strip()
          region = os.environ.get("AWS_REGION", "eu-west-2").strip() or "eu-west-2"
          upstream_m11j = os.environ["UPSTREAM_M11J_EXEC"].strip()

          s3 = boto3.client("s3", region_name=region)
          blockers: list[dict[str, str]] = []
          read_errors: list[dict[str, str]] = []
          upload_errors: list[dict[str, str]] = []

          upstream_key = f"evidence/dev_full/run_control/{upstream_m11j}/m11j_execution_summary.json"
          upstream_summary: dict[str, Any] = {}
          try:
              upstream_summary = s3_get_json(s3, bucket, upstream_key)
          except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
              read_errors.append({"surface": upstream_key, "error": type(exc).__name__})
              blockers.append({"code": "M12-B1", "message": "Unreadable M11.J upstream summary."})

          platform_run_id = ""
          scenario_run_id = ""
          if upstream_summary:
              platform_run_id = str(upstream_summary.get("platform_run_id", "")).strip()
              scenario_run_id = str(upstream_summary.get("scenario_run_id", "")).strip()
              if not bool(upstream_summary.get("overall_pass", False)):
                  blockers.append({"code": "M12-B1", "message": "M11.J upstream summary overall_pass is false."})
              try:
                  blocker_count = int(str(upstream_summary.get("blocker_count", "")).strip())
              except Exception:
                  blocker_count = -1
              if blocker_count != 0:
                  blockers.append({"code": "M12-B1", "message": "M11.J upstream blocker_count is not zero."})
              if str(upstream_summary.get("next_gate", "")).strip() != "M12_READY":
                  blockers.append({"code": "M12-B1", "message": "M11.J upstream next_gate is not M12_READY."})
              if not platform_run_id or not scenario_run_id:
                  blockers.append({"code": "M12-B1", "message": "M11.J upstream run scope is incomplete."})

          required_handles = [
              "MPR_PROMOTION_RECEIPT_PATH_PATTERN",
              "MPR_ROLLBACK_DRILL_PATH_PATTERN",
              "FP_BUS_LEARNING_REGISTRY_EVENTS_V1",
              "GOV_APPEND_LOG_PATH_PATTERN",
              "GOV_RUN_CLOSE_MARKER_PATH_PATTERN",
              "MF_CANDIDATE_BUNDLE_PATH_PATTERN",
              "PHASE_BUDGET_ENVELOPE_PATH_PATTERN",
              "PHASE_COST_OUTCOME_RECEIPT_PATH_PATTERN",
          ]
          handles_path = Path("docs/model_spec/platform/migration_to_dev/dev_full_handles.registry.v0.md")
          handles: dict[str, str] = {}
          try:
              handles = parse_handles(handles_path)
          except Exception as exc:
              blockers.append({"code": "M12-B1", "message": f"Unable to parse handles registry: {type(exc).__name__}."})

          resolved_handles: dict[str, str] = {}
          unresolved: list[str] = []
          for key in required_handles:
              value = str(handles.get(key, "")).strip()
              resolved_handles[key] = value
              if (not value) or (value.upper() == "TO_PIN"):
                  unresolved.append(key)
          if unresolved:
              blockers.append({"code": "M12-B1", "message": f"Unresolved required handles: {', '.join(unresolved)}."})

          handle_snapshot = {
              "captured_at_utc": now(),
              "phase": "M12.A",
              "execution_id": exec_id,
              "platform_run_id": platform_run_id,
              "scenario_run_id": scenario_run_id,
              "upstream_m11j_execution": upstream_m11j,
              "upstream_summary_key": upstream_key,
              "required_handles": required_handles,
              "resolved_handles": resolved_handles,
              "unresolved_handles": unresolved,
              "handle_matrix_complete": len(unresolved) == 0,
          }

          blocker_register = {
              "captured_at_utc": now(),
              "phase": "M12.A",
              "phase_id": "P15",
              "execution_id": exec_id,
              "blocker_count": 0,
              "blockers": [],
              "overall_pass": False,
          }

          execution_summary = {
              "captured_at_utc": now(),
              "phase": "M12.A",
              "phase_id": "P15",
              "execution_id": exec_id,
              "platform_run_id": platform_run_id,
              "scenario_run_id": scenario_run_id,
              "overall_pass": False,
              "blocker_count": 0,
              "verdict": "HOLD_REMEDIATE",
              "next_gate": "HOLD_REMEDIATE",
              "upstream_refs": {"m11j_execution_id": upstream_m11j},
              "artifact_keys": {},
          }

          artifacts = {
              "m12a_handle_closure_snapshot.json": handle_snapshot,
              "m12a_blocker_register.json": blocker_register,
              "m12a_execution_summary.json": execution_summary,
          }

          run_dir.mkdir(parents=True, exist_ok=True)
          for fname, payload in artifacts.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")

          run_control_prefix = f"evidence/dev_full/run_control/{exec_id}/"
          for fname, payload in artifacts.items():
              try:
                  s3_put_json(s3, bucket, run_control_prefix + fname, payload)
              except (BotoCoreError, ClientError) as exc:
                  upload_errors.append({"surface": run_control_prefix + fname, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B1", "message": f"Failed to publish {fname}."})

          blockers = dedupe(blockers)
          overall_pass = len(blockers) == 0
          verdict = "ADVANCE_TO_M12_B" if overall_pass else "HOLD_REMEDIATE"
          next_gate = "M12.B_READY" if overall_pass else "HOLD_REMEDIATE"
          blocker_register["blocker_count"] = len(blockers)
          blocker_register["blockers"] = blockers
          blocker_register["overall_pass"] = overall_pass
          execution_summary["overall_pass"] = overall_pass
          execution_summary["blocker_count"] = len(blockers)
          execution_summary["verdict"] = verdict
          execution_summary["next_gate"] = next_gate
          execution_summary["artifact_keys"] = {
              "m12a_handle_closure_snapshot": run_control_prefix + "m12a_handle_closure_snapshot.json",
              "m12a_blocker_register": run_control_prefix + "m12a_blocker_register.json",
              "m12a_execution_summary": run_control_prefix + "m12a_execution_summary.json",
          }
          execution_summary["read_errors"] = read_errors
          execution_summary["upload_errors"] = upload_errors

          for fname, payload in {
              "m12a_blocker_register.json": blocker_register,
              "m12a_execution_summary.json": execution_summary,
          }.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")
              try:
                  s3_put_json(s3, bucket, run_control_prefix + fname, payload)
              except Exception:
                  pass

          print(
              json.dumps(
                  {
                      "execution_id": exec_id,
                      "overall_pass": overall_pass,
                      "blocker_count": len(blockers),
                      "next_gate": next_gate,
                      "verdict": verdict,
                      "evidence_prefix": f"s3://{bucket}/{run_control_prefix}",
                  },
                  indent=2,
                  ensure_ascii=True,
              )
          )
          if not overall_pass:
              raise SystemExit(1)
          PY

      - name: Execute M12.B candidate eligibility precheck (managed)
        if: ${{ inputs.execution_mode == 'm12b_execute' && inputs.m12_subphase == 'B' }}
        shell: bash
        env:
          EXEC_ID: ${{ steps.run_meta.outputs.execution_id }}
          RUN_DIR: ${{ steps.run_meta.outputs.run_dir }}
          EVIDENCE_BUCKET: ${{ inputs.evidence_bucket }}
          AWS_REGION: ${{ inputs.aws_region }}
          UPSTREAM_M12A_EXEC: ${{ inputs.upstream_m12a_execution }}
        run: |
          set -euo pipefail
          python - <<'PY'
          from __future__ import annotations
          import json
          import os
          from datetime import datetime, timezone
          from pathlib import Path
          from typing import Any

          import boto3
          from botocore.exceptions import BotoCoreError, ClientError

          def now() -> str:
              return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")

          def s3_get_json(s3: Any, bucket: str, key: str) -> dict[str, Any]:
              raw = s3.get_object(Bucket=bucket, Key=key)["Body"].read().decode("utf-8")
              payload = json.loads(raw)
              if not isinstance(payload, dict):
                  raise ValueError("json_not_object")
              return payload

          def s3_put_json(s3: Any, bucket: str, key: str, payload: dict[str, Any]) -> None:
              body = (json.dumps(payload, indent=2, ensure_ascii=True) + "\n").encode("utf-8")
              s3.put_object(Bucket=bucket, Key=key, Body=body, ContentType="application/json")
              s3.head_object(Bucket=bucket, Key=key)

          def s3_parse_uri(uri: str) -> tuple[str, str]:
              if not uri.startswith("s3://"):
                  raise ValueError("not_s3_uri")
              tail = uri[5:]
              if "/" not in tail:
                  raise ValueError("missing_key")
              bucket, key = tail.split("/", 1)
              if not bucket or not key:
                  raise ValueError("incomplete_s3_uri")
              return bucket, key

          def dedupe(blockers: list[dict[str, str]]) -> list[dict[str, str]]:
              out: list[dict[str, str]] = []
              seen: set[tuple[str, str]] = set()
              for b in blockers:
                  code = str(b.get("code", "")).strip()
                  msg = str(b.get("message", "")).strip()
                  sig = (code, msg)
                  if sig in seen:
                      continue
                  seen.add(sig)
                  out.append({"code": code, "message": msg})
              return out

          exec_id = os.environ["EXEC_ID"].strip()
          run_dir = Path(os.environ["RUN_DIR"].strip())
          default_bucket = os.environ["EVIDENCE_BUCKET"].strip()
          region = os.environ.get("AWS_REGION", "eu-west-2").strip() or "eu-west-2"
          upstream_m12a = os.environ["UPSTREAM_M12A_EXEC"].strip()

          s3 = boto3.client("s3", region_name=region)
          blockers: list[dict[str, str]] = []
          read_errors: list[dict[str, str]] = []
          upload_errors: list[dict[str, str]] = []

          m12a_summary_key = f"evidence/dev_full/run_control/{upstream_m12a}/m12a_execution_summary.json"
          m12a_summary: dict[str, Any] = {}
          try:
              m12a_summary = s3_get_json(s3, default_bucket, m12a_summary_key)
          except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
              read_errors.append({"surface": m12a_summary_key, "error": type(exc).__name__})
              blockers.append({"code": "M12-B2", "message": "Unreadable M12.A execution summary."})

          platform_run_id = ""
          scenario_run_id = ""
          upstream_m11j = ""
          if m12a_summary:
              platform_run_id = str(m12a_summary.get("platform_run_id", "")).strip()
              scenario_run_id = str(m12a_summary.get("scenario_run_id", "")).strip()
              upstream_m11j = str((m12a_summary.get("upstream_refs") or {}).get("m11j_execution_id", "")).strip()
              if not bool(m12a_summary.get("overall_pass", False)):
                  blockers.append({"code": "M12-B2", "message": "M12.A overall_pass is false."})
              try:
                  m12a_blocker_count = int(str(m12a_summary.get("blocker_count", "")).strip())
              except Exception:
                  m12a_blocker_count = -1
              if m12a_blocker_count != 0:
                  blockers.append({"code": "M12-B2", "message": "M12.A blocker_count is not zero."})
              if str(m12a_summary.get("next_gate", "")).strip() != "M12.B_READY":
                  blockers.append({"code": "M12-B2", "message": "M12.A next_gate is not M12.B_READY."})
              if not platform_run_id or not scenario_run_id:
                  blockers.append({"code": "M12-B2", "message": "M12.A run scope is incomplete."})
              if not upstream_m11j:
                  blockers.append({"code": "M12-B2", "message": "M12.A upstream m11j_execution_id is missing."})

          m11j_summary_key = f"evidence/dev_full/run_control/{upstream_m11j}/m11j_execution_summary.json" if upstream_m11j else ""
          m11j_summary: dict[str, Any] = {}
          if m11j_summary_key:
              try:
                  m11j_summary = s3_get_json(s3, default_bucket, m11j_summary_key)
              except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
                  read_errors.append({"surface": m11j_summary_key, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B2", "message": "Unreadable M11.J execution summary."})

          upstream_m11i = ""
          if m11j_summary:
              if not bool(m11j_summary.get("overall_pass", False)):
                  blockers.append({"code": "M12-B2", "message": "M11.J overall_pass is false."})
              if str(m11j_summary.get("next_gate", "")).strip() != "M12_READY":
                  blockers.append({"code": "M12-B2", "message": "M11.J next_gate is not M12_READY."})
              upstream_m11i = str((m11j_summary.get("upstream_refs") or {}).get("m11i_execution_id", "")).strip()
              if not upstream_m11i:
                  blockers.append({"code": "M12-B2", "message": "M11.J upstream m11i_execution_id is missing."})

          handoff_key = f"evidence/dev_full/run_control/{upstream_m11i}/m12_handoff_pack.json" if upstream_m11i else ""
          handoff_pack: dict[str, Any] = {}
          if handoff_key:
              try:
                  handoff_pack = s3_get_json(s3, default_bucket, handoff_key)
              except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
                  read_errors.append({"surface": handoff_key, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B2", "message": "Unreadable m12_handoff_pack.json from M11.I."})

          if handoff_pack:
              hp_platform_run = str(handoff_pack.get("platform_run_id", "")).strip()
              hp_scenario_run = str(handoff_pack.get("scenario_run_id", "")).strip()
              if hp_platform_run != platform_run_id or hp_scenario_run != scenario_run_id:
                  blockers.append({"code": "M12-B2", "message": "Run-scope mismatch between M12.A and M11.I handoff pack."})

          required_ref_keys = [
              "mf_candidate_bundle_ref",
              "m11_model_operability_report_ref",
              "m11_eval_report_ref",
              "m11_eval_vs_baseline_report_ref",
              "mf_leakage_provenance_check_ref",
              "m11_reproducibility_check_ref",
              "m11f_mlflow_lineage_snapshot_ref",
          ]
          handoff_required_refs = handoff_pack.get("required_refs") if isinstance(handoff_pack.get("required_refs"), dict) else {}
          missing_required_refs: list[str] = []
          readable_ref_report: dict[str, dict[str, Any]] = {}
          loaded_refs: dict[str, dict[str, Any]] = {}
          for ref_key in required_ref_keys:
              ref_value = str(handoff_required_refs.get(ref_key, "")).strip()
              ref_state = {"ref": ref_value, "readable": False, "error": ""}
              if not ref_value:
                  missing_required_refs.append(ref_key)
                  ref_state["error"] = "missing_ref"
                  readable_ref_report[ref_key] = ref_state
                  continue
              try:
                  ref_bucket, ref_key_path = s3_parse_uri(ref_value)
                  ref_payload = s3_get_json(s3, ref_bucket, ref_key_path)
                  ref_state["readable"] = True
                  loaded_refs[ref_key] = ref_payload
              except Exception as exc:
                  ref_state["error"] = type(exc).__name__
                  read_errors.append({"surface": ref_value, "error": type(exc).__name__})
              readable_ref_report[ref_key] = ref_state

          if missing_required_refs:
              blockers.append({"code": "M12-B2", "message": f"Missing required handoff refs: {', '.join(missing_required_refs)}."})

          unreadable_refs = [k for k, v in readable_ref_report.items() if not bool(v.get("readable", False))]
          if unreadable_refs:
              blockers.append({"code": "M12-B2", "message": f"Unreadable required refs: {', '.join(unreadable_refs)}."})

          candidate_bundle = loaded_refs.get("mf_candidate_bundle_ref", {})
          candidate_checks = {
              "present": bool(candidate_bundle),
              "bundle_status_candidate": False,
              "run_scope_match": False,
              "required_fields_present": False,
              "eval_gate_results_all_true": False,
              "lineage_fields_present": False,
          }
          required_candidate_fields = [
              "bundle_id",
              "bundle_status",
              "model",
              "metrics",
              "lineage",
              "rollback_pointers",
              "platform_run_id",
              "scenario_run_id",
          ]
          missing_candidate_fields: list[str] = []
          if candidate_bundle:
              candidate_checks["bundle_status_candidate"] = str(candidate_bundle.get("bundle_status", "")).strip() == "CANDIDATE"
              candidate_checks["run_scope_match"] = (
                  str(candidate_bundle.get("platform_run_id", "")).strip() == platform_run_id
                  and str(candidate_bundle.get("scenario_run_id", "")).strip() == scenario_run_id
              )
              for key in required_candidate_fields:
                  v = candidate_bundle.get(key)
                  if v is None:
                      missing_candidate_fields.append(key)
                  elif isinstance(v, str) and not v.strip():
                      missing_candidate_fields.append(key)
              candidate_checks["required_fields_present"] = len(missing_candidate_fields) == 0
              eval_gate = ((candidate_bundle.get("metrics") or {}).get("eval_gate_results")) if isinstance(candidate_bundle.get("metrics"), dict) else None
              if isinstance(eval_gate, dict):
                  gate_keys = ["compatibility", "leakage", "performance", "stability"]
                  candidate_checks["eval_gate_results_all_true"] = all(bool(eval_gate.get(k, False)) for k in gate_keys)
              lineage = candidate_bundle.get("lineage") if isinstance(candidate_bundle.get("lineage"), dict) else {}
              lineage_keys = ["m11d_execution_id", "m11e_execution_id", "m11f_execution_id", "mlflow_run_id"]
              candidate_checks["lineage_fields_present"] = all(bool(str(lineage.get(k, "")).strip()) for k in lineage_keys)

          if not candidate_checks["present"]:
              blockers.append({"code": "M12-B2", "message": "Candidate bundle is unreadable."})
          if candidate_bundle and not candidate_checks["bundle_status_candidate"]:
              blockers.append({"code": "M12-B2", "message": "Candidate bundle status is not CANDIDATE."})
          if candidate_bundle and not candidate_checks["run_scope_match"]:
              blockers.append({"code": "M12-B2", "message": "Candidate bundle run scope mismatches M12 run scope."})
          if candidate_bundle and not candidate_checks["required_fields_present"]:
              blockers.append({"code": "M12-B2", "message": f"Candidate bundle missing required fields: {', '.join(missing_candidate_fields)}."})
          if candidate_bundle and not candidate_checks["eval_gate_results_all_true"]:
              blockers.append({"code": "M12-B2", "message": "Candidate bundle eval gate results are not all true."})
          if candidate_bundle and not candidate_checks["lineage_fields_present"]:
              blockers.append({"code": "M12-B2", "message": "Candidate bundle lineage fields are incomplete."})

          eligibility_snapshot = {
              "captured_at_utc": now(),
              "phase": "M12.B",
              "phase_id": "P15",
              "execution_id": exec_id,
              "platform_run_id": platform_run_id,
              "scenario_run_id": scenario_run_id,
              "upstream_refs": {
                  "m12a_execution_id": upstream_m12a,
                  "m12a_execution_summary_key": m12a_summary_key,
                  "m11j_execution_id": upstream_m11j,
                  "m11j_execution_summary_key": m11j_summary_key,
                  "m11i_execution_id": upstream_m11i,
                  "m12_handoff_pack_key": handoff_key,
              },
              "required_handoff_refs": required_ref_keys,
              "readable_ref_report": readable_ref_report,
              "candidate_checks": candidate_checks,
              "missing_candidate_fields": missing_candidate_fields,
              "candidate_bundle_bundle_id": str(candidate_bundle.get("bundle_id", "")).strip() if candidate_bundle else "",
          }

          blocker_register = {
              "captured_at_utc": now(),
              "phase": "M12.B",
              "phase_id": "P15",
              "execution_id": exec_id,
              "blocker_count": 0,
              "blockers": [],
              "overall_pass": False,
          }

          execution_summary = {
              "captured_at_utc": now(),
              "phase": "M12.B",
              "phase_id": "P15",
              "execution_id": exec_id,
              "platform_run_id": platform_run_id,
              "scenario_run_id": scenario_run_id,
              "overall_pass": False,
              "blocker_count": 0,
              "verdict": "HOLD_REMEDIATE",
              "next_gate": "HOLD_REMEDIATE",
              "upstream_refs": {
                  "m12a_execution_id": upstream_m12a,
                  "m11j_execution_id": upstream_m11j,
                  "m11i_execution_id": upstream_m11i,
              },
              "artifact_keys": {},
          }

          artifacts = {
              "m12b_candidate_eligibility_snapshot.json": eligibility_snapshot,
              "m12b_blocker_register.json": blocker_register,
              "m12b_execution_summary.json": execution_summary,
          }

          run_dir.mkdir(parents=True, exist_ok=True)
          for fname, payload in artifacts.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")

          run_control_prefix = f"evidence/dev_full/run_control/{exec_id}/"
          for fname, payload in artifacts.items():
              try:
                  s3_put_json(s3, default_bucket, run_control_prefix + fname, payload)
              except (BotoCoreError, ClientError) as exc:
                  upload_errors.append({"surface": run_control_prefix + fname, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B2", "message": f"Failed to publish {fname}."})

          blockers = dedupe(blockers)
          overall_pass = len(blockers) == 0
          verdict = "ADVANCE_TO_M12_C" if overall_pass else "HOLD_REMEDIATE"
          next_gate = "M12.C_READY" if overall_pass else "HOLD_REMEDIATE"
          blocker_register["blocker_count"] = len(blockers)
          blocker_register["blockers"] = blockers
          blocker_register["overall_pass"] = overall_pass
          execution_summary["overall_pass"] = overall_pass
          execution_summary["blocker_count"] = len(blockers)
          execution_summary["verdict"] = verdict
          execution_summary["next_gate"] = next_gate
          execution_summary["artifact_keys"] = {
              "m12b_candidate_eligibility_snapshot": run_control_prefix + "m12b_candidate_eligibility_snapshot.json",
              "m12b_blocker_register": run_control_prefix + "m12b_blocker_register.json",
              "m12b_execution_summary": run_control_prefix + "m12b_execution_summary.json",
          }
          execution_summary["read_errors"] = read_errors
          execution_summary["upload_errors"] = upload_errors

          for fname, payload in {
              "m12b_blocker_register.json": blocker_register,
              "m12b_execution_summary.json": execution_summary,
          }.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")
              try:
                  s3_put_json(s3, default_bucket, run_control_prefix + fname, payload)
              except Exception:
                  pass

          print(
              json.dumps(
                  {
                      "execution_id": exec_id,
                      "overall_pass": overall_pass,
                      "blocker_count": len(blockers),
                      "next_gate": next_gate,
                      "verdict": verdict,
                      "evidence_prefix": f"s3://{default_bucket}/{run_control_prefix}",
                  },
                  indent=2,
                  ensure_ascii=True,
              )
          )
          if not overall_pass:
              raise SystemExit(1)
          PY

      - name: Upload local run artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: dev-full-m12-${{ inputs.m12_subphase }}-${{ steps.run_meta.outputs.execution_id }}
          path: ${{ steps.run_meta.outputs.run_dir }}
          if-no-files-found: warn
