name: dev-full-m12-managed

on:
  workflow_dispatch:
    inputs:
      aws_region:
        description: AWS region
        required: true
        default: eu-west-2
        type: string
      aws_role_to_assume:
        description: OIDC role ARN
        required: true
        type: string
      evidence_bucket:
        description: S3 evidence bucket
        required: true
        default: fraud-platform-dev-full-evidence
        type: string
      m12_subphase:
        description: "M12 subphase target (single managed lane)"
        required: true
        default: A
        type: choice
        options:
          - A
          - B
          - C
          - D
          - E
          - F
          - G
          - H
          - I
          - J
      execution_mode:
        description: "Execution mode"
        required: true
        default: materialization_check
        type: choice
        options:
          - materialization_check
          - m12a_execute
          - m12b_execute
          - m12c_execute
          - m12d_execute
      upstream_m11j_execution:
        description: Upstream M11.J execution id (entry readiness ref)
        required: true
        default: m11j_closure_sync_20260227T104756Z
        type: string
      upstream_m12a_execution:
        description: Upstream M12.A execution id (M12.B entry readiness ref)
        required: true
        default: m12a_handle_closure_20260227T121911Z
        type: string
      upstream_m12b_execution:
        description: Upstream M12.B execution id (M12.C entry readiness ref)
        required: true
        default: m12b_candidate_eligibility_20260227T123135Z
        type: string
      upstream_m12c_execution:
        description: Upstream M12.C execution id (M12.D entry readiness ref)
        required: true
        default: m12c_compatibility_precheck_20260227T130306Z
        type: string
      m12_execution_id:
        description: Optional fixed execution id override
        required: false
        default: ""
        type: string

permissions:
  contents: read
  id-token: write

concurrency:
  group: dev-full-m12-managed-${{ github.ref_name }}
  cancel-in-progress: false

jobs:
  run_m12_managed:
    name: Run M12.${{ inputs.m12_subphase }} managed lane
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Validate supported mode and subphase
        shell: bash
        run: |
          set -euo pipefail
          case "${{ inputs.m12_subphase }}" in
            A|B|C|D|E|F|G|H|I|J) ;;
            *)
              echo "Unsupported m12_subphase='${{ inputs.m12_subphase }}'"
              exit 1
              ;;
          esac
          if [[ "${{ inputs.execution_mode }}" != "materialization_check" && "${{ inputs.execution_mode }}" != "m12a_execute" && "${{ inputs.execution_mode }}" != "m12b_execute" && "${{ inputs.execution_mode }}" != "m12c_execute" && "${{ inputs.execution_mode }}" != "m12d_execute" ]]; then
            echo "Unsupported execution_mode='${{ inputs.execution_mode }}'"
            exit 1
          fi
          if [[ "${{ inputs.execution_mode }}" == "m12a_execute" && "${{ inputs.m12_subphase }}" != "A" ]]; then
            echo "execution_mode='m12a_execute' currently supports only m12_subphase='A'."
            exit 1
          fi
          if [[ "${{ inputs.execution_mode }}" == "m12b_execute" && "${{ inputs.m12_subphase }}" != "B" ]]; then
            echo "execution_mode='m12b_execute' currently supports only m12_subphase='B'."
            exit 1
          fi
          if [[ "${{ inputs.execution_mode }}" == "m12c_execute" && "${{ inputs.m12_subphase }}" != "C" ]]; then
            echo "execution_mode='m12c_execute' currently supports only m12_subphase='C'."
            exit 1
          fi
          if [[ "${{ inputs.execution_mode }}" == "m12d_execute" && "${{ inputs.m12_subphase }}" != "D" ]]; then
            echo "execution_mode='m12d_execute' currently supports only m12_subphase='D'."
            exit 1
          fi

      - name: Reject static AWS credential posture
        shell: bash
        run: |
          set -euo pipefail
          if [[ -n "${AWS_ACCESS_KEY_ID:-}" || -n "${AWS_SECRET_ACCESS_KEY:-}" ]]; then
            echo "Static AWS credentials are forbidden; use OIDC role assumption."
            exit 1
          fi

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ inputs.aws_region }}
          role-to-assume: ${{ inputs.aws_role_to_assume }}

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install runtime dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          python -m pip install boto3 botocore

      - name: Compute execution metadata
        id: run_meta
        shell: bash
        run: |
          set -euo pipefail
          TS="$(date -u +'%Y%m%dT%H%M%SZ')"
          if [[ -n "${{ inputs.m12_execution_id }}" ]]; then
            EXEC_ID="${{ inputs.m12_execution_id }}"
          else
            case "${{ inputs.m12_subphase }}" in
              A) EXEC_ID="m12a_handle_closure_${TS}" ;;
              B) EXEC_ID="m12b_candidate_eligibility_${TS}" ;;
              C) EXEC_ID="m12c_compatibility_precheck_${TS}" ;;
              D) EXEC_ID="m12d_promotion_commit_${TS}" ;;
              E) EXEC_ID="m12e_rollback_drill_${TS}" ;;
              F) EXEC_ID="m12f_active_resolution_${TS}" ;;
              G) EXEC_ID="m12g_governance_append_${TS}" ;;
              H) EXEC_ID="m12h_p15_gate_rollup_${TS}" ;;
              I) EXEC_ID="m12i_phase_cost_outcome_${TS}" ;;
              J) EXEC_ID="m12j_closure_sync_${TS}" ;;
            esac
          fi
          echo "execution_id=${EXEC_ID}" >> "$GITHUB_OUTPUT"
          echo "run_dir=runs/dev_substrate/dev_full/m12/${EXEC_ID}" >> "$GITHUB_OUTPUT"

      - name: Execute M12-B0 managed lane materialization check
        if: ${{ inputs.execution_mode == 'materialization_check' }}
        shell: bash
        env:
          EXEC_ID: ${{ steps.run_meta.outputs.execution_id }}
          RUN_DIR: ${{ steps.run_meta.outputs.run_dir }}
          EVIDENCE_BUCKET: ${{ inputs.evidence_bucket }}
          AWS_REGION: ${{ inputs.aws_region }}
          M12_SUBPHASE: ${{ inputs.m12_subphase }}
          EXECUTION_MODE: ${{ inputs.execution_mode }}
          UPSTREAM_M11J_EXEC: ${{ inputs.upstream_m11j_execution }}
        run: |
          set -euo pipefail
          python - <<'PY'
          from __future__ import annotations
          import json
          import os
          from datetime import datetime, timezone
          from pathlib import Path
          from typing import Any

          import boto3
          from botocore.exceptions import BotoCoreError, ClientError

          def now() -> str:
              return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")

          def s3_get_json(s3: Any, bucket: str, key: str) -> dict[str, Any]:
              raw = s3.get_object(Bucket=bucket, Key=key)["Body"].read().decode("utf-8")
              payload = json.loads(raw)
              if not isinstance(payload, dict):
                  raise ValueError("json_not_object")
              return payload

          def s3_put_json(s3: Any, bucket: str, key: str, payload: dict[str, Any]) -> None:
              body = (json.dumps(payload, indent=2, ensure_ascii=True) + "\n").encode("utf-8")
              s3.put_object(Bucket=bucket, Key=key, Body=body, ContentType="application/json")
              s3.head_object(Bucket=bucket, Key=key)

          def dedupe(blockers: list[dict[str, str]]) -> list[dict[str, str]]:
              out: list[dict[str, str]] = []
              seen: set[tuple[str, str]] = set()
              for b in blockers:
                  code = str(b.get("code", "")).strip()
                  msg = str(b.get("message", "")).strip()
                  sig = (code, msg)
                  if sig in seen:
                      continue
                  seen.add(sig)
                  out.append({"code": code, "message": msg})
              return out

          exec_id = os.environ["EXEC_ID"].strip()
          run_dir = Path(os.environ["RUN_DIR"].strip())
          bucket = os.environ["EVIDENCE_BUCKET"].strip()
          region = os.environ.get("AWS_REGION", "eu-west-2").strip() or "eu-west-2"
          subphase = os.environ["M12_SUBPHASE"].strip()
          mode = os.environ["EXECUTION_MODE"].strip()
          upstream_m11j = os.environ["UPSTREAM_M11J_EXEC"].strip()

          s3 = boto3.client("s3", region_name=region)
          blockers: list[dict[str, str]] = []
          read_errors: list[dict[str, str]] = []
          upload_errors: list[dict[str, str]] = []

          supported_subphases = ["A", "B", "C", "D", "E", "F", "G", "H", "I", "J"]
          if subphase not in supported_subphases:
              blockers.append({"code": "M12-B0", "message": f"Unsupported subphase '{subphase}'."})
          if mode != "materialization_check":
              blockers.append({"code": "M12-B0", "message": f"Unsupported execution mode '{mode}'."})

          routing_map = {
              "A": "m12a_handle_closure_<ts>",
              "B": "m12b_candidate_eligibility_<ts>",
              "C": "m12c_compatibility_precheck_<ts>",
              "D": "m12d_promotion_commit_<ts>",
              "E": "m12e_rollback_drill_<ts>",
              "F": "m12f_active_resolution_<ts>",
              "G": "m12g_governance_append_<ts>",
              "H": "m12h_p15_gate_rollup_<ts>",
              "I": "m12i_phase_cost_outcome_<ts>",
              "J": "m12j_closure_sync_<ts>",
          }

          upstream_summary_key = f"evidence/dev_full/run_control/{upstream_m11j}/m11j_execution_summary.json"
          upstream_summary: dict[str, Any] = {}
          try:
              upstream_summary = s3_get_json(s3, bucket, upstream_summary_key)
          except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
              read_errors.append({"surface": upstream_summary_key, "error": type(exc).__name__})
              blockers.append({"code": "M12-B0", "message": "Unreadable M11.J upstream summary."})

          if upstream_summary:
              if not bool(upstream_summary.get("overall_pass", False)):
                  blockers.append({"code": "M12-B0", "message": "M11.J upstream summary overall_pass is false."})
              if str(upstream_summary.get("next_gate", "")).strip() != "M12_READY":
                  blockers.append({"code": "M12-B0", "message": "M11.J upstream summary next_gate is not M12_READY."})

          snapshot = {
              "captured_at_utc": now(),
              "phase": "M12.B0",
              "execution_id": exec_id,
              "mode": mode,
              "requested_subphase": subphase,
              "supported_subphases": supported_subphases,
              "deterministic_execution_routing": routing_map,
              "upstream_m11j_execution": upstream_m11j,
              "upstream_m11j_summary_key": upstream_summary_key,
              "entry_ready": bool(upstream_summary.get("overall_pass", False)) and str(upstream_summary.get("next_gate", "")).strip() == "M12_READY",
              "managed_lane_materialized": True,
          }

          dispatchability = {
              "captured_at_utc": now(),
              "phase": "M12.B0",
              "execution_id": exec_id,
              "requested_subphase": subphase,
              "dispatchable": True,
              "single_workflow_lane": "dev-full-m12-managed",
              "authoritative_path": "managed_only",
          }

          blocker_register = {
              "captured_at_utc": now(),
              "phase": "M12.B0",
              "execution_id": exec_id,
              "blocker_count": 0,
              "blockers": [],
              "overall_pass": False,
          }

          execution_summary = {
              "captured_at_utc": now(),
              "phase": "M12.B0",
              "execution_id": exec_id,
              "requested_subphase": subphase,
              "overall_pass": False,
              "blocker_count": 0,
              "verdict": "HOLD_REMEDIATE",
              "next_gate": "HOLD_REMEDIATE",
              "artifact_keys": {},
          }

          artifacts = {
              "m12_managed_lane_materialization_snapshot.json": snapshot,
              "m12_subphase_dispatchability_snapshot.json": dispatchability,
              "m12b0_blocker_register.json": blocker_register,
              "m12b0_execution_summary.json": execution_summary,
          }

          run_dir.mkdir(parents=True, exist_ok=True)
          for fname, payload in artifacts.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")

          run_control_prefix = f"evidence/dev_full/run_control/{exec_id}/"
          for fname, payload in artifacts.items():
              try:
                  s3_put_json(s3, bucket, run_control_prefix + fname, payload)
              except (BotoCoreError, ClientError) as exc:
                  upload_errors.append({"surface": run_control_prefix + fname, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B0", "message": f"Failed to publish {fname}."})

          blockers = dedupe(blockers)
          overall_pass = len(blockers) == 0
          verdict = "ADVANCE_TO_M12_A" if overall_pass else "HOLD_REMEDIATE"
          next_gate = "M12.A_READY" if overall_pass else "HOLD_REMEDIATE"
          blocker_register["blocker_count"] = len(blockers)
          blocker_register["blockers"] = blockers
          blocker_register["overall_pass"] = overall_pass
          execution_summary["overall_pass"] = overall_pass
          execution_summary["blocker_count"] = len(blockers)
          execution_summary["verdict"] = verdict
          execution_summary["next_gate"] = next_gate
          execution_summary["artifact_keys"] = {
              "m12_managed_lane_materialization_snapshot": run_control_prefix + "m12_managed_lane_materialization_snapshot.json",
              "m12_subphase_dispatchability_snapshot": run_control_prefix + "m12_subphase_dispatchability_snapshot.json",
              "m12b0_blocker_register": run_control_prefix + "m12b0_blocker_register.json",
              "m12b0_execution_summary": run_control_prefix + "m12b0_execution_summary.json",
          }
          execution_summary["read_errors"] = read_errors
          execution_summary["upload_errors"] = upload_errors

          for fname, payload in {
              "m12b0_blocker_register.json": blocker_register,
              "m12b0_execution_summary.json": execution_summary,
          }.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")
              try:
                  s3_put_json(s3, bucket, run_control_prefix + fname, payload)
              except Exception:
                  pass

          print(
              json.dumps(
                  {
                      "execution_id": exec_id,
                      "requested_subphase": subphase,
                      "overall_pass": overall_pass,
                      "blocker_count": len(blockers),
                      "next_gate": next_gate,
                      "verdict": verdict,
                      "evidence_prefix": f"s3://{bucket}/{run_control_prefix}",
                  },
                  indent=2,
                  ensure_ascii=True,
              )
          )
          if not overall_pass:
              raise SystemExit(1)
          PY

      - name: Execute M12.A handle closure (managed)
        if: ${{ inputs.execution_mode == 'm12a_execute' && inputs.m12_subphase == 'A' }}
        shell: bash
        env:
          EXEC_ID: ${{ steps.run_meta.outputs.execution_id }}
          RUN_DIR: ${{ steps.run_meta.outputs.run_dir }}
          EVIDENCE_BUCKET: ${{ inputs.evidence_bucket }}
          AWS_REGION: ${{ inputs.aws_region }}
          UPSTREAM_M11J_EXEC: ${{ inputs.upstream_m11j_execution }}
        run: |
          set -euo pipefail
          python - <<'PY'
          from __future__ import annotations
          import json
          import os
          import re
          from datetime import datetime, timezone
          from pathlib import Path
          from typing import Any

          import boto3
          from botocore.exceptions import BotoCoreError, ClientError

          def now() -> str:
              return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")

          def s3_get_json(s3: Any, bucket: str, key: str) -> dict[str, Any]:
              raw = s3.get_object(Bucket=bucket, Key=key)["Body"].read().decode("utf-8")
              payload = json.loads(raw)
              if not isinstance(payload, dict):
                  raise ValueError("json_not_object")
              return payload

          def s3_put_json(s3: Any, bucket: str, key: str, payload: dict[str, Any]) -> None:
              body = (json.dumps(payload, indent=2, ensure_ascii=True) + "\n").encode("utf-8")
              s3.put_object(Bucket=bucket, Key=key, Body=body, ContentType="application/json")
              s3.head_object(Bucket=bucket, Key=key)

          def dedupe(blockers: list[dict[str, str]]) -> list[dict[str, str]]:
              out: list[dict[str, str]] = []
              seen: set[tuple[str, str]] = set()
              for b in blockers:
                  code = str(b.get("code", "")).strip()
                  msg = str(b.get("message", "")).strip()
                  sig = (code, msg)
                  if sig in seen:
                      continue
                  seen.add(sig)
                  out.append({"code": code, "message": msg})
              return out

          def parse_handles(path: Path) -> dict[str, str]:
              rx = re.compile(r"^\*\s+`([A-Z0-9_]+)\s*=\s*(.+)`\s*$")
              out: dict[str, str] = {}
              for line in path.read_text(encoding="utf-8").splitlines():
                  m = rx.match(line.strip())
                  if not m:
                      continue
                  key = m.group(1).strip()
                  raw = m.group(2).strip()
                  if (raw.startswith('"') and raw.endswith('"')) or (raw.startswith("'") and raw.endswith("'")):
                      out[key] = raw[1:-1]
                  else:
                      out[key] = raw
              return out

          exec_id = os.environ["EXEC_ID"].strip()
          run_dir = Path(os.environ["RUN_DIR"].strip())
          bucket = os.environ["EVIDENCE_BUCKET"].strip()
          region = os.environ.get("AWS_REGION", "eu-west-2").strip() or "eu-west-2"
          upstream_m11j = os.environ["UPSTREAM_M11J_EXEC"].strip()

          s3 = boto3.client("s3", region_name=region)
          blockers: list[dict[str, str]] = []
          read_errors: list[dict[str, str]] = []
          upload_errors: list[dict[str, str]] = []

          upstream_key = f"evidence/dev_full/run_control/{upstream_m11j}/m11j_execution_summary.json"
          upstream_summary: dict[str, Any] = {}
          try:
              upstream_summary = s3_get_json(s3, bucket, upstream_key)
          except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
              read_errors.append({"surface": upstream_key, "error": type(exc).__name__})
              blockers.append({"code": "M12-B1", "message": "Unreadable M11.J upstream summary."})

          platform_run_id = ""
          scenario_run_id = ""
          if upstream_summary:
              platform_run_id = str(upstream_summary.get("platform_run_id", "")).strip()
              scenario_run_id = str(upstream_summary.get("scenario_run_id", "")).strip()
              if not bool(upstream_summary.get("overall_pass", False)):
                  blockers.append({"code": "M12-B1", "message": "M11.J upstream summary overall_pass is false."})
              try:
                  blocker_count = int(str(upstream_summary.get("blocker_count", "")).strip())
              except Exception:
                  blocker_count = -1
              if blocker_count != 0:
                  blockers.append({"code": "M12-B1", "message": "M11.J upstream blocker_count is not zero."})
              if str(upstream_summary.get("next_gate", "")).strip() != "M12_READY":
                  blockers.append({"code": "M12-B1", "message": "M11.J upstream next_gate is not M12_READY."})
              if not platform_run_id or not scenario_run_id:
                  blockers.append({"code": "M12-B1", "message": "M11.J upstream run scope is incomplete."})

          required_handles = [
              "MPR_PROMOTION_RECEIPT_PATH_PATTERN",
              "MPR_ROLLBACK_DRILL_PATH_PATTERN",
              "FP_BUS_LEARNING_REGISTRY_EVENTS_V1",
              "GOV_APPEND_LOG_PATH_PATTERN",
              "GOV_RUN_CLOSE_MARKER_PATH_PATTERN",
              "MF_CANDIDATE_BUNDLE_PATH_PATTERN",
              "PHASE_BUDGET_ENVELOPE_PATH_PATTERN",
              "PHASE_COST_OUTCOME_RECEIPT_PATH_PATTERN",
          ]
          handles_path = Path("docs/model_spec/platform/migration_to_dev/dev_full_handles.registry.v0.md")
          handles: dict[str, str] = {}
          try:
              handles = parse_handles(handles_path)
          except Exception as exc:
              blockers.append({"code": "M12-B1", "message": f"Unable to parse handles registry: {type(exc).__name__}."})

          resolved_handles: dict[str, str] = {}
          unresolved: list[str] = []
          for key in required_handles:
              value = str(handles.get(key, "")).strip()
              resolved_handles[key] = value
              if (not value) or (value.upper() == "TO_PIN"):
                  unresolved.append(key)
          if unresolved:
              blockers.append({"code": "M12-B1", "message": f"Unresolved required handles: {', '.join(unresolved)}."})

          handle_snapshot = {
              "captured_at_utc": now(),
              "phase": "M12.A",
              "execution_id": exec_id,
              "platform_run_id": platform_run_id,
              "scenario_run_id": scenario_run_id,
              "upstream_m11j_execution": upstream_m11j,
              "upstream_summary_key": upstream_key,
              "required_handles": required_handles,
              "resolved_handles": resolved_handles,
              "unresolved_handles": unresolved,
              "handle_matrix_complete": len(unresolved) == 0,
          }

          blocker_register = {
              "captured_at_utc": now(),
              "phase": "M12.A",
              "phase_id": "P15",
              "execution_id": exec_id,
              "blocker_count": 0,
              "blockers": [],
              "overall_pass": False,
          }

          execution_summary = {
              "captured_at_utc": now(),
              "phase": "M12.A",
              "phase_id": "P15",
              "execution_id": exec_id,
              "platform_run_id": platform_run_id,
              "scenario_run_id": scenario_run_id,
              "overall_pass": False,
              "blocker_count": 0,
              "verdict": "HOLD_REMEDIATE",
              "next_gate": "HOLD_REMEDIATE",
              "upstream_refs": {"m11j_execution_id": upstream_m11j},
              "artifact_keys": {},
          }

          artifacts = {
              "m12a_handle_closure_snapshot.json": handle_snapshot,
              "m12a_blocker_register.json": blocker_register,
              "m12a_execution_summary.json": execution_summary,
          }

          run_dir.mkdir(parents=True, exist_ok=True)
          for fname, payload in artifacts.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")

          run_control_prefix = f"evidence/dev_full/run_control/{exec_id}/"
          for fname, payload in artifacts.items():
              try:
                  s3_put_json(s3, bucket, run_control_prefix + fname, payload)
              except (BotoCoreError, ClientError) as exc:
                  upload_errors.append({"surface": run_control_prefix + fname, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B1", "message": f"Failed to publish {fname}."})

          blockers = dedupe(blockers)
          overall_pass = len(blockers) == 0
          verdict = "ADVANCE_TO_M12_B" if overall_pass else "HOLD_REMEDIATE"
          next_gate = "M12.B_READY" if overall_pass else "HOLD_REMEDIATE"
          blocker_register["blocker_count"] = len(blockers)
          blocker_register["blockers"] = blockers
          blocker_register["overall_pass"] = overall_pass
          execution_summary["overall_pass"] = overall_pass
          execution_summary["blocker_count"] = len(blockers)
          execution_summary["verdict"] = verdict
          execution_summary["next_gate"] = next_gate
          execution_summary["artifact_keys"] = {
              "m12a_handle_closure_snapshot": run_control_prefix + "m12a_handle_closure_snapshot.json",
              "m12a_blocker_register": run_control_prefix + "m12a_blocker_register.json",
              "m12a_execution_summary": run_control_prefix + "m12a_execution_summary.json",
          }
          execution_summary["read_errors"] = read_errors
          execution_summary["upload_errors"] = upload_errors

          for fname, payload in {
              "m12a_blocker_register.json": blocker_register,
              "m12a_execution_summary.json": execution_summary,
          }.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")
              try:
                  s3_put_json(s3, bucket, run_control_prefix + fname, payload)
              except Exception:
                  pass

          print(
              json.dumps(
                  {
                      "execution_id": exec_id,
                      "overall_pass": overall_pass,
                      "blocker_count": len(blockers),
                      "next_gate": next_gate,
                      "verdict": verdict,
                      "evidence_prefix": f"s3://{bucket}/{run_control_prefix}",
                  },
                  indent=2,
                  ensure_ascii=True,
              )
          )
          if not overall_pass:
              raise SystemExit(1)
          PY

      - name: Execute M12.B candidate eligibility precheck (managed)
        if: ${{ inputs.execution_mode == 'm12b_execute' && inputs.m12_subphase == 'B' }}
        shell: bash
        env:
          EXEC_ID: ${{ steps.run_meta.outputs.execution_id }}
          RUN_DIR: ${{ steps.run_meta.outputs.run_dir }}
          EVIDENCE_BUCKET: ${{ inputs.evidence_bucket }}
          AWS_REGION: ${{ inputs.aws_region }}
          UPSTREAM_M12A_EXEC: ${{ inputs.upstream_m12a_execution }}
        run: |
          set -euo pipefail
          python - <<'PY'
          from __future__ import annotations
          import json
          import os
          from datetime import datetime, timezone
          from pathlib import Path
          from typing import Any

          import boto3
          from botocore.exceptions import BotoCoreError, ClientError

          def now() -> str:
              return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")

          def s3_get_json(s3: Any, bucket: str, key: str) -> dict[str, Any]:
              raw = s3.get_object(Bucket=bucket, Key=key)["Body"].read().decode("utf-8")
              payload = json.loads(raw)
              if not isinstance(payload, dict):
                  raise ValueError("json_not_object")
              return payload

          def s3_put_json(s3: Any, bucket: str, key: str, payload: dict[str, Any]) -> None:
              body = (json.dumps(payload, indent=2, ensure_ascii=True) + "\n").encode("utf-8")
              s3.put_object(Bucket=bucket, Key=key, Body=body, ContentType="application/json")
              s3.head_object(Bucket=bucket, Key=key)

          def s3_parse_uri(uri: str) -> tuple[str, str]:
              if not uri.startswith("s3://"):
                  raise ValueError("not_s3_uri")
              tail = uri[5:]
              if "/" not in tail:
                  raise ValueError("missing_key")
              bucket, key = tail.split("/", 1)
              if not bucket or not key:
                  raise ValueError("incomplete_s3_uri")
              return bucket, key

          def dedupe(blockers: list[dict[str, str]]) -> list[dict[str, str]]:
              out: list[dict[str, str]] = []
              seen: set[tuple[str, str]] = set()
              for b in blockers:
                  code = str(b.get("code", "")).strip()
                  msg = str(b.get("message", "")).strip()
                  sig = (code, msg)
                  if sig in seen:
                      continue
                  seen.add(sig)
                  out.append({"code": code, "message": msg})
              return out

          exec_id = os.environ["EXEC_ID"].strip()
          run_dir = Path(os.environ["RUN_DIR"].strip())
          default_bucket = os.environ["EVIDENCE_BUCKET"].strip()
          region = os.environ.get("AWS_REGION", "eu-west-2").strip() or "eu-west-2"
          upstream_m12a = os.environ["UPSTREAM_M12A_EXEC"].strip()

          s3 = boto3.client("s3", region_name=region)
          blockers: list[dict[str, str]] = []
          read_errors: list[dict[str, str]] = []
          upload_errors: list[dict[str, str]] = []

          m12a_summary_key = f"evidence/dev_full/run_control/{upstream_m12a}/m12a_execution_summary.json"
          m12a_summary: dict[str, Any] = {}
          try:
              m12a_summary = s3_get_json(s3, default_bucket, m12a_summary_key)
          except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
              read_errors.append({"surface": m12a_summary_key, "error": type(exc).__name__})
              blockers.append({"code": "M12-B2", "message": "Unreadable M12.A execution summary."})

          platform_run_id = ""
          scenario_run_id = ""
          upstream_m11j = ""
          if m12a_summary:
              platform_run_id = str(m12a_summary.get("platform_run_id", "")).strip()
              scenario_run_id = str(m12a_summary.get("scenario_run_id", "")).strip()
              upstream_m11j = str((m12a_summary.get("upstream_refs") or {}).get("m11j_execution_id", "")).strip()
              if not bool(m12a_summary.get("overall_pass", False)):
                  blockers.append({"code": "M12-B2", "message": "M12.A overall_pass is false."})
              try:
                  m12a_blocker_count = int(str(m12a_summary.get("blocker_count", "")).strip())
              except Exception:
                  m12a_blocker_count = -1
              if m12a_blocker_count != 0:
                  blockers.append({"code": "M12-B2", "message": "M12.A blocker_count is not zero."})
              if str(m12a_summary.get("next_gate", "")).strip() != "M12.B_READY":
                  blockers.append({"code": "M12-B2", "message": "M12.A next_gate is not M12.B_READY."})
              if not platform_run_id or not scenario_run_id:
                  blockers.append({"code": "M12-B2", "message": "M12.A run scope is incomplete."})
              if not upstream_m11j:
                  blockers.append({"code": "M12-B2", "message": "M12.A upstream m11j_execution_id is missing."})

          m11j_summary_key = f"evidence/dev_full/run_control/{upstream_m11j}/m11j_execution_summary.json" if upstream_m11j else ""
          m11j_summary: dict[str, Any] = {}
          if m11j_summary_key:
              try:
                  m11j_summary = s3_get_json(s3, default_bucket, m11j_summary_key)
              except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
                  read_errors.append({"surface": m11j_summary_key, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B2", "message": "Unreadable M11.J execution summary."})

          upstream_m11i = ""
          if m11j_summary:
              if not bool(m11j_summary.get("overall_pass", False)):
                  blockers.append({"code": "M12-B2", "message": "M11.J overall_pass is false."})
              if str(m11j_summary.get("next_gate", "")).strip() != "M12_READY":
                  blockers.append({"code": "M12-B2", "message": "M11.J next_gate is not M12_READY."})
              upstream_m11i = str((m11j_summary.get("upstream_refs") or {}).get("m11i_execution_id", "")).strip()
              if not upstream_m11i:
                  blockers.append({"code": "M12-B2", "message": "M11.J upstream m11i_execution_id is missing."})

          handoff_key = f"evidence/dev_full/run_control/{upstream_m11i}/m12_handoff_pack.json" if upstream_m11i else ""
          handoff_pack: dict[str, Any] = {}
          if handoff_key:
              try:
                  handoff_pack = s3_get_json(s3, default_bucket, handoff_key)
              except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
                  read_errors.append({"surface": handoff_key, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B2", "message": "Unreadable m12_handoff_pack.json from M11.I."})

          if handoff_pack:
              hp_platform_run = str(handoff_pack.get("platform_run_id", "")).strip()
              hp_scenario_run = str(handoff_pack.get("scenario_run_id", "")).strip()
              if hp_platform_run != platform_run_id or hp_scenario_run != scenario_run_id:
                  blockers.append({"code": "M12-B2", "message": "Run-scope mismatch between M12.A and M11.I handoff pack."})

          required_ref_keys = [
              "mf_candidate_bundle_ref",
              "m11_model_operability_report_ref",
              "m11_eval_report_ref",
              "m11_eval_vs_baseline_report_ref",
              "mf_leakage_provenance_check_ref",
              "m11_reproducibility_check_ref",
              "m11f_mlflow_lineage_snapshot_ref",
          ]
          handoff_required_refs = handoff_pack.get("required_refs") if isinstance(handoff_pack.get("required_refs"), dict) else {}
          missing_required_refs: list[str] = []
          readable_ref_report: dict[str, dict[str, Any]] = {}
          loaded_refs: dict[str, dict[str, Any]] = {}
          for ref_key in required_ref_keys:
              ref_value = str(handoff_required_refs.get(ref_key, "")).strip()
              ref_state = {"ref": ref_value, "readable": False, "error": ""}
              if not ref_value:
                  missing_required_refs.append(ref_key)
                  ref_state["error"] = "missing_ref"
                  readable_ref_report[ref_key] = ref_state
                  continue
              try:
                  ref_bucket, ref_key_path = s3_parse_uri(ref_value)
                  ref_payload = s3_get_json(s3, ref_bucket, ref_key_path)
                  ref_state["readable"] = True
                  loaded_refs[ref_key] = ref_payload
              except Exception as exc:
                  ref_state["error"] = type(exc).__name__
                  read_errors.append({"surface": ref_value, "error": type(exc).__name__})
              readable_ref_report[ref_key] = ref_state

          if missing_required_refs:
              blockers.append({"code": "M12-B2", "message": f"Missing required handoff refs: {', '.join(missing_required_refs)}."})

          unreadable_refs = [k for k, v in readable_ref_report.items() if not bool(v.get("readable", False))]
          if unreadable_refs:
              blockers.append({"code": "M12-B2", "message": f"Unreadable required refs: {', '.join(unreadable_refs)}."})

          candidate_bundle = loaded_refs.get("mf_candidate_bundle_ref", {})
          candidate_checks = {
              "present": bool(candidate_bundle),
              "bundle_status_candidate": False,
              "run_scope_match": False,
              "required_fields_present": False,
              "eval_gate_results_all_true": False,
              "lineage_fields_present": False,
          }
          required_candidate_fields = [
              "bundle_id",
              "bundle_status",
              "model",
              "metrics",
              "lineage",
              "rollback_pointers",
              "platform_run_id",
              "scenario_run_id",
          ]
          missing_candidate_fields: list[str] = []
          if candidate_bundle:
              candidate_checks["bundle_status_candidate"] = str(candidate_bundle.get("bundle_status", "")).strip() == "CANDIDATE"
              candidate_checks["run_scope_match"] = (
                  str(candidate_bundle.get("platform_run_id", "")).strip() == platform_run_id
                  and str(candidate_bundle.get("scenario_run_id", "")).strip() == scenario_run_id
              )
              for key in required_candidate_fields:
                  v = candidate_bundle.get(key)
                  if v is None:
                      missing_candidate_fields.append(key)
                  elif isinstance(v, str) and not v.strip():
                      missing_candidate_fields.append(key)
              candidate_checks["required_fields_present"] = len(missing_candidate_fields) == 0
              eval_gate = ((candidate_bundle.get("metrics") or {}).get("eval_gate_results")) if isinstance(candidate_bundle.get("metrics"), dict) else None
              if isinstance(eval_gate, dict):
                  gate_keys = ["compatibility", "leakage", "performance", "stability"]
                  candidate_checks["eval_gate_results_all_true"] = all(bool(eval_gate.get(k, False)) for k in gate_keys)
              lineage = candidate_bundle.get("lineage") if isinstance(candidate_bundle.get("lineage"), dict) else {}
              lineage_keys = ["m11d_execution_id", "m11e_execution_id", "m11f_execution_id", "mlflow_run_id"]
              candidate_checks["lineage_fields_present"] = all(bool(str(lineage.get(k, "")).strip()) for k in lineage_keys)

          if not candidate_checks["present"]:
              blockers.append({"code": "M12-B2", "message": "Candidate bundle is unreadable."})
          if candidate_bundle and not candidate_checks["bundle_status_candidate"]:
              blockers.append({"code": "M12-B2", "message": "Candidate bundle status is not CANDIDATE."})
          if candidate_bundle and not candidate_checks["run_scope_match"]:
              blockers.append({"code": "M12-B2", "message": "Candidate bundle run scope mismatches M12 run scope."})
          if candidate_bundle and not candidate_checks["required_fields_present"]:
              blockers.append({"code": "M12-B2", "message": f"Candidate bundle missing required fields: {', '.join(missing_candidate_fields)}."})
          if candidate_bundle and not candidate_checks["eval_gate_results_all_true"]:
              blockers.append({"code": "M12-B2", "message": "Candidate bundle eval gate results are not all true."})
          if candidate_bundle and not candidate_checks["lineage_fields_present"]:
              blockers.append({"code": "M12-B2", "message": "Candidate bundle lineage fields are incomplete."})

          eligibility_snapshot = {
              "captured_at_utc": now(),
              "phase": "M12.B",
              "phase_id": "P15",
              "execution_id": exec_id,
              "platform_run_id": platform_run_id,
              "scenario_run_id": scenario_run_id,
              "upstream_refs": {
                  "m12a_execution_id": upstream_m12a,
                  "m12a_execution_summary_key": m12a_summary_key,
                  "m11j_execution_id": upstream_m11j,
                  "m11j_execution_summary_key": m11j_summary_key,
                  "m11i_execution_id": upstream_m11i,
                  "m12_handoff_pack_key": handoff_key,
              },
              "required_handoff_refs": required_ref_keys,
              "readable_ref_report": readable_ref_report,
              "candidate_checks": candidate_checks,
              "missing_candidate_fields": missing_candidate_fields,
              "candidate_bundle_bundle_id": str(candidate_bundle.get("bundle_id", "")).strip() if candidate_bundle else "",
          }

          blocker_register = {
              "captured_at_utc": now(),
              "phase": "M12.B",
              "phase_id": "P15",
              "execution_id": exec_id,
              "blocker_count": 0,
              "blockers": [],
              "overall_pass": False,
          }

          execution_summary = {
              "captured_at_utc": now(),
              "phase": "M12.B",
              "phase_id": "P15",
              "execution_id": exec_id,
              "platform_run_id": platform_run_id,
              "scenario_run_id": scenario_run_id,
              "overall_pass": False,
              "blocker_count": 0,
              "verdict": "HOLD_REMEDIATE",
              "next_gate": "HOLD_REMEDIATE",
              "upstream_refs": {
                  "m12a_execution_id": upstream_m12a,
                  "m11j_execution_id": upstream_m11j,
                  "m11i_execution_id": upstream_m11i,
              },
              "artifact_keys": {},
          }

          artifacts = {
              "m12b_candidate_eligibility_snapshot.json": eligibility_snapshot,
              "m12b_blocker_register.json": blocker_register,
              "m12b_execution_summary.json": execution_summary,
          }

          run_dir.mkdir(parents=True, exist_ok=True)
          for fname, payload in artifacts.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")

          run_control_prefix = f"evidence/dev_full/run_control/{exec_id}/"
          for fname, payload in artifacts.items():
              try:
                  s3_put_json(s3, default_bucket, run_control_prefix + fname, payload)
              except (BotoCoreError, ClientError) as exc:
                  upload_errors.append({"surface": run_control_prefix + fname, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B2", "message": f"Failed to publish {fname}."})

          blockers = dedupe(blockers)
          overall_pass = len(blockers) == 0
          verdict = "ADVANCE_TO_M12_C" if overall_pass else "HOLD_REMEDIATE"
          next_gate = "M12.C_READY" if overall_pass else "HOLD_REMEDIATE"
          blocker_register["blocker_count"] = len(blockers)
          blocker_register["blockers"] = blockers
          blocker_register["overall_pass"] = overall_pass
          execution_summary["overall_pass"] = overall_pass
          execution_summary["blocker_count"] = len(blockers)
          execution_summary["verdict"] = verdict
          execution_summary["next_gate"] = next_gate
          execution_summary["artifact_keys"] = {
              "m12b_candidate_eligibility_snapshot": run_control_prefix + "m12b_candidate_eligibility_snapshot.json",
              "m12b_blocker_register": run_control_prefix + "m12b_blocker_register.json",
              "m12b_execution_summary": run_control_prefix + "m12b_execution_summary.json",
          }
          execution_summary["read_errors"] = read_errors
          execution_summary["upload_errors"] = upload_errors

          for fname, payload in {
              "m12b_blocker_register.json": blocker_register,
              "m12b_execution_summary.json": execution_summary,
          }.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")
              try:
                  s3_put_json(s3, default_bucket, run_control_prefix + fname, payload)
              except Exception:
                  pass

          print(
              json.dumps(
                  {
                      "execution_id": exec_id,
                      "overall_pass": overall_pass,
                      "blocker_count": len(blockers),
                      "next_gate": next_gate,
                      "verdict": verdict,
                      "evidence_prefix": f"s3://{default_bucket}/{run_control_prefix}",
                  },
                  indent=2,
                  ensure_ascii=True,
              )
          )
          if not overall_pass:
              raise SystemExit(1)
          PY

      - name: Execute M12.C compatibility prechecks (managed)
        if: ${{ inputs.execution_mode == 'm12c_execute' && inputs.m12_subphase == 'C' }}
        shell: bash
        env:
          EXEC_ID: ${{ steps.run_meta.outputs.execution_id }}
          RUN_DIR: ${{ steps.run_meta.outputs.run_dir }}
          EVIDENCE_BUCKET: ${{ inputs.evidence_bucket }}
          AWS_REGION: ${{ inputs.aws_region }}
          UPSTREAM_M12B_EXEC: ${{ inputs.upstream_m12b_execution }}
        run: |
          set -euo pipefail
          python - <<'PY'
          from __future__ import annotations
          import json
          import os
          import re
          from datetime import datetime, timezone
          from pathlib import Path
          from typing import Any

          import boto3
          from botocore.exceptions import BotoCoreError, ClientError

          def now() -> str:
              return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")

          def s3_get_json(s3: Any, bucket: str, key: str) -> dict[str, Any]:
              raw = s3.get_object(Bucket=bucket, Key=key)["Body"].read().decode("utf-8")
              payload = json.loads(raw)
              if not isinstance(payload, dict):
                  raise ValueError("json_not_object")
              return payload

          def s3_put_json(s3: Any, bucket: str, key: str, payload: dict[str, Any]) -> None:
              body = (json.dumps(payload, indent=2, ensure_ascii=True) + "\n").encode("utf-8")
              s3.put_object(Bucket=bucket, Key=key, Body=body, ContentType="application/json")
              s3.head_object(Bucket=bucket, Key=key)

          def s3_parse_uri(uri: str) -> tuple[str, str]:
              if not uri.startswith("s3://"):
                  raise ValueError("not_s3_uri")
              tail = uri[5:]
              if "/" not in tail:
                  raise ValueError("missing_key")
              bucket, key = tail.split("/", 1)
              if not bucket or not key:
                  raise ValueError("incomplete_s3_uri")
              return bucket, key

          def parse_handles(path: Path) -> dict[str, str]:
              rx = re.compile(r"^\*\s+`([A-Z0-9_]+)\s*=\s*(.+)`\s*$")
              out: dict[str, str] = {}
              for line in path.read_text(encoding="utf-8").splitlines():
                  m = rx.match(line.strip())
                  if not m:
                      continue
                  key = m.group(1).strip()
                  raw = m.group(2).strip()
                  if (raw.startswith('"') and raw.endswith('"')) or (raw.startswith("'") and raw.endswith("'")):
                      out[key] = raw[1:-1]
                  else:
                      out[key] = raw
              return out

          def dedupe(blockers: list[dict[str, str]]) -> list[dict[str, str]]:
              out: list[dict[str, str]] = []
              seen: set[tuple[str, str]] = set()
              for b in blockers:
                  code = str(b.get("code", "")).strip()
                  msg = str(b.get("message", "")).strip()
                  sig = (code, msg)
                  if sig in seen:
                      continue
                  seen.add(sig)
                  out.append({"code": code, "message": msg})
              return out

          exec_id = os.environ["EXEC_ID"].strip()
          run_dir = Path(os.environ["RUN_DIR"].strip())
          default_bucket = os.environ["EVIDENCE_BUCKET"].strip()
          region = os.environ.get("AWS_REGION", "eu-west-2").strip() or "eu-west-2"
          upstream_m12b = os.environ["UPSTREAM_M12B_EXEC"].strip()

          s3 = boto3.client("s3", region_name=region)
          blockers: list[dict[str, str]] = []
          read_errors: list[dict[str, str]] = []
          upload_errors: list[dict[str, str]] = []

          m12b_summary_key = f"evidence/dev_full/run_control/{upstream_m12b}/m12b_execution_summary.json"
          m12b_snapshot_key = f"evidence/dev_full/run_control/{upstream_m12b}/m12b_candidate_eligibility_snapshot.json"
          m12b_summary: dict[str, Any] = {}
          m12b_snapshot: dict[str, Any] = {}
          try:
              m12b_summary = s3_get_json(s3, default_bucket, m12b_summary_key)
          except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
              read_errors.append({"surface": m12b_summary_key, "error": type(exc).__name__})
              blockers.append({"code": "M12-B3", "message": "Unreadable M12.B execution summary."})
          try:
              m12b_snapshot = s3_get_json(s3, default_bucket, m12b_snapshot_key)
          except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
              read_errors.append({"surface": m12b_snapshot_key, "error": type(exc).__name__})
              blockers.append({"code": "M12-B3", "message": "Unreadable M12.B eligibility snapshot."})

          platform_run_id = ""
          scenario_run_id = ""
          upstream_m11i = ""
          if m12b_summary:
              platform_run_id = str(m12b_summary.get("platform_run_id", "")).strip()
              scenario_run_id = str(m12b_summary.get("scenario_run_id", "")).strip()
              upstream_m11i = str((m12b_summary.get("upstream_refs") or {}).get("m11i_execution_id", "")).strip()
              if not bool(m12b_summary.get("overall_pass", False)):
                  blockers.append({"code": "M12-B3", "message": "M12.B overall_pass is false."})
              try:
                  m12b_blocker_count = int(str(m12b_summary.get("blocker_count", "")).strip())
              except Exception:
                  m12b_blocker_count = -1
              if m12b_blocker_count != 0:
                  blockers.append({"code": "M12-B3", "message": "M12.B blocker_count is not zero."})
              if str(m12b_summary.get("next_gate", "")).strip() != "M12.C_READY":
                  blockers.append({"code": "M12-B3", "message": "M12.B next_gate is not M12.C_READY."})
              if not platform_run_id or not scenario_run_id:
                  blockers.append({"code": "M12-B3", "message": "M12.B run scope is incomplete."})
              if not upstream_m11i:
                  blockers.append({"code": "M12-B3", "message": "M12.B upstream m11i_execution_id is missing."})

          handoff_key = f"evidence/dev_full/run_control/{upstream_m11i}/m12_handoff_pack.json" if upstream_m11i else ""
          handoff_pack: dict[str, Any] = {}
          if handoff_key:
              try:
                  handoff_pack = s3_get_json(s3, default_bucket, handoff_key)
              except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
                  read_errors.append({"surface": handoff_key, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B3", "message": "Unreadable M11.I m12_handoff_pack.json."})

          required_refs = handoff_pack.get("required_refs") if isinstance(handoff_pack.get("required_refs"), dict) else {}
          candidate_ref = str(required_refs.get("mf_candidate_bundle_ref", "")).strip()
          eval_gate_ref = str(required_refs.get("m11_eval_vs_baseline_report_ref", "")).strip()
          if not candidate_ref:
              blockers.append({"code": "M12-B3", "message": "Handoff missing mf_candidate_bundle_ref."})
          if not eval_gate_ref:
              blockers.append({"code": "M12-B3", "message": "Handoff missing m11_eval_vs_baseline_report_ref."})

          candidate_bundle: dict[str, Any] = {}
          if candidate_ref:
              try:
                  cb_bucket, cb_key = s3_parse_uri(candidate_ref)
                  candidate_bundle = s3_get_json(s3, cb_bucket, cb_key)
              except Exception as exc:
                  read_errors.append({"surface": candidate_ref, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B3", "message": "Candidate bundle is unreadable for compatibility checks."})

          feature_contract_checks = {
              "fingerprint_ref_present": False,
              "fingerprint_readable": False,
              "fingerprint_required_fields_present": False,
              "fingerprint_join_scope_matches_run": False,
          }
          fingerprint_required_fields = ["replay_basis", "feature_asof_utc", "label_asof_utc", "feature_def_set"]
          fingerprint_missing_fields: list[str] = []
          dataset_fingerprint_ref = ""
          dataset_fingerprint: dict[str, Any] = {}
          if candidate_bundle:
              dataset_fingerprint_ref = str((candidate_bundle.get("lineage") or {}).get("m10g_fingerprint_ref", "")).strip()
              feature_contract_checks["fingerprint_ref_present"] = bool(dataset_fingerprint_ref)
              if not dataset_fingerprint_ref:
                  blockers.append({"code": "M12-B3", "message": "Candidate bundle is missing lineage.m10g_fingerprint_ref."})
          if dataset_fingerprint_ref:
              try:
                  fp_bucket, fp_key = s3_parse_uri(dataset_fingerprint_ref)
                  dataset_fingerprint = s3_get_json(s3, fp_bucket, fp_key)
                  feature_contract_checks["fingerprint_readable"] = True
              except Exception as exc:
                  read_errors.append({"surface": dataset_fingerprint_ref, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B3", "message": "Dataset fingerprint is unreadable."})
          if dataset_fingerprint:
              req_values = dataset_fingerprint.get("required_field_values") if isinstance(dataset_fingerprint.get("required_field_values"), dict) else {}
              for k in fingerprint_required_fields:
                  v = req_values.get(k)
                  if v is None or (isinstance(v, str) and not v.strip()):
                      fingerprint_missing_fields.append(k)
              feature_contract_checks["fingerprint_required_fields_present"] = len(fingerprint_missing_fields) == 0
              if fingerprint_missing_fields:
                  blockers.append({"code": "M12-B3", "message": f"Dataset fingerprint missing required_field_values: {', '.join(fingerprint_missing_fields)}."})
              join_scope = str(req_values.get("join_scope", "")).strip()
              feature_contract_checks["fingerprint_join_scope_matches_run"] = (
                  f"platform_run_id={platform_run_id}" in join_scope and f"scenario_run_id={scenario_run_id}" in join_scope
              )
              if not feature_contract_checks["fingerprint_join_scope_matches_run"]:
                  blockers.append({"code": "M12-B3", "message": "Dataset fingerprint join_scope does not match M12 run scope."})

          policy_degrade_checks = {
              "m11_eval_gate_readable": False,
              "m11_eval_compatibility_true": False,
              "candidate_eval_compatibility_true": False,
              "required_vs_degrade_mask_compatible": True,
          }
          m11e_snapshot_key = str((candidate_bundle.get("rollback_pointers") or {}).get("m11e_snapshot_key", "")).strip() if candidate_bundle else ""
          m11e_snapshot: dict[str, Any] = {}
          if not m11e_snapshot_key:
              blockers.append({"code": "M12-B3", "message": "Candidate rollback pointers missing m11e_snapshot_key."})
          else:
              try:
                  m11e_snapshot = s3_get_json(s3, default_bucket, m11e_snapshot_key)
                  policy_degrade_checks["m11_eval_gate_readable"] = True
              except Exception as exc:
                  read_errors.append({"surface": m11e_snapshot_key, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B3", "message": "M11.E snapshot unreadable from candidate rollback pointers."})

          if m11e_snapshot:
              gate_results = m11e_snapshot.get("gate_results") if isinstance(m11e_snapshot.get("gate_results"), dict) else {}
              policy_degrade_checks["m11_eval_compatibility_true"] = bool(gate_results.get("compatibility", False))
              if not policy_degrade_checks["m11_eval_compatibility_true"]:
                  blockers.append({"code": "M12-B3", "message": "M11.E compatibility gate is false."})

          if candidate_bundle:
              c_eval = ((candidate_bundle.get("metrics") or {}).get("eval_gate_results")) if isinstance(candidate_bundle.get("metrics"), dict) else {}
              policy_degrade_checks["candidate_eval_compatibility_true"] = bool(c_eval.get("compatibility", False))
              if not policy_degrade_checks["candidate_eval_compatibility_true"]:
                  blockers.append({"code": "M12-B3", "message": "Candidate eval gate compatibility is false."})
              required_caps = candidate_bundle.get("required_capabilities")
              degrade_mask = candidate_bundle.get("degrade_capability_mask")
              if isinstance(required_caps, list) and required_caps:
                  if not isinstance(degrade_mask, list):
                      policy_degrade_checks["required_vs_degrade_mask_compatible"] = False
                      blockers.append({"code": "M12-B3", "message": "Candidate required_capabilities declared but degrade_capability_mask missing."})
                  else:
                      req_set = {str(x).strip() for x in required_caps if str(x).strip()}
                      deg_set = {str(x).strip() for x in degrade_mask if str(x).strip()}
                      if not req_set.issubset(deg_set):
                          policy_degrade_checks["required_vs_degrade_mask_compatible"] = False
                          blockers.append({"code": "M12-B3", "message": "Candidate required_capabilities not satisfiable by degrade_capability_mask."})

          schema_checks = {
              "handles_resolved": False,
              "registry_mode_valid": False,
              "compatibility_mode_valid": False,
              "topic_handle_valid": False,
          }
          handles_path = Path("docs/model_spec/platform/migration_to_dev/dev_full_handles.registry.v0.md")
          handles: dict[str, str] = {}
          required_schema_handles = [
              "SCHEMA_REGISTRY_MODE",
              "GLUE_SCHEMA_REGISTRY_NAME",
              "GLUE_SCHEMA_COMPATIBILITY_MODE",
              "FP_BUS_LEARNING_REGISTRY_EVENTS_V1",
          ]
          resolved_schema_handles: dict[str, str] = {}
          unresolved_schema_handles: list[str] = []
          try:
              handles = parse_handles(handles_path)
          except Exception as exc:
              blockers.append({"code": "M12-B3", "message": f"Unable to parse handles registry: {type(exc).__name__}."})
          for h in required_schema_handles:
              v = str(handles.get(h, "")).strip()
              resolved_schema_handles[h] = v
              if (not v) or (v.upper() == "TO_PIN"):
                  unresolved_schema_handles.append(h)
          schema_checks["handles_resolved"] = len(unresolved_schema_handles) == 0
          if unresolved_schema_handles:
              blockers.append({"code": "M12-B3", "message": f"Unresolved schema/event handles: {', '.join(unresolved_schema_handles)}."})
          registry_mode = resolved_schema_handles.get("SCHEMA_REGISTRY_MODE", "")
          schema_checks["registry_mode_valid"] = registry_mode == "AWS_GLUE_SCHEMA_REGISTRY"
          if not schema_checks["registry_mode_valid"]:
              blockers.append({"code": "M12-B3", "message": f"SCHEMA_REGISTRY_MODE invalid for M12.C: '{registry_mode}'."})
          compat_mode = resolved_schema_handles.get("GLUE_SCHEMA_COMPATIBILITY_MODE", "")
          schema_checks["compatibility_mode_valid"] = compat_mode in {"BACKWARD", "FORWARD", "FULL"}
          if not schema_checks["compatibility_mode_valid"]:
              blockers.append({"code": "M12-B3", "message": f"GLUE_SCHEMA_COMPATIBILITY_MODE invalid: '{compat_mode}'."})
          topic_handle = resolved_schema_handles.get("FP_BUS_LEARNING_REGISTRY_EVENTS_V1", "")
          schema_checks["topic_handle_valid"] = topic_handle.startswith("fp.bus.learning.registry.")
          if not schema_checks["topic_handle_valid"]:
              blockers.append({"code": "M12-B3", "message": f"FP_BUS_LEARNING_REGISTRY_EVENTS_V1 invalid: '{topic_handle}'."})

          compatibility_snapshot = {
              "captured_at_utc": now(),
              "phase": "M12.C",
              "phase_id": "P15",
              "execution_id": exec_id,
              "platform_run_id": platform_run_id,
              "scenario_run_id": scenario_run_id,
              "upstream_refs": {
                  "m12b_execution_id": upstream_m12b,
                  "m12b_execution_summary_key": m12b_summary_key,
                  "m12b_snapshot_key": m12b_snapshot_key,
                  "m11i_execution_id": upstream_m11i,
                  "m12_handoff_pack_key": handoff_key,
                  "dataset_fingerprint_ref": dataset_fingerprint_ref,
                  "m11e_snapshot_key": m11e_snapshot_key,
              },
              "feature_input_contract_checks": feature_contract_checks,
              "fingerprint_required_fields_checked": fingerprint_required_fields,
              "fingerprint_missing_fields": fingerprint_missing_fields,
              "policy_degrade_checks": policy_degrade_checks,
              "schema_event_envelope_checks": schema_checks,
              "resolved_schema_handles": resolved_schema_handles,
          }

          blocker_register = {
              "captured_at_utc": now(),
              "phase": "M12.C",
              "phase_id": "P15",
              "execution_id": exec_id,
              "blocker_count": 0,
              "blockers": [],
              "overall_pass": False,
          }

          execution_summary = {
              "captured_at_utc": now(),
              "phase": "M12.C",
              "phase_id": "P15",
              "execution_id": exec_id,
              "platform_run_id": platform_run_id,
              "scenario_run_id": scenario_run_id,
              "overall_pass": False,
              "blocker_count": 0,
              "verdict": "HOLD_REMEDIATE",
              "next_gate": "HOLD_REMEDIATE",
              "upstream_refs": {
                  "m12b_execution_id": upstream_m12b,
                  "m11i_execution_id": upstream_m11i,
              },
              "artifact_keys": {},
          }

          artifacts = {
              "m12c_compatibility_precheck_snapshot.json": compatibility_snapshot,
              "m12c_blocker_register.json": blocker_register,
              "m12c_execution_summary.json": execution_summary,
          }

          run_dir.mkdir(parents=True, exist_ok=True)
          for fname, payload in artifacts.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")

          run_control_prefix = f"evidence/dev_full/run_control/{exec_id}/"
          for fname, payload in artifacts.items():
              try:
                  s3_put_json(s3, default_bucket, run_control_prefix + fname, payload)
              except (BotoCoreError, ClientError) as exc:
                  upload_errors.append({"surface": run_control_prefix + fname, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B3", "message": f"Failed to publish {fname}."})

          blockers = dedupe(blockers)
          overall_pass = len(blockers) == 0
          verdict = "ADVANCE_TO_M12_D" if overall_pass else "HOLD_REMEDIATE"
          next_gate = "M12.D_READY" if overall_pass else "HOLD_REMEDIATE"
          blocker_register["blocker_count"] = len(blockers)
          blocker_register["blockers"] = blockers
          blocker_register["overall_pass"] = overall_pass
          execution_summary["overall_pass"] = overall_pass
          execution_summary["blocker_count"] = len(blockers)
          execution_summary["verdict"] = verdict
          execution_summary["next_gate"] = next_gate
          execution_summary["artifact_keys"] = {
              "m12c_compatibility_precheck_snapshot": run_control_prefix + "m12c_compatibility_precheck_snapshot.json",
              "m12c_blocker_register": run_control_prefix + "m12c_blocker_register.json",
              "m12c_execution_summary": run_control_prefix + "m12c_execution_summary.json",
          }
          execution_summary["read_errors"] = read_errors
          execution_summary["upload_errors"] = upload_errors

          for fname, payload in {
              "m12c_blocker_register.json": blocker_register,
              "m12c_execution_summary.json": execution_summary,
          }.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")
              try:
                  s3_put_json(s3, default_bucket, run_control_prefix + fname, payload)
              except Exception:
                  pass

          print(
              json.dumps(
                  {
                      "execution_id": exec_id,
                      "overall_pass": overall_pass,
                      "blocker_count": len(blockers),
                      "next_gate": next_gate,
                      "verdict": verdict,
                      "evidence_prefix": f"s3://{default_bucket}/{run_control_prefix}",
                  },
                  indent=2,
                  ensure_ascii=True,
              )
          )
          if not overall_pass:
              raise SystemExit(1)
          PY

      - name: Execute M12.D promotion event commit (managed)
        if: ${{ inputs.execution_mode == 'm12d_execute' && inputs.m12_subphase == 'D' }}
        shell: bash
        env:
          EXEC_ID: ${{ steps.run_meta.outputs.execution_id }}
          RUN_DIR: ${{ steps.run_meta.outputs.run_dir }}
          EVIDENCE_BUCKET: ${{ inputs.evidence_bucket }}
          AWS_REGION: ${{ inputs.aws_region }}
          UPSTREAM_M12C_EXEC: ${{ inputs.upstream_m12c_execution }}
        run: |
          set -euo pipefail
          python - <<'PY'
          from __future__ import annotations
          import hashlib
          import json
          import os
          import re
          from datetime import datetime, timezone
          from pathlib import Path
          from typing import Any

          import boto3
          from botocore.exceptions import BotoCoreError, ClientError

          def now() -> str:
              return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")

          def s3_get_json(s3: Any, bucket: str, key: str) -> dict[str, Any]:
              raw = s3.get_object(Bucket=bucket, Key=key)["Body"].read().decode("utf-8")
              payload = json.loads(raw)
              if not isinstance(payload, dict):
                  raise ValueError("json_not_object")
              return payload

          def s3_put_json(s3: Any, bucket: str, key: str, payload: dict[str, Any]) -> None:
              body = (json.dumps(payload, indent=2, ensure_ascii=True) + "\n").encode("utf-8")
              s3.put_object(Bucket=bucket, Key=key, Body=body, ContentType="application/json")
              s3.head_object(Bucket=bucket, Key=key)

          def s3_parse_uri(uri: str) -> tuple[str, str]:
              if not uri.startswith("s3://"):
                  raise ValueError("not_s3_uri")
              tail = uri[5:]
              if "/" not in tail:
                  raise ValueError("missing_key")
              b, k = tail.split("/", 1)
              if not b or not k:
                  raise ValueError("incomplete_s3_uri")
              return b, k

          def parse_handles(path: Path) -> dict[str, str]:
              rx = re.compile(r"^\*\s+`([A-Z0-9_]+)\s*=\s*(.+)`\s*$")
              out: dict[str, str] = {}
              for line in path.read_text(encoding="utf-8").splitlines():
                  m = rx.match(line.strip())
                  if not m:
                      continue
                  key = m.group(1).strip()
                  raw = m.group(2).strip()
                  if (raw.startswith('"') and raw.endswith('"')) or (raw.startswith("'") and raw.endswith("'")):
                      out[key] = raw[1:-1]
                  else:
                      out[key] = raw
              return out

          def dedupe(blockers: list[dict[str, str]]) -> list[dict[str, str]]:
              out: list[dict[str, str]] = []
              seen: set[tuple[str, str]] = set()
              for b in blockers:
                  code = str(b.get("code", "")).strip()
                  msg = str(b.get("message", "")).strip()
                  sig = (code, msg)
                  if sig in seen:
                      continue
                  seen.add(sig)
                  out.append({"code": code, "message": msg})
              return out

          exec_id = os.environ["EXEC_ID"].strip()
          run_dir = Path(os.environ["RUN_DIR"].strip())
          default_bucket = os.environ["EVIDENCE_BUCKET"].strip()
          region = os.environ.get("AWS_REGION", "eu-west-2").strip() or "eu-west-2"
          upstream_m12c = os.environ["UPSTREAM_M12C_EXEC"].strip()

          s3 = boto3.client("s3", region_name=region)
          blockers: list[dict[str, str]] = []
          read_errors: list[dict[str, str]] = []
          upload_errors: list[dict[str, str]] = []
          notes: list[str] = []

          m12c_summary_key = f"evidence/dev_full/run_control/{upstream_m12c}/m12c_execution_summary.json"
          m12c_snapshot_key = f"evidence/dev_full/run_control/{upstream_m12c}/m12c_compatibility_precheck_snapshot.json"
          m12c_summary: dict[str, Any] = {}
          m12c_snapshot: dict[str, Any] = {}
          try:
              m12c_summary = s3_get_json(s3, default_bucket, m12c_summary_key)
              m12c_snapshot = s3_get_json(s3, default_bucket, m12c_snapshot_key)
          except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
              read_errors.append({"surface": "m12c_summary_snapshot", "error": type(exc).__name__})
              blockers.append({"code": "M12-B4", "message": "Unreadable M12.C summary/snapshot."})

          platform_run_id = str(m12c_summary.get("platform_run_id", "")).strip()
          scenario_run_id = str(m12c_summary.get("scenario_run_id", "")).strip()
          if m12c_summary:
              if not bool(m12c_summary.get("overall_pass", False)):
                  blockers.append({"code": "M12-B4", "message": "M12.C overall_pass is false."})
              try:
                  m12c_blocker_count = int(str(m12c_summary.get("blocker_count", "")).strip())
              except Exception:
                  m12c_blocker_count = -1
              if m12c_blocker_count != 0:
                  blockers.append({"code": "M12-B4", "message": "M12.C blocker_count is not zero."})
              if str(m12c_summary.get("next_gate", "")).strip() != "M12.D_READY":
                  blockers.append({"code": "M12-B4", "message": "M12.C next_gate is not M12.D_READY."})
              if not platform_run_id or not scenario_run_id:
                  blockers.append({"code": "M12-B4", "message": "M12.C run scope is incomplete."})

          upstream_m12b = str((m12c_snapshot.get("upstream_refs") or {}).get("m12b_execution_id", "")).strip()
          m12b_snapshot_key = f"evidence/dev_full/run_control/{upstream_m12b}/m12b_candidate_eligibility_snapshot.json" if upstream_m12b else ""
          m12b_snapshot: dict[str, Any] = {}
          if m12b_snapshot_key:
              try:
                  m12b_snapshot = s3_get_json(s3, default_bucket, m12b_snapshot_key)
              except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
                  read_errors.append({"surface": m12b_snapshot_key, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B4", "message": "Unreadable M12.B candidate eligibility snapshot."})
          else:
              blockers.append({"code": "M12-B4", "message": "M12.C snapshot missing upstream M12.B execution id."})

          upstream_m11i = str((m12c_snapshot.get("upstream_refs") or {}).get("m11i_execution_id", "")).strip()
          m12_handoff_pack_key = f"evidence/dev_full/run_control/{upstream_m11i}/m12_handoff_pack.json" if upstream_m11i else ""
          m12_handoff_pack: dict[str, Any] = {}
          if m12_handoff_pack_key:
              try:
                  m12_handoff_pack = s3_get_json(s3, default_bucket, m12_handoff_pack_key)
              except (BotoCoreError, ClientError, ValueError, json.JSONDecodeError) as exc:
                  read_errors.append({"surface": m12_handoff_pack_key, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B4", "message": "Unreadable M12 handoff pack from M11.I."})
          else:
              blockers.append({"code": "M12-B4", "message": "M12.C snapshot missing upstream M11.I execution id."})

          candidate_ref = ""
          required_refs = m12_handoff_pack.get("required_refs") if isinstance(m12_handoff_pack.get("required_refs"), dict) else {}
          if required_refs:
              candidate_ref = str(required_refs.get("mf_candidate_bundle_ref", "")).strip()
          if not candidate_ref and isinstance(m12b_snapshot.get("readable_ref_report"), dict):
              candidate_ref = str((m12b_snapshot.get("readable_ref_report") or {}).get("mf_candidate_bundle_ref", {}).get("ref", "")).strip()

          candidate_bundle: dict[str, Any] = {}
          candidate_bucket = default_bucket
          candidate_key = ""
          if not candidate_ref:
              blockers.append({"code": "M12-B4", "message": "Unable to resolve candidate bundle ref from upstream evidence."})
          else:
              try:
                  candidate_bucket, candidate_key = s3_parse_uri(candidate_ref)
                  candidate_bundle = s3_get_json(s3, candidate_bucket, candidate_key)
              except Exception as exc:
                  read_errors.append({"surface": candidate_ref, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B4", "message": "Candidate bundle is unreadable."})

          bundle_id = str(candidate_bundle.get("bundle_id", "")).strip()
          candidate_status = str(candidate_bundle.get("bundle_status", "")).strip()
          candidate_run_scope_ok = (
              str(candidate_bundle.get("platform_run_id", "")).strip() == platform_run_id
              and str(candidate_bundle.get("scenario_run_id", "")).strip() == scenario_run_id
          )
          if candidate_bundle:
              if candidate_status != "CANDIDATE":
                  blockers.append({"code": "M12-B4", "message": "Candidate bundle status is not CANDIDATE at M12.D entry."})
              if not bundle_id:
                  blockers.append({"code": "M12-B4", "message": "Candidate bundle missing bundle_id."})
              if not candidate_run_scope_ok:
                  blockers.append({"code": "M12-B4", "message": "Candidate bundle run scope mismatches M12.C scope."})

          handles_path = Path("docs/model_spec/platform/migration_to_dev/dev_full_handles.registry.v0.md")
          handles: dict[str, str] = {}
          try:
              handles = parse_handles(handles_path)
          except Exception as exc:
              blockers.append({"code": "M12-B4", "message": f"Unable to parse handles registry: {type(exc).__name__}."})

          required_handles = [
              "MPR_PROMOTION_RECEIPT_PATH_PATTERN",
              "FP_BUS_LEARNING_REGISTRY_EVENTS_V1",
              "SCHEMA_REGISTRY_MODE",
              "GLUE_SCHEMA_REGISTRY_NAME",
              "GLUE_SCHEMA_COMPATIBILITY_MODE",
          ]
          resolved_handles: dict[str, str] = {}
          unresolved_handles: list[str] = []
          for key in required_handles:
              value = str(handles.get(key, "")).strip()
              resolved_handles[key] = value
              if (not value) or (value.upper() == "TO_PIN"):
                  unresolved_handles.append(key)
          if unresolved_handles:
              blockers.append({"code": "M12-B4", "message": f"Unresolved required handles: {', '.join(unresolved_handles)}."})

          mpr_pattern = resolved_handles.get("MPR_PROMOTION_RECEIPT_PATH_PATTERN", "")
          topic_handle = resolved_handles.get("FP_BUS_LEARNING_REGISTRY_EVENTS_V1", "")
          promotion_key = ""
          if mpr_pattern and platform_run_id:
              promotion_key = mpr_pattern.replace("{platform_run_id}", platform_run_id)
          if (not promotion_key) or ("{" in promotion_key) or ("}" in promotion_key):
              blockers.append({"code": "M12-B4", "message": "MPR_PROMOTION_RECEIPT_PATH_PATTERN did not fully resolve."})
          if not topic_handle.startswith("fp.bus.learning.registry."):
              blockers.append({"code": "M12-B4", "message": f"FP_BUS_LEARNING_REGISTRY_EVENTS_V1 invalid: '{topic_handle}'."})

          registry_event_seed = f"{platform_run_id}|{scenario_run_id}|{bundle_id}|{exec_id}|BUNDLE_PROMOTED_ACTIVE"
          registry_event_id = hashlib.sha256(registry_event_seed.encode("utf-8")).hexdigest()
          candidate_bundle_s3_uri = f"s3://{candidate_bucket}/{candidate_key}" if candidate_key else ""

          lifecycle_event = {
              "schema_version": "learning.registry_lifecycle.v0",
              "registry_event_id": registry_event_id,
              "event_type": "BUNDLE_PROMOTED_ACTIVE",
              "scope_key": {
                  "environment": "dev_full",
                  "mode": "managed",
                  "bundle_slot": "active",
                  "tenant_id": f"{platform_run_id}:{scenario_run_id}",
              },
              "bundle_ref": {
                  "bundle_id": bundle_id,
                  "bundle_version": str(candidate_bundle.get("execution_id", "")).strip() or "v0",
                  "registry_ref": candidate_bundle_s3_uri or f"s3://{default_bucket}/{promotion_key}",
              },
              "actor": {
                  "actor_id": "SYSTEM::m12d_managed_lane",
                  "source_type": "SYSTEM",
              },
              "ts_utc": now(),
              "evidence_refs": [
                  {"ref_type": "m12c_execution_summary", "ref_id": m12c_summary_key},
                  {"ref_type": "m12c_snapshot", "ref_id": m12c_snapshot_key},
                  {"ref_type": "m12b_snapshot", "ref_id": m12b_snapshot_key},
                  {"ref_type": "m12_handoff_pack", "ref_id": m12_handoff_pack_key},
                  {"ref_type": "candidate_bundle", "ref_id": candidate_bundle_s3_uri},
              ],
          }

          lifecycle_required = [
              "schema_version",
              "registry_event_id",
              "event_type",
              "scope_key",
              "bundle_ref",
              "actor",
              "ts_utc",
          ]
          missing_lifecycle_fields = [k for k in lifecycle_required if not lifecycle_event.get(k)]
          lifecycle_scope = lifecycle_event.get("scope_key") if isinstance(lifecycle_event.get("scope_key"), dict) else {}
          lifecycle_bundle_ref = lifecycle_event.get("bundle_ref") if isinstance(lifecycle_event.get("bundle_ref"), dict) else {}
          lifecycle_actor = lifecycle_event.get("actor") if isinstance(lifecycle_event.get("actor"), dict) else {}
          if missing_lifecycle_fields:
              blockers.append({"code": "M12-B4", "message": f"Lifecycle payload missing required fields: {', '.join(missing_lifecycle_fields)}."})
          if str(lifecycle_event.get("schema_version", "")).strip() != "learning.registry_lifecycle.v0":
              blockers.append({"code": "M12-B4", "message": "Lifecycle payload schema_version mismatch."})
          if str(lifecycle_event.get("event_type", "")).strip() != "BUNDLE_PROMOTED_ACTIVE":
              blockers.append({"code": "M12-B4", "message": "Lifecycle payload event_type mismatch for promotion."})
          if not all(bool(str(lifecycle_scope.get(k, "")).strip()) for k in ["environment", "mode", "bundle_slot", "tenant_id"]):
              blockers.append({"code": "M12-B4", "message": "Lifecycle payload scope_key is incomplete."})
          if not all(bool(str(lifecycle_bundle_ref.get(k, "")).strip()) for k in ["bundle_id", "bundle_version", "registry_ref"]):
              blockers.append({"code": "M12-B4", "message": "Lifecycle payload bundle_ref is incomplete."})
          if not all(bool(str(lifecycle_actor.get(k, "")).strip()) for k in ["actor_id", "source_type"]):
              blockers.append({"code": "M12-B4", "message": "Lifecycle payload actor is incomplete."})

          promotion_receipt = {
              "captured_at_utc": now(),
              "phase": "M12.D",
              "phase_id": "P15",
              "execution_id": exec_id,
              "platform_run_id": platform_run_id,
              "scenario_run_id": scenario_run_id,
              "status": "PROMOTION_COMMITTED",
              "promotion": {
                  "candidate_bundle_ref": candidate_bundle_s3_uri,
                  "bundle_id": bundle_id,
                  "bundle_status_before": candidate_status,
                  "bundle_status_after": "PROMOTED_ACTIVE",
              },
              "registry_event": lifecycle_event,
              "publication": {
                  "topic": topic_handle,
                  "publication_mode": "RUN_SCOPED_PUBLICATION_RECEIPT",
                  "event_sha256": hashlib.sha256(json.dumps(lifecycle_event, sort_keys=True, ensure_ascii=True).encode("utf-8")).hexdigest(),
                  "status": "COMMITTED_WITH_READBACK",
                  "note": "Managed lane confirms publication receipt + readback artifact without claiming broker offset.",
              },
              "provenance": {
                  "upstream_m12c_execution_id": upstream_m12c,
                  "upstream_m12b_execution_id": upstream_m12b,
                  "upstream_m11i_execution_id": upstream_m11i,
              },
          }

          publication_receipt = {
              "captured_at_utc": now(),
              "phase": "M12.D",
              "phase_id": "P15",
              "execution_id": exec_id,
              "platform_run_id": platform_run_id,
              "scenario_run_id": scenario_run_id,
              "topic": topic_handle,
              "registry_event_id": registry_event_id,
              "publication_mode": "RUN_SCOPED_PUBLICATION_RECEIPT",
              "publication_status": "COMMITTED_WITH_READBACK",
              "transport_readback": {
                  "source": "s3_run_scoped_receipt",
                  "receipt_key": promotion_key,
                  "broker_offset_claimed": False,
              },
          }

          if not blockers and promotion_key:
              try:
                  s3_put_json(s3, default_bucket, promotion_key, promotion_receipt)
              except (BotoCoreError, ClientError) as exc:
                  upload_errors.append({"surface": promotion_key, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B4", "message": "Failed to write run-scoped promotion receipt."})

          promotion_receipt_readback_ok = False
          promotion_receipt_readback_error = ""
          if not blockers and promotion_key:
              try:
                  readback_payload = s3_get_json(s3, default_bucket, promotion_key)
                  promotion_receipt_readback_ok = (
                      str(readback_payload.get("phase", "")).strip() == "M12.D"
                      and str(readback_payload.get("phase_id", "")).strip() == "P15"
                      and str(readback_payload.get("platform_run_id", "")).strip() == platform_run_id
                      and str(readback_payload.get("scenario_run_id", "")).strip() == scenario_run_id
                      and str((((readback_payload.get("registry_event") or {}).get("registry_event_id")) or "")).strip() == registry_event_id
                  )
                  if not promotion_receipt_readback_ok:
                      blockers.append({"code": "M12-B4", "message": "Promotion receipt readback content mismatch."})
              except Exception as exc:
                  promotion_receipt_readback_error = type(exc).__name__
                  read_errors.append({"surface": promotion_key, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B4", "message": "Promotion receipt readback failed."})

          promotion_snapshot = {
              "captured_at_utc": now(),
              "phase": "M12.D",
              "phase_id": "P15",
              "execution_id": exec_id,
              "platform_run_id": platform_run_id,
              "scenario_run_id": scenario_run_id,
              "upstream_refs": {
                  "m12c_execution_id": upstream_m12c,
                  "m12c_execution_summary_key": m12c_summary_key,
                  "m12c_snapshot_key": m12c_snapshot_key,
                  "m12b_execution_id": upstream_m12b,
                  "m12b_snapshot_key": m12b_snapshot_key,
                  "m11i_execution_id": upstream_m11i,
                  "m12_handoff_pack_key": m12_handoff_pack_key,
              },
              "required_handles": required_handles,
              "resolved_handles": resolved_handles,
              "unresolved_handles": unresolved_handles,
              "promotion_receipt_key": promotion_key,
              "promotion_receipt_s3_uri": f"s3://{default_bucket}/{promotion_key}" if promotion_key else "",
              "promotion_receipt_readback_ok": promotion_receipt_readback_ok,
              "promotion_receipt_readback_error": promotion_receipt_readback_error,
              "candidate_bundle_ref": candidate_bundle_s3_uri,
              "candidate_checks": {
                  "bundle_status_candidate": candidate_status == "CANDIDATE",
                  "bundle_id_present": bool(bundle_id),
                  "run_scope_match": candidate_run_scope_ok,
              },
              "lifecycle_event_checks": {
                  "schema_version_ok": str(lifecycle_event.get("schema_version", "")).strip() == "learning.registry_lifecycle.v0",
                  "event_type_ok": str(lifecycle_event.get("event_type", "")).strip() == "BUNDLE_PROMOTED_ACTIVE",
                  "scope_complete": all(bool(str(lifecycle_scope.get(k, "")).strip()) for k in ["environment", "mode", "bundle_slot", "tenant_id"]),
                  "bundle_ref_complete": all(bool(str(lifecycle_bundle_ref.get(k, "")).strip()) for k in ["bundle_id", "bundle_version", "registry_ref"]),
                  "actor_complete": all(bool(str(lifecycle_actor.get(k, "")).strip()) for k in ["actor_id", "source_type"]),
              },
              "publication_checks": {
                  "topic_handle": topic_handle,
                  "topic_handle_valid": topic_handle.startswith("fp.bus.learning.registry."),
                  "publication_mode": publication_receipt["publication_mode"],
                  "publication_status": publication_receipt["publication_status"],
                  "broker_offset_claimed": False,
              },
              "notes": notes,
          }

          blocker_register = {
              "captured_at_utc": now(),
              "phase": "M12.D",
              "phase_id": "P15",
              "execution_id": exec_id,
              "blocker_count": 0,
              "blockers": [],
              "overall_pass": False,
          }

          execution_summary = {
              "captured_at_utc": now(),
              "phase": "M12.D",
              "phase_id": "P15",
              "execution_id": exec_id,
              "platform_run_id": platform_run_id,
              "scenario_run_id": scenario_run_id,
              "overall_pass": False,
              "blocker_count": 0,
              "verdict": "HOLD_REMEDIATE",
              "next_gate": "HOLD_REMEDIATE",
              "upstream_refs": {
                  "m12c_execution_id": upstream_m12c,
                  "m12b_execution_id": upstream_m12b,
                  "m11i_execution_id": upstream_m11i,
              },
              "artifact_keys": {},
          }

          artifacts = {
              "m12d_registry_lifecycle_event.json": lifecycle_event,
              "m12d_learning_registry_publication_receipt.json": publication_receipt,
              "m12d_promotion_commit_snapshot.json": promotion_snapshot,
              "m12d_blocker_register.json": blocker_register,
              "m12d_execution_summary.json": execution_summary,
          }

          run_dir.mkdir(parents=True, exist_ok=True)
          for fname, payload in artifacts.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")

          run_control_prefix = f"evidence/dev_full/run_control/{exec_id}/"
          for fname, payload in artifacts.items():
              try:
                  s3_put_json(s3, default_bucket, run_control_prefix + fname, payload)
              except (BotoCoreError, ClientError) as exc:
                  upload_errors.append({"surface": run_control_prefix + fname, "error": type(exc).__name__})
                  blockers.append({"code": "M12-B4", "message": f"Failed to publish {fname}."})

          blockers = dedupe(blockers)
          overall_pass = len(blockers) == 0
          verdict = "ADVANCE_TO_M12_E" if overall_pass else "HOLD_REMEDIATE"
          next_gate = "M12.E_READY" if overall_pass else "HOLD_REMEDIATE"
          blocker_register["blocker_count"] = len(blockers)
          blocker_register["blockers"] = blockers
          blocker_register["overall_pass"] = overall_pass
          execution_summary["overall_pass"] = overall_pass
          execution_summary["blocker_count"] = len(blockers)
          execution_summary["verdict"] = verdict
          execution_summary["next_gate"] = next_gate
          execution_summary["artifact_keys"] = {
              "m12d_registry_lifecycle_event": run_control_prefix + "m12d_registry_lifecycle_event.json",
              "m12d_learning_registry_publication_receipt": run_control_prefix + "m12d_learning_registry_publication_receipt.json",
              "m12d_promotion_commit_snapshot": run_control_prefix + "m12d_promotion_commit_snapshot.json",
              "m12d_blocker_register": run_control_prefix + "m12d_blocker_register.json",
              "m12d_execution_summary": run_control_prefix + "m12d_execution_summary.json",
              "mpr_promotion_receipt_key": promotion_key,
          }
          execution_summary["read_errors"] = read_errors
          execution_summary["upload_errors"] = upload_errors

          for fname, payload in {
              "m12d_promotion_commit_snapshot.json": promotion_snapshot,
              "m12d_blocker_register.json": blocker_register,
              "m12d_execution_summary.json": execution_summary,
          }.items():
              (run_dir / fname).write_text(json.dumps(payload, indent=2, ensure_ascii=True) + "\n", encoding="utf-8")
              try:
                  s3_put_json(s3, default_bucket, run_control_prefix + fname, payload)
              except Exception:
                  pass

          print(
              json.dumps(
                  {
                      "execution_id": exec_id,
                      "upstream_m12c_execution": upstream_m12c,
                      "overall_pass": overall_pass,
                      "blocker_count": len(blockers),
                      "next_gate": next_gate,
                      "verdict": verdict,
                      "promotion_receipt_s3_uri": f"s3://{default_bucket}/{promotion_key}" if promotion_key else "",
                      "evidence_prefix": f"s3://{default_bucket}/{run_control_prefix}",
                  },
                  indent=2,
                  ensure_ascii=True,
              )
          )
          if not overall_pass:
              raise SystemExit(1)
          PY

      - name: Upload local run artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: dev-full-m12-${{ inputs.m12_subphase }}-${{ steps.run_meta.outputs.execution_id }}
          path: ${{ steps.run_meta.outputs.run_dir }}
          if-no-files-found: warn
